{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - An\u00e1lisis de Resultados de Modelos\n",
    "\n",
    "**Objetivo:** Analizar y comparar los resultados de los modelos de clasificaci\u00f3n y regresi\u00f3n generados por los pipelines de Kedro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librer\u00edas cargadas correctamente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci\u00f3n de gr\u00e1ficos\n",
    "plt.style.use('ggplot')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Rutas\n",
    "project_root = Path('..') if Path('..').joinpath('data').exists() else Path('.')\n",
    "\n",
    "print('Librer\u00edas cargadas correctamente')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versi\u00f3n: Dataset Combinado SO2023 + SO2025\n",
    "\n",
    "**Dataset Utilizado:**\n",
    "- Stack Overflow Developer Survey 2023: 89,184 registros\n",
    "- Stack Overflow Developer Survey 2025: 49,123 registros  \n",
    "- **Total procesado**: 68,613 registros (incremento del 50% respecto a versi\u00f3n previa)\n",
    "- **Features**: 556 columnas (incluye variable Year para an\u00e1lisis temporal)\n",
    "\n",
    "**Mejoras en Rendimiento de Modelos:**\n",
    "- Regresi\u00f3n: R\u00b2=0.9130 (+0.75%), RMSE=$15,845 (reducci\u00f3n de $206)\n",
    "- Clasificaci\u00f3n: F1=0.9769 (+0.31%), Accuracy=98.59%\n",
    "- An\u00e1lisis Chile: 186 desarrolladores, mediana salarial $40,016 USD\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Verificaci\u00f3n del Entorno\n",
    "\n",
    "Antes de comenzar el an\u00e1lisis, verificamos que todos los componentes necesarios est\u00e9n disponibles:\n",
    "- Librer\u00edas Python requeridas\n",
    "- Estructura de directorios del proyecto\n",
    "- Artefactos generados por los pipelines (modelos, m\u00e9tricas)\n",
    "\n",
    "Este notebook utiliza la **extensi\u00f3n IPython de Kedro** para acceder al cat\u00e1logo de datos y cargar los resultados de los experimentos de forma reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos de m\u00e9tricas disponibles:\n",
      "\n",
      "Modelos disponibles:\n",
      "  - regresion_model.pkl\n",
      "  - clasificacion_model.pkl\n",
      "  - ridge_poly_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Verificar archivos de m\u00e9tricas disponibles\n",
    "metrics_dir = project_root / 'data' / '08_reporting'\n",
    "models_dir = project_root / 'data' / '06_models'\n",
    "\n",
    "print('Archivos de m\u00e9tricas disponibles:')\n",
    "if metrics_dir.exists():\n",
    "    for f in metrics_dir.glob('*.json'):\n",
    "        print(f'  - {f.name}')\n",
    "else:\n",
    "    print('  Directorio de m\u00e9tricas no encontrado')\n",
    "\n",
    "print('\\nModelos disponibles:')\n",
    "if models_dir.exists():\n",
    "    for f in models_dir.glob('*.pkl'):\n",
    "        print(f'  - {f.name}')\n",
    "else:\n",
    "    print('  Directorio de modelos no encontrado')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga del Contexto y Cat\u00e1logo de Kedro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuraci\u00f3n b\u00e1sica aplicada (sin Kedro)\n"
     ]
    }
   ],
   "source": [
    "# Entorno listo.\n",
    "print('Configuraci\u00f3n b\u00e1sica aplicada (sin Kedro)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecci\u00f3n del Cat\u00e1logo de Kedro\n",
    "\n",
    "Una vez cargada la extensi\u00f3n, tenemos acceso a las **variables globales** de Kedro. Vamos a explorarlas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado: 45,813 filas, 300 columnas\n"
     ]
    }
   ],
   "source": [
    "# Cargar dataset procesado\n",
    "data_path = project_root / 'data' / '05_model_input' / 'datos_para_modelado.parquet'\n",
    "\n",
    "if data_path.exists():\n",
    "    df = pd.read_parquet(data_path)\n",
    "    print(f'Dataset cargado: {df.shape[0]:,} filas, {df.shape[1]} columnas')\n",
    "    df.head()\n",
    "else:\n",
    "    print(f'Archivo no encontrado: {data_path}')\n",
    "    print('Ejecutar primero: kedro run --pipeline procesamiento_de_datos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \u00bfQu\u00e9 acaba de pasar? Explicaci\u00f3n del Contexto de Kedro\n",
    "\n",
    "La celda anterior ejecuta dos \"comandos m\u00e1gicos\" espec\u00edficos de Kedro para notebooks:\n",
    "\n",
    "1.  `%load_ext kedro.ipython`: Carga una extensi\u00f3n especial de Kedro que nos permite usar comandos de Kedro dentro del notebook.\n",
    "2.  `%reload_kedro`: Este es el comando importante. Busca la ra\u00edz de nuestro proyecto Kedro, inicia una sesi\u00f3n y carga en la memoria del notebook varios objetos clave.\n",
    "\n",
    "El texto que aparece como salida nos confirma que todo ha ido bien y nos informa de las **variables globales** que ha creado para nosotros:\n",
    "\n",
    "*   `catalog`: Este es el m\u00e1s importante para nosotros ahora. Es una copia del **Cat\u00e1logo de Datos** (`conf/base/catalog.yml`). A trav\u00e9s de \u00e9l, podemos cargar y guardar cualquier dataset definido en el proyecto con un simple `catalog.load(\"nombre_del_dataset\")`.\n",
    "*   `context`: Es el \"coraz\u00f3n\" del proyecto Kedro. Contiene toda la configuraci\u00f3n, par\u00e1metros, etc.\n",
    "*   `pipelines`: Un diccionario que contiene todos los pipelines definidos en el proyecto.\n",
    "*   `session`: La sesi\u00f3n de Kedro activa, que gestiona la ejecuci\u00f3n.\n",
    "\n",
    "En resumen, esa celda ha \"conectado\" nuestro notebook con el proyecto Kedro, d\u00e1ndonos acceso a todos sus componentes de forma program\u00e1tica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar m\u00e9tricas desde archivos JSON (sin Kedro)\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "metrics_dir = project_root / 'data' / '08_reporting'\n",
    "metrics_regresion = {}\n",
    "metrics_clasificacion = {}\n",
    "\n",
    "reg_path = metrics_dir / 'metrics.json'\n",
    "clf_path = metrics_dir / 'metrics_clf.json'\n",
    "\n",
    "def _leer_metricas(ruta, etiqueta):\n",
    "    if ruta.exists():\n",
    "        with ruta.open() as f:\n",
    "            datos = json.load(f)\n",
    "        print(f\"OK {etiqueta} cargadas desde {ruta}\")\n",
    "        return datos\n",
    "    print(f\"FALTA archivo {ruta}. Ejecuta 'kedro run --pipeline {etiqueta}' para generarlo.\")\n",
    "    return {}\n",
    "\n",
    "metrics_regresion = _leer_metricas(reg_path, 'data_science_regresion')\n",
    "metrics_clasificacion = _leer_metricas(clf_path, 'data_science_clasificacion')\n",
    "\n",
    "if metrics_regresion or metrics_clasificacion:\n",
    "    print('Resumen r\u00e1pido de m\u00e9tricas:')\n",
    "    for nombre, valor in list(metrics_regresion.items())[:5]:\n",
    "        print(f'  REG {nombre}: {valor}')\n",
    "    for nombre, valor in list(metrics_clasificacion.items())[:5]:\n",
    "        print(f'  CLF {nombre}: {valor}')\n",
    "else:\n",
    "    print('No hay m\u00e9tricas disponibles todav\u00eda.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">\u2502</span>         df = # # catalog.load <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">reemplazado</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">'datos_para_modelado'</span><span style=\"font-weight: bold\">)</span>                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">\u2502</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">\u2502</span>              <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">\u25b2</span>                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">\u2502</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">SyntaxError: </span>invalid syntax\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[91m\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\u001b[0m\n",
       "\u001b[91m\u2502\u001b[0m         df = # # catalog.load \u001b[1;35mreemplazado\u001b[0m\u001b[1m(\u001b[0m\u001b[33m'datos_para_modelado'\u001b[0m\u001b[1m)\u001b[0m                                 \u001b[91m\u2502\u001b[0m\n",
       "\u001b[91m\u2502\u001b[0m              \u001b[1;91m\u25b2\u001b[0m                                                                                   \u001b[91m\u2502\u001b[0m\n",
       "\u001b[91m\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\u001b[0m\n",
       "\u001b[1;91mSyntaxError: \u001b[0minvalid syntax\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exploraci\u00f3n r\u00e1pida del dataset\n",
    "if '# catalog' in locals():\n",
    "    try:\n",
    "        df = # # catalog.load reemplazado('datos_para_modelado')\n",
    "        display(df.head())\n",
    "        display(df.describe())\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANTE: Entendiendo la Normalizacion de Datos\n",
    "\n",
    "**NOTA CRITICA**: Los valores numericos en el dataset procesado estan **NORMALIZADOS** usando StandardScaler.\n",
    "\n",
    "### Que significa esto?\n",
    "\n",
    "Los modelos de Machine Learning funcionan mejor cuando todas las variables tienen escalas similares. Por ejemplo:\n",
    "- WorkExp: valores entre 0-50 (a\u00f1os)\n",
    "- ConvertedCompYearly: valores entre 0-500,000 (USD)\n",
    "\n",
    "Sin normalizacion, el modelo daria mas importancia a CompTotal solo por tener valores mas grandes.\n",
    "\n",
    "### Formula de Normalizacion (StandardScaler):\n",
    "\n",
    "```\n",
    "valor_normalizado = (valor_original - media) / desviacion_estandar\n",
    "```\n",
    "\n",
    "### Como Interpretar Valores Normalizados:\n",
    "\n",
    "| Valor Normalizado | Significado | Ejemplo WorkExp |\n",
    "|-------------------|-------------|-----------------|\n",
    "| -2.0 | Muy por debajo del promedio | ~0 a\u00f1os (recien graduado) |\n",
    "| -1.0 | Bajo el promedio | ~2-3 a\u00f1os |\n",
    "| -0.5 | Ligeramente bajo | ~5-6 a\u00f1os |\n",
    "| 0.0 | Promedio exacto | ~8 a\u00f1os |\n",
    "| +0.5 | Ligeramente alto | ~10-11 a\u00f1os |\n",
    "| +1.0 | Sobre el promedio | ~14-15 a\u00f1os |\n",
    "| +2.0 | Muy alto | ~20+ a\u00f1os |\n",
    "\n",
    "### Ejemplo Real:\n",
    "\n",
    "**Desarrollador con WorkExp = -0.256558 (normalizado)**\n",
    "- Interpretacion: Experiencia ligeramente BAJO el promedio\n",
    "- Valor aproximado real: 6-7 a\u00f1os de experiencia\n",
    "\n",
    "**Variables Binarias (LearnCode_*, LanguageHaveWorkedWith_*, etc.)**\n",
    "- NO se normalizan (son 0 o 1)\n",
    "- 1 = La persona tiene esa caracteristica\n",
    "- 0 = La persona NO tiene esa caracteristica\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\udcca Visualizaci\u00f3n de Salarios: Datos Reales vs Normalizados\n",
    "\n",
    "**\u26a0\ufe0f IMPORTANTE**: Para la **visualizaci\u00f3n de distribuci\u00f3n de salarios**, se cargan los **datos REALES** (no normalizados) desde StackOverflow 2023, ya que los datos procesados est\u00e1n en escala normalizada (-3 a +3) y no son interpretables en gr\u00e1ficos.\n",
    "\n",
    "**Filtrado de Outliers Extremos:**\n",
    "- Se muestran salarios en el rango **$0 - $300,000 USD** para mejor legibilidad\n",
    "- Los outliers extremos (>$300K) se excluyen de la visualizaci\u00f3n pero NO del entrenamiento\n",
    "- Ejemplo de outliers: Algunos registros reportan salarios de $74 millones (probablemente errores de captura)\n",
    "- **Total real**: ~48,000 desarrolladores, de los cuales ~975 tienen salarios >$300K\n",
    "\n",
    "**Estad\u00edsticas del mercado real:**\n",
    "- **Mediana**: $74,963 USD (salario t\u00edpico de un desarrollador)\n",
    "- **Media**: $103,110 USD (inflada por outliers altos)\n",
    "- **Q1 (25%)**: $43,907 USD\n",
    "- **Q3 (75%)**: $121,641 USD\n",
    "\n",
    "A continuacion se muestra el dataset procesado (normalizado) que es el input al modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Data Understanding: Exploraci\u00f3n del Dataset\n",
    "\n",
    "Antes de analizar los resultados de los modelos, es fundamental entender la estructura y caracter\u00edsticas de los datos con los que trabajamos. Esta secci\u00f3n cumple con los requisitos de la metodolog\u00eda **CRISP-DM** (fase de Data Understanding)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cargar los Artefactos de los Pipelines\n",
    "\n",
    "Ahora que tenemos acceso al `catalog`, lo usamos para cargar todos los \"artefactos\" (resultados) que fueron generados y guardados por nuestros pipelines de `regresion` y `clasificacion`.\n",
    "\n",
    "Cada l\u00ednea de c\u00f3digo `catalog.load(\"...\")` busca en el archivo `conf/base/catalog.yml` el dataset con ese nombre y lo carga en una variable de Python:\n",
    "\n",
    "*   `catalog.load(\"metrics\")`: Carga el archivo `metrics.json` con los resultados del pipeline de regresi\u00f3n.\n",
    "*   `catalog.load(\"metrics_clf\")`: Carga el archivo `metrics_clf.json` con los resultados del pipeline de clasificaci\u00f3n.\n",
    "*   `catalog.load(\"classification_confusion_matrices\")`: Carga las matrices de confusi\u00f3n.\n",
    "*   `catalog.load(\"regresion_model\")` y `catalog.load(\"clasificacion_model\")`: Cargan los archivos `.pkl` que contienen los objetos de los modelos entrenados.\n",
    "\n",
    "**Significado de la Salida:**\n",
    "\n",
    "La salida de la celda es simplemente la impresi\u00f3n (`print`) de los diccionarios de m\u00e9tricas que acabamos de cargar. Esto nos sirve como una verificaci\u00f3n r\u00e1pida para confirmar que los datos se han cargado correctamente en las variables `metrics_regresion` y `metrics_clasificacion` antes de proceder a analizarlos en detalle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(list(metrics_regresion.items()), columns=[\"M\u00e9trica\", \"Valor\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaci\u00f3n de M\u00e9tricas con JSON\n",
    "\n",
    "Esta celda toma la variable `metrics_regresion` (que es un diccionario de Python) y la muestra en un formato m\u00e1s legible.\n",
    "\n",
    "*   `import json`: Importa la librer\u00eda est\u00e1ndar de Python para trabajar con el formato JSON.\n",
    "*   `json.dumps(..., indent=4)`: Esta funci\u00f3n, a menudo llamada \"pretty-print\" (impresi\u00f3n bonita), convierte el diccionario de Python en un texto con formato JSON, usando 4 espacios de indentaci\u00f3n.\n",
    "\n",
    "**Es exactamente la misma informaci\u00f3n** que se carg\u00f3 del cat\u00e1logo, pero en lugar de verla como un diccionario de Python en una sola l\u00ednea, la vemos estructurada y anidada, lo que facilita enormemente su lectura y comparaci\u00f3n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configurar estilo moderno y elegante\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# --- Preparar los datos para el gr\u00e1fico ---\n",
    "# Extraemos el nombre del modelo y su m\u00e9trica R2\n",
    "# Ignoramos LinearRegression porque su valor es tan bajo que distorsionar\u00eda el gr\u00e1fico\n",
    "r2_scores = {\n",
    "    model.replace('_model', ''): result['r2']\n",
    "    for model, result in metrics_regresion.items()\n",
    "    if 'LinearRegression' not in model\n",
    "}\n",
    "\n",
    "# Creamos un DataFrame de pandas para facilitar el ploteo\n",
    "df_r2 = pd.DataFrame(list(r2_scores.items()), columns=['Modelo', 'R2 Score']).sort_values('R2 Score', ascending=False)\n",
    "\n",
    "# Paleta de colores moderna: de mejor a peor (verde oscuro -> amarillo)\n",
    "colores_modernos = ['#2ECC71', '#3498DB', '#F39C12', '#E74C3C']\n",
    "\n",
    "# --- Crear el gr\u00e1fico ---\n",
    "plt.figure(figsize=(14, 7))\n",
    "barplot = sns.barplot(x='R2 Score', y='Modelo', data=df_r2, palette=colores_modernos, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# A\u00f1adir el valor exacto en cada barra para mayor claridad\n",
    "for index, value in enumerate(df_r2['R2 Score']):\n",
    "    plt.text(value + 0.02, index, f'{value:.4f}', color='black', ha=\"left\", va=\"center\", weight='bold', fontsize=13)\n",
    "\n",
    "# --- T\u00edtulos y etiquetas---\n",
    "plt.title('Comparaci\u00f3n de Modelos de Regresi\u00f3n por R\u00b2 Score', fontsize=18, weight='bold', pad=20)\n",
    "plt.xlabel('R\u00b2 Score (M\u00e1s alto es mejor)', fontsize=13, weight='bold')\n",
    "plt.ylabel('Modelo', fontsize=13, weight='bold')\n",
    "plt.xlim(0, 1.05)  # El R2 Score va de 0 a 1\n",
    "plt.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones del An\u00e1lisis de Regresi\u00f3n\n",
    "\n",
    "El gr\u00e1fico de barras anterior compara el rendimiento de los diferentes modelos de regresi\u00f3n utilizando la m\u00e9trica **R\u00b2 Score**.\n",
    "\n",
    "**Observaciones:**\n",
    "\n",
    "1.  **Ganador Claro:** El modelo `RandomForestRegressor` es notablemente superior a los dem\u00e1s, con un **R\u00b2 de 0.909**. Esto indica que es capaz de explicar casi el 91% de la variabilidad en los salarios, lo cual es un resultado excelente.\n",
    "2.  **Modelos de Boosting:** `XGBRegressor` tambi\u00e9n muestra un rendimiento muy fuerte con un R\u00b2 de 0.876, consolidando la idea de que los modelos basados en ensambles de \u00e1rboles son muy efectivos para este conjunto de datos.\n",
    "3.  **Modelos Lineales:** Los modelos `Ridge` y `Lasso`, aunque muy superiores a la regresi\u00f3n lineal simple (cuyo R\u00b2 era masivamente negativo), se quedan en un R\u00b2 de ~0.60. Esto sugiere que la relaci\u00f3n entre las caracter\u00edsticas y el salario no es puramente lineal y que estos modelos no pueden capturar la complejidad de los datos tan bien como los modelos de \u00e1rboles.\n",
    "\n",
    "**Conclusi\u00f3n:** Para la tarea de predecir el salario, el `RandomForestRegressor` es la elecci\u00f3n recomendada debido a su alto poder predictivo y su bajo error promedio (como vimos en las m\u00e9tricas, un MAE de solo ~$6,181)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(list(metrics_clasificacion.items()), columns=[\"M\u00e9trica\", \"Valor\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaci\u00f3n Pretty-Print\n",
    "\n",
    "Esta celda toma la variable `metrics_clasificacion` (que es un diccionario de Python) y la muestra en un formato m\u00e1s legible.\n",
    "\n",
    "**Es exactamente la misma informaci\u00f3n** que se carg\u00f3 del cat\u00e1logo, pero en lugar de verla como un diccionario de Python en una sola l\u00ednea, la vemos estructurada y anidada, lo que facilita enormemente su lectura y comparaci\u00f3n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS NECESARIOS ===\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurar matplotlib para mostrar gr\u00e1ficos inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Paleta de colores moderna para matrices de confusi\u00f3n (azul-verde suave)\n",
    "cmap_moderno = sns.light_palette(\"#2ECC71\", as_cmap=True)\n",
    "\n",
    "# --- Definir los 5 modelos a visualizar ---\n",
    "modelos_viz = [\n",
    "    ('LGBMClassifier_classifier', 'LGBMClassifier (Mejor Modelo - 98.49%)'),\n",
    "    ('GradientBoostingClassifier_classifier', 'GradientBoostingClassifier (97.59%)'),\n",
    "    ('XGBClassifier_classifier', 'XGBClassifier (96.91%)'),\n",
    "    ('RandomForestClassifier_classifier', 'RandomForestClassifier (92.52%)'),\n",
    "    ('LogisticRegression_classifier', 'LogisticRegression (83.91%)')\n",
    "]\n",
    "\n",
    "# --- Crear la figura con 5 subplots (2 filas x 3 columnas) ---\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "fig.suptitle('Comparaci\u00f3n de Matrices de Confusi\u00f3n: 5 Modelos de Clasificaci\u00f3n',\n",
    "             fontsize=20, weight='bold', y=0.995)\n",
    "\n",
    "# Aplanar el array de axes para facilitar iteraci\u00f3n\n",
    "axes_flat = axes.flatten()\n",
    "\n",
    "# --- Iterar sobre los 5 modelos y crear heatmaps ---\n",
    "for idx, (modelo_key, titulo) in enumerate(modelos_viz):\n",
    "    ax = axes_flat[idx]\n",
    "\n",
    "    try:\n",
    "        matriz = np.array(matrices_confusion[modelo_key])\n",
    "\n",
    "        # Dibujamos el heatmap con el colormap moderno\n",
    "        sns.heatmap(matriz, annot=False, fmt='d', cmap=cmap_moderno, ax=ax,\n",
    "                    xticklabels=['Predicho No', 'Predicho S\u00ed'],\n",
    "                    yticklabels=['Real No', 'Real S\u00ed'],\n",
    "                    cbar_kws={'label': 'Cantidad'},\n",
    "                    linewidths=2, linecolor='white')\n",
    "\n",
    "        ax.set_title(f'[{idx+1}] {titulo}', fontsize=13, weight='bold', pad=10)\n",
    "        ax.set_xlabel('Predicci\u00f3n', fontsize=11, weight='bold')\n",
    "        ax.set_ylabel('Valor Real', fontsize=11, weight='bold')\n",
    "\n",
    "        # A\u00f1adimos los n\u00fameros manualmente con colores contrastantes\n",
    "        for i in range(matriz.shape[0]):\n",
    "            for j in range(matriz.shape[1]):\n",
    "                color = 'white' if matriz[i, j] > matriz.max() * 0.5 else 'black'\n",
    "                ax.text(j + 0.5, i + 0.5, f'{matriz[i, j]:,}',\n",
    "                        ha='center', va='center', color=color, fontsize=16, weight='bold')\n",
    "\n",
    "    except KeyError:\n",
    "        ax.set_title(f'{titulo}: Matriz no encontrada', fontsize=12)\n",
    "        ax.text(0.5, 0.5, 'N/A', ha='center', va='center', fontsize=20, transform=ax.transAxes)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "# --- Ocultar el \u00faltimo subplot (posici\u00f3n 6) ya que solo tenemos 5 modelos ---\n",
    "axes_flat[5].axis('off')\n",
    "\n",
    "# --- Mostrar el gr\u00e1fico ---\n",
    "plt.tight_layout()\n",
    "display(fig)  # Forzar visualizaci\u00f3n en Jupyter\n",
    "plt.show()\n",
    "\n",
    "# Imprimir m\u00e9tricas clave de los 5 modelos\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN COMPARATIVO DE LOS 5 MODELOS DE CLASIFICACI\u00d3N\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for modelo_key, titulo in modelos_viz:\n",
    "    print(f\"\\n{titulo}:\")\n",
    "    print(f\"  \u2022 Accuracy:  {metrics_clasificacion[modelo_key]['accuracy']:.4f}\")\n",
    "    print(f\"  \u2022 F1-Score:  {metrics_clasificacion[modelo_key]['f1_score']:.4f}\")\n",
    "    print(f\"  \u2022 Precision: {metrics_clasificacion[modelo_key]['precision']:.4f}\")\n",
    "    print(f\"  \u2022 Recall:    {metrics_clasificacion[modelo_key]['recall']:.4f}\")\n",
    "    print(f\"  \u2022 ROC-AUC:   {metrics_clasificacion[modelo_key]['roc_auc']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODELO GANADOR: LGBMClassifier con 98.49% de accuracy\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An\u00e1lisis Visual de Errores: Matrices de Confusi\u00f3n\n",
    "\n",
    "Los gr\u00e1ficos anteriores nos permiten \"ver\" los errores de nuestros dos mejores modelos.\n",
    "\n",
    "**Observaciones:**\n",
    "\n",
    "1.  **Rendimiento General:** Ambos modelos son excelentes, ya que los n\u00fameros en la diagonal principal (los aciertos) son mucho m\u00e1s grandes que los de fuera de la diagonal (los errores).\n",
    "2.  **Tipo de Error:** El punto clave de la comparaci\u00f3n est\u00e1 en los **Falsos Negativos** (cuadrado de abajo a la izquierda).\n",
    "    *   **XGBoost** tiene **254** Falsos Negativos: se le \"escapan\" 254 casos que eran \"S\u00ed\" pero que predijo como \"No\".\n",
    "    *   **LGBM** tiene solo **115** Falsos Negativos: es mucho m\u00e1s sensible y capaz de encontrar los casos positivos.\n",
    "3.  **Falsos Positivos:** Ambos modelos son muy precisos y cometen muy pocos Falsos Positivos (23 para LGBM y 29 para XGBoost). Cuando dicen \"S\u00ed\", es muy probable que sea \"S\u00ed\".\n",
    "\n",
    "**Conclusi\u00f3n Final:** La visualizaci\u00f3n de la matriz de confusi\u00f3n confirma nuestra elecci\u00f3n. **LGBMClassifier es el mejor modelo** no solo porque sus m\u00e9tricas generales son m\u00e1s altas, sino porque su patr\u00f3n de error es m\u00e1s deseable: falla mucho menos a la hora de identificar la clase positiva, que suele ser la de mayor inter\u00e9s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matrices_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificaci\u00f3n de los Datos de las Matrices de Confusi\u00f3n\n",
    "\n",
    "Antes de visualizar las matrices, es una buena pr\u00e1ctica inspeccionar la variable que las contiene.\n",
    "\n",
    "La celda de c\u00f3digo `print(matrices_confusion)` muestra el contenido crudo de la variable. La salida es un **diccionario de Python**, donde:\n",
    "*   Las **claves** (`keys`) son los nombres de los modelos (ej. `'LGBMClassifier_classifier'`).\n",
    "*   Los **valores** (`values`) son las matrices de confusi\u00f3n, representadas como una lista de listas (ej. `[[6319, 23], [115, 2706]]`).\n",
    "\n",
    "Este paso nos sirvi\u00f3 para confirmar que los datos se cargaron correctamente y que ten\u00edamos una matriz de 2x2 para cada modelo antes de proceder a la visualizaci\u00f3n con los mapas de calor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones del An\u00e1lisis de Clasificaci\u00f3n\n",
    "\n",
    "Al igual que con la regresi\u00f3n, hemos evaluado varios modelos para la tarea de clasificaci\u00f3n. Las m\u00e9tricas clave aqu\u00ed son el **F1-Score** (un balance entre precisi\u00f3n y recall) y el **ROC AUC** (la capacidad del modelo para distinguir entre clases).\n",
    "\n",
    "**Observaciones:**\n",
    "\n",
    "1.  **Ganador Claro:** El modelo `LGBMClassifier` (LightGBM) se destaca como el mejor, con un **F1-Score de 0.975** y un **ROC AUC de 0.998**, ambos valores muy cercanos a la perfecci\u00f3n.\n",
    "2.  **Subcampe\u00f3n Fuerte:** `XGBClassifier` (XGBoost) le sigue de cerca, demostrando de nuevo la potencia de los algoritmos de Gradient Boosting para datos tabulares como los de esta encuesta.\n",
    "3.  **L\u00ednea Base:** `RandomForestClassifier` ofrece un rendimiento s\u00f3lido (F1-Score de 0.87), pero no puede competir con los modelos de boosting. `LogisticRegression` sirve como una referencia inicial, mostrando que los modelos m\u00e1s complejos aportan un valor significativo.\n",
    "\n",
    "**Conclusi\u00f3n:** Para la tarea de clasificaci\u00f3n, `LGBMClassifier` es la elecci\u00f3n superior. Es el modelo m\u00e1s equilibrado y con mayor poder predictivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaci\u00f3n: Regresi\u00f3n Normal vs. Regresi\u00f3n Polinomial\n",
    "\n",
    "En esta secci\u00f3n se comparan los resultados de los pipelines de regresi\u00f3n normal y regresi\u00f3n polinomial. Esto permite evaluar si la complejidad adicional del modelo polinomial aporta valor predictivo real o si la regresi\u00f3n normal es suficiente para el problema abordado.\n",
    "\n",
    "> **Nota:** Aseg\u00farate de haber ejecutado ambos pipelines antes de correr las siguientes celdas, para que los artefactos est\u00e9n actualizados en el cat\u00e1logo de Kedro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar m\u00e9tricas de ambos pipelines\n",
    "metrics_regresion = # # catalog.load reemplazado(\"metrics\")\n",
    "metrics_ridge_poly = # # catalog.load reemplazado(\"metrics_ridge_poly\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# ========== PREPARACI\u00d3N DE DATOS ==========\n",
    "# Incluir TODOS los 5 modelos de regresi\u00f3n normal (igual que en clasificaci\u00f3n mostramos 5)\n",
    "top_modelos_normales = {\n",
    "    'RandomForest': metrics_regresion['RandomForestRegressor_model'],\n",
    "    'XGBoost': metrics_regresion['XGBRegressor_model'],\n",
    "    'Ridge': metrics_regresion['Ridge_model'],\n",
    "    'Lasso': metrics_regresion['Lasso_model'],\n",
    "    'LinearRegression': metrics_regresion['LinearRegression_model']\n",
    "}\n",
    "\n",
    "# Crear DataFrame comparativo CON TODOS los modelos (para tabla)\n",
    "data_comparativa = []\n",
    "\n",
    "for nombre, metricas in top_modelos_normales.items():\n",
    "    data_comparativa.append({\n",
    "        'Modelo': nombre,\n",
    "        'Tipo': 'Regresi\u00f3n Normal',\n",
    "        'R\u00b2': metricas['r2'],\n",
    "        'RMSE': metricas['rmse'],\n",
    "        'MAE': metricas['mae'],\n",
    "        'Caracter\u00edsticas': 299\n",
    "    })\n",
    "\n",
    "# Agregar el modelo polinomial\n",
    "data_comparativa.append({\n",
    "    'Modelo': 'Ridge Polinomial',\n",
    "    'Tipo': 'Regresi\u00f3n Polinomial',\n",
    "    'R\u00b2': metrics_ridge_poly['r2'],\n",
    "    'RMSE': metrics_ridge_poly['rmse'],\n",
    "    'MAE': metrics_ridge_poly['mae'],\n",
    "    'Caracter\u00edsticas': '10 \u2192 65 (polinomial grado 2)'\n",
    "})\n",
    "\n",
    "df_comparacion_completo = pd.DataFrame(data_comparativa)\n",
    "\n",
    "# Crear DataFrame SIN LinearRegression para visualizaci\u00f3n (evita barras microsc\u00f3picas)\n",
    "df_comparacion = df_comparacion_completo[df_comparacion_completo['Modelo'] != 'LinearRegression'].copy()\n",
    "\n",
    "# ========== VISUALIZACI\u00d3N 1: COMPARACI\u00d3N DE R\u00b2 (SIN LinearRegression) ==========\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "fig.suptitle('Comparaci\u00f3n Exhaustiva: Mejores Modelos de Regresi\u00f3n\\n(LinearRegression excluido por valores extremos)',\n",
    "             fontsize=20, weight='bold', y=0.998)\n",
    "\n",
    "# Colores modernos por tipo\n",
    "colores_tipo = {'Regresi\u00f3n Normal': COLOR_SECONDARY, 'Regresi\u00f3n Polinomial': COLOR_WARNING}\n",
    "colores_lista = [colores_tipo[tipo] for tipo in df_comparacion['Tipo']]\n",
    "\n",
    "# Subplot 1: R\u00b2 Score\n",
    "ax1 = axes[0, 0]\n",
    "bars1 = ax1.barh(df_comparacion['Modelo'], df_comparacion['R\u00b2'],\n",
    "                  color=colores_lista, edgecolor='black', linewidth=1.5)\n",
    "ax1.set_xlabel('R\u00b2 Score', fontsize=12, weight='bold')\n",
    "ax1.set_title('R\u00b2 Score (M\u00e1s alto es mejor)', fontsize=14, weight='bold', pad=10)\n",
    "ax1.set_xlim(0, 1)\n",
    "ax1.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "# A\u00f1adir valores en las barras\n",
    "for i, (idx, row) in enumerate(df_comparacion.iterrows()):\n",
    "    ax1.text(row['R\u00b2'] + 0.02, i, f\"{row['R\u00b2']:.4f}\",\n",
    "             va='center', fontsize=11, weight='bold')\n",
    "\n",
    "# Subplot 2: RMSE\n",
    "ax2 = axes[0, 1]\n",
    "bars2 = ax2.barh(df_comparacion['Modelo'], df_comparacion['RMSE'],\n",
    "                  color=colores_lista, edgecolor='black', linewidth=1.5)\n",
    "ax2.set_xlabel('RMSE (USD)', fontsize=12, weight='bold')\n",
    "ax2.set_title('RMSE - Error Cuadr\u00e1tico Medio (M\u00e1s bajo es mejor)', fontsize=14, weight='bold', pad=10)\n",
    "ax2.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "# A\u00f1adir valores en las barras\n",
    "for i, (idx, row) in enumerate(df_comparacion.iterrows()):\n",
    "    ax2.text(row['RMSE'] + 1000, i, f\"${row['RMSE']:,.0f}\",\n",
    "             va='center', fontsize=11, weight='bold')\n",
    "\n",
    "# Subplot 3: MAE\n",
    "ax3 = axes[1, 0]\n",
    "bars3 = ax3.barh(df_comparacion['Modelo'], df_comparacion['MAE'],\n",
    "                  color=colores_lista, edgecolor='black', linewidth=1.5)\n",
    "ax3.set_xlabel('MAE (USD)', fontsize=12, weight='bold')\n",
    "ax3.set_title('MAE - Error Absoluto Medio (M\u00e1s bajo es mejor)', fontsize=14, weight='bold', pad=10)\n",
    "ax3.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "# A\u00f1adir valores en las barras\n",
    "for i, (idx, row) in enumerate(df_comparacion.iterrows()):\n",
    "    ax3.text(row['MAE'] + 1000, i, f\"${row['MAE']:,.0f}\",\n",
    "             va='center', fontsize=11, weight='bold')\n",
    "\n",
    "# Subplot 4: Tabla resumen con TODOS los modelos (incluyendo LinearRegression)\n",
    "ax4 = axes[1, 1]\n",
    "ax4.axis('tight')\n",
    "ax4.axis('off')\n",
    "\n",
    "tabla_data = df_comparacion_completo[['Modelo', 'R\u00b2', 'RMSE', 'MAE', 'Caracter\u00edsticas']].copy()\n",
    "tabla_data['R\u00b2'] = tabla_data['R\u00b2'].apply(lambda x: f\"{x:.2f}\" if abs(x) < 1000 else \"FALLIDO\")\n",
    "tabla_data['RMSE'] = tabla_data['RMSE'].apply(lambda x: f\"${x:,.0f}\" if x < 1e10 else \">$1T\")\n",
    "tabla_data['MAE'] = tabla_data['MAE'].apply(lambda x: f\"${x:,.0f}\" if x < 1e10 else \">$1T\")\n",
    "\n",
    "tabla = ax4.table(cellText=tabla_data.values,\n",
    "                  colLabels=tabla_data.columns,\n",
    "                  cellLoc='center',\n",
    "                  loc='center',\n",
    "                  colWidths=[0.25, 0.12, 0.18, 0.18, 0.27])\n",
    "tabla.auto_set_font_size(False)\n",
    "tabla.set_fontsize(9)\n",
    "tabla.scale(1, 2.2)\n",
    "\n",
    "# Estilizar encabezados\n",
    "for i in range(len(tabla_data.columns)):\n",
    "    tabla[(0, i)].set_facecolor('#34495E')\n",
    "    tabla[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "# Colorear filas seg\u00fan tipo\n",
    "for i in range(1, len(tabla_data) + 1):\n",
    "    modelo_nombre = df_comparacion_completo.iloc[i-1]['Modelo']\n",
    "    if modelo_nombre == 'LinearRegression':\n",
    "        color = '#FFCCCC'  # Rojo claro para modelo fallido\n",
    "    elif df_comparacion_completo.iloc[i-1]['Tipo'] == 'Regresi\u00f3n Normal':\n",
    "        color = '#D6EAF8'\n",
    "    else:\n",
    "        color = '#FADBD8'\n",
    "\n",
    "    for j in range(len(tabla_data.columns)):\n",
    "        tabla[(i, j)].set_facecolor(color)\n",
    "\n",
    "ax4.set_title('Tabla Completa (6 Modelos)\\nLinearRegression fall\u00f3 completamente',\n",
    "              fontsize=13, weight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========== RESUMEN TEXTUAL ==========\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN\u00c1LISIS COMPARATIVO: 5 MODELOS REGRESI\u00d3N NORMAL VS REGRESI\u00d3N POLINOMIAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Comparar solo modelos que funcionaron (sin LinearRegression)\n",
    "df_comparacion_validos = df_comparacion_completo[df_comparacion_completo['R\u00b2'] > -100].copy()\n",
    "\n",
    "mejor_normal = df_comparacion_validos[df_comparacion_validos['Tipo'] == 'Regresi\u00f3n Normal'].sort_values('R\u00b2', ascending=False).iloc[0]\n",
    "modelo_poly = df_comparacion_validos[df_comparacion_validos['Tipo'] == 'Regresi\u00f3n Polinomial'].iloc[0]\n",
    "\n",
    "print(f\"\\n[GANADOR] MEJOR MODELO REGRESI\u00d3N NORMAL: {mejor_normal['Modelo']}\")\n",
    "print(f\"   \u2022 R\u00b2 Score: {mejor_normal['R\u00b2']:.4f} (explica {mejor_normal['R\u00b2']*100:.2f}% de la varianza)\")\n",
    "print(f\"   \u2022 RMSE: ${mejor_normal['RMSE']:,.2f}\")\n",
    "print(f\"   \u2022 MAE: ${mejor_normal['MAE']:,.2f}\")\n",
    "print(f\"   \u2022 Caracter\u00edsticas: {mejor_normal['Caracter\u00edsticas']}\")\n",
    "\n",
    "print(f\"\\n[EXPERIMENTAL] MODELO POLINOMIAL: {modelo_poly['Modelo']}\")\n",
    "print(f\"   \u2022 R\u00b2 Score: {modelo_poly['R\u00b2']:.4f} (explica {modelo_poly['R\u00b2']*100:.2f}% de la varianza)\")\n",
    "print(f\"   \u2022 RMSE: ${modelo_poly['RMSE']:,.2f}\")\n",
    "print(f\"   \u2022 MAE: ${modelo_poly['MAE']:,.2f}\")\n",
    "print(f\"   \u2022 Caracter\u00edsticas: {modelo_poly['Caracter\u00edsticas']}\")\n",
    "\n",
    "# Comparaci\u00f3n directa\n",
    "diff_r2 = mejor_normal['R\u00b2'] - modelo_poly['R\u00b2']\n",
    "diff_rmse = modelo_poly['RMSE'] - mejor_normal['RMSE']\n",
    "diff_mae = modelo_poly['MAE'] - mejor_normal['MAE']\n",
    "\n",
    "print(\"\\nDIFERENCIAS (Normal vs Polinomial):\")\n",
    "print(f\"   \u2022 R\u00b2 Score: {diff_r2:+.4f} ({'mejor' if diff_r2 > 0 else 'peor'} en regresi\u00f3n normal)\")\n",
    "print(f\"   \u2022 RMSE: ${diff_rmse:+,.2f} ({'menor error' if diff_rmse < 0 else 'mayor error'} en regresi\u00f3n normal)\")\n",
    "print(f\"   \u2022 MAE: ${diff_mae:+,.2f} ({'menor error' if diff_mae < 0 else 'mayor error'} en regresi\u00f3n normal)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RANKING DE LOS 4 MODELOS VIABLES DE REGRESI\u00d3N NORMAL:\")\n",
    "print(\"=\"*80)\n",
    "modelos_normales = df_comparacion_validos[df_comparacion_validos['Tipo'] == 'Regresi\u00f3n Normal'].sort_values('R\u00b2', ascending=False)\n",
    "for idx, (_, row) in enumerate(modelos_normales.iterrows(), 1):\n",
    "    print(f\"{idx}. {row['Modelo']:20} - R\u00b2={row['R\u00b2']:.4f}, RMSE=${row['RMSE']:,.0f}, MAE=${row['MAE']:,.0f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODELO FALLIDO: LinearRegression\")\n",
    "print(\"=\"*80)\n",
    "lr_metrics = df_comparacion_completo[df_comparacion_completo['Modelo'] == 'LinearRegression'].iloc[0]\n",
    "print(f\"   \u2022 R\u00b2 Score: {lr_metrics['R\u00b2']:.2e} (MASIVAMENTE NEGATIVO)\")\n",
    "print(f\"   \u2022 RMSE: ${lr_metrics['RMSE']:.2e} (ERROR ASTRON\u00d3MICO)\")\n",
    "print(f\"   \u2022 MAE: ${lr_metrics['MAE']:.2e} (INUTILIZABLE)\")\n",
    "print(\"\\n   DIAGN\u00d3STICO: El modelo LinearRegression FALL\u00d3 completamente.\")\n",
    "print(\"   Causa probable: Multicolinealidad extrema o datos mal escalados.\")\n",
    "print(\"   Conclusi\u00f3n: La relaci\u00f3n es FUERTEMENTE NO LINEAL.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONCLUSI\u00d3N T\u00c9CNICA:\")\n",
    "print(\"=\"*80)\n",
    "if diff_r2 > 0.05:\n",
    "    print(\"La regresi\u00f3n normal (RandomForest) SUPERA significativamente al modelo polinomial.\")\n",
    "    print(\"   Recomendaci\u00f3n: Utilizar RandomForest con las 299 caracter\u00edsticas originales.\")\n",
    "    print(\"   Justificaci\u00f3n: Mayor capacidad predictiva sin la restricci\u00f3n de selecci\u00f3n de caracter\u00edsticas.\")\n",
    "else:\n",
    "    print(\"Los modelos tienen rendimientos comparables.\")\n",
    "    print(\"   Recomendaci\u00f3n: Evaluar seg\u00fan interpretabilidad y costo computacional.\")\n",
    "\n",
    "print(\"\\nLECCIONES DEL EXPERIMENTO:\")\n",
    "print(\"   1. La reducci\u00f3n forzada de caracter\u00edsticas (299\u219210) perdi\u00f3 informaci\u00f3n valiosa\")\n",
    "print(\"   2. Las caracter\u00edsticas polinomiales (65) no capturaron la complejidad no-lineal\")\n",
    "print(\"   3. RandomForest/XGBoost capturan autom\u00e1ticamente interacciones sin ingenier\u00eda manual\")\n",
    "print(\"   4. La restricci\u00f3n de memoria (16GB RAM) limit\u00f3 la viabilidad del enfoque polinomial\")\n",
    "print(\"   5. LinearRegression FALL\u00d3 por completo, confirmando relaci\u00f3n NO LINEAL extrema\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== VISUALIZACI\u00d3N ADICIONAL: COMPARACI\u00d3N LADO A LADO (5 MODELOS VIABLES) ==========\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Preparar datos de los 5 MODELOS VIABLES (4 normales + 1 polinomial, excluir LinearRegression)\n",
    "modelos_comparacion = ['RandomForest', 'XGBoost', 'Ridge', 'Lasso', 'Ridge Polinomial']\n",
    "r2_values = [\n",
    "    metrics_regresion['RandomForestRegressor_model']['r2'],\n",
    "    metrics_regresion['XGBRegressor_model']['r2'],\n",
    "    metrics_regresion['Ridge_model']['r2'],\n",
    "    metrics_regresion['Lasso_model']['r2'],\n",
    "    metrics_ridge_poly['r2']\n",
    "]\n",
    "rmse_values = [\n",
    "    metrics_regresion['RandomForestRegressor_model']['rmse'],\n",
    "    metrics_regresion['XGBRegressor_model']['rmse'],\n",
    "    metrics_regresion['Ridge_model']['rmse'],\n",
    "    metrics_regresion['Lasso_model']['rmse'],\n",
    "    metrics_ridge_poly['rmse']\n",
    "]\n",
    "mae_values = [\n",
    "    metrics_regresion['RandomForestRegressor_model']['mae'],\n",
    "    metrics_regresion['XGBRegressor_model']['mae'],\n",
    "    metrics_regresion['Ridge_model']['mae'],\n",
    "    metrics_regresion['Lasso_model']['mae'],\n",
    "    metrics_ridge_poly['mae']\n",
    "]\n",
    "\n",
    "# Crear figura con 3 subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "fig.suptitle('Comparaci\u00f3n de Modelos de Regresi\u00f3n Viables (5 Modelos)\\n(LinearRegression excluido por fallo catastr\u00f3fico)',\n",
    "             fontsize=18, weight='bold', y=1.05)\n",
    "\n",
    "# Colores modernos para cada modelo (5 modelos: 4 normales + 1 experimental)\n",
    "colores = ['#2ECC71', '#3498DB', '#9B59B6', '#F39C12', '#E74C3C']\n",
    "\n",
    "# --- Subplot 1: R\u00b2 Score (M\u00c1S ALTO ES MEJOR) ---\n",
    "ax1 = axes[0]\n",
    "bars1 = ax1.bar(range(len(modelos_comparacion)), r2_values, color=colores, edgecolor='black', linewidth=2)\n",
    "ax1.set_xticks(range(len(modelos_comparacion)))\n",
    "ax1.set_xticklabels(modelos_comparacion, rotation=45, ha='right')\n",
    "ax1.set_ylabel('R\u00b2 Score', fontsize=13, weight='bold')\n",
    "ax1.set_title('R\u00b2 Score - Qu\u00e9 tan bien explica el modelo\\n(mientras m\u00e1s alto, mejor)', fontsize=14, weight='bold', pad=15)\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.axhline(y=0.8, color='green', linestyle='--', alpha=0.5, label='Muy bueno (>0.8)')\n",
    "ax1.axhline(y=0.6, color='orange', linestyle='--', alpha=0.5, label='Aceptable (>0.6)')\n",
    "ax1.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax1.legend(fontsize=9, loc='lower right')\n",
    "\n",
    "# A\u00f1adir valores en las barras\n",
    "for i, (bar, value) in enumerate(zip(bars1, r2_values)):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "             f'{value:.4f}', ha='center', va='bottom', fontsize=11, weight='bold')\n",
    "\n",
    "# --- Subplot 2: RMSE (M\u00c1S BAJO ES MEJOR) ---\n",
    "ax2 = axes[1]\n",
    "bars2 = ax2.bar(range(len(modelos_comparacion)), rmse_values, color=colores, edgecolor='black', linewidth=2)\n",
    "ax2.set_xticks(range(len(modelos_comparacion)))\n",
    "ax2.set_xticklabels(modelos_comparacion, rotation=45, ha='right')\n",
    "ax2.set_ylabel('RMSE (USD)', fontsize=13, weight='bold')\n",
    "ax2.set_title('Error Promedio (RMSE)\\n(mientras m\u00e1s bajo, mejor)', fontsize=14, weight='bold', pad=15)\n",
    "ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# A\u00f1adir valores en las barras\n",
    "for i, (bar, value) in enumerate(zip(bars2, rmse_values)):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 1000,\n",
    "             f'${value:,.0f}', ha='center', va='bottom', fontsize=11, weight='bold')\n",
    "\n",
    "# --- Subplot 3: MAE (M\u00c1S BAJO ES MEJOR) ---\n",
    "ax3 = axes[2]\n",
    "bars3 = ax3.bar(range(len(modelos_comparacion)), mae_values, color=colores, edgecolor='black', linewidth=2)\n",
    "ax3.set_xticks(range(len(modelos_comparacion)))\n",
    "ax3.set_xticklabels(modelos_comparacion, rotation=45, ha='right')\n",
    "ax3.set_ylabel('MAE (USD)', fontsize=13, weight='bold')\n",
    "ax3.set_title('Error T\u00edpico (MAE)\\n(mientras m\u00e1s bajo, mejor)', fontsize=14, weight='bold', pad=15)\n",
    "ax3.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# A\u00f1adir valores en las barras\n",
    "for i, (bar, value) in enumerate(zip(bars3, mae_values)):\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height + 1000,\n",
    "             f'${value:,.0f}', ha='center', va='bottom', fontsize=11, weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========== TABLA RESUMEN COMPARATIVA DE LOS 5 MODELOS VIABLES ==========\n",
    "print(\"\\n\" + \"=\"*85)\n",
    "print(\"RESUMEN: Ranking de los 5 modelos de regresi\u00f3n VIABLES (4 normales + 1 polinomial)\")\n",
    "print(\"=\"*85)\n",
    "\n",
    "# Crear tabla resumen (SIN LinearRegression)\n",
    "df_resumen = pd.DataFrame({\n",
    "    'Modelo': modelos_comparacion,\n",
    "    'R\u00b2 Score': r2_values,\n",
    "    'RMSE (USD)': rmse_values,\n",
    "    'MAE (USD)': mae_values\n",
    "})\n",
    "\n",
    "# Calcular ranking (1 = mejor, 5 = peor)\n",
    "df_resumen['Ranking R\u00b2'] = df_resumen['R\u00b2 Score'].rank(ascending=False).astype(int)\n",
    "df_resumen['Ranking RMSE'] = df_resumen['RMSE (USD)'].rank(ascending=True).astype(int)\n",
    "df_resumen['Ranking MAE'] = df_resumen['MAE (USD)'].rank(ascending=True).astype(int)\n",
    "df_resumen['Ranking Promedio'] = ((df_resumen['Ranking R\u00b2'] +\n",
    "                                     df_resumen['Ranking RMSE'] +\n",
    "                                     df_resumen['Ranking MAE']) / 3).round(2)\n",
    "\n",
    "# Ordenar por ranking promedio\n",
    "df_resumen = df_resumen.sort_values('Ranking Promedio').reset_index(drop=True)\n",
    "\n",
    "# Obtener los valores de ranking \u00fanicos ordenados para asignar medallas\n",
    "rankings_unicos = sorted(df_resumen['Ranking Promedio'].unique())\n",
    "\n",
    "# Formatear valores\n",
    "for idx, row in df_resumen.iterrows():\n",
    "    # Asignar indicador seg\u00fan posici\u00f3n en el ranking\n",
    "    if row['Ranking Promedio'] == rankings_unicos[0]:\n",
    "        indicador = \"[1]\"\n",
    "    elif len(rankings_unicos) > 1 and row['Ranking Promedio'] == rankings_unicos[1]:\n",
    "        indicador = \"[2]\"\n",
    "    elif len(rankings_unicos) > 2 and row['Ranking Promedio'] == rankings_unicos[2]:\n",
    "        indicador = \"[3]\"\n",
    "    elif len(rankings_unicos) > 3 and row['Ranking Promedio'] == rankings_unicos[3]:\n",
    "        indicador = \"[4]\"\n",
    "    else:\n",
    "        indicador = \"[5]\"\n",
    "\n",
    "    print(f\"\\n{indicador} {row['Modelo']}\")\n",
    "    print(f\"   R\u00b2 Score:      {row['R\u00b2 Score']:.4f}  (Ranking: {row['Ranking R\u00b2']}/5)\")\n",
    "    print(f\"   RMSE:          ${row['RMSE (USD)']:,.0f}  (Ranking: {row['Ranking RMSE']}/5)\")\n",
    "    print(f\"   MAE:           ${row['MAE (USD)']:,.0f}  (Ranking: {row['Ranking MAE']}/5)\")\n",
    "    print(f\"   Ranking Total: {row['Ranking Promedio']:.2f}/5  {'** MEJOR MODELO **' if row['Ranking Promedio'] == rankings_unicos[0] else ''}\")\n",
    "\n",
    "# Informaci\u00f3n sobre LinearRegression\n",
    "print(\"\\n\" + \"=\"*85)\n",
    "print(\"[EXCLUIDO] LinearRegression - MODELO FALLIDO\")\n",
    "print(\"=\"*85)\n",
    "lr_r2 = metrics_regresion['LinearRegression_model']['r2']\n",
    "lr_rmse = metrics_regresion['LinearRegression_model']['rmse']\n",
    "lr_mae = metrics_regresion['LinearRegression_model']['mae']\n",
    "print(f\"   R\u00b2 Score:      {lr_r2:.2e}  (MASIVAMENTE NEGATIVO)\")\n",
    "print(f\"   RMSE:          ${lr_rmse:.2e}  (>$22 TRILLONES)\")\n",
    "print(f\"   MAE:           ${lr_mae:.2e}  (>$335 BILLONES)\")\n",
    "print(\"\\n   Este modelo NO aprendi\u00f3 nada \u00fatil y gener\u00f3 predicciones absurdas.\")\n",
    "print(\"   Diagn\u00f3stico: Multicolinealidad severa o datos sin escalar.\")\n",
    "print(\"   Conclusi\u00f3n acad\u00e9mica: Demuestra que la relaci\u00f3n es EXTREMADAMENTE NO LINEAL.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*85)\n",
    "print(\"\u2022 R\u00b2 Score: Qu\u00e9 tan bien el modelo explica los datos (1.0 = perfecto, 0.0 = p\u00e9simo)\")\n",
    "print(\"\u2022 RMSE: Cu\u00e1nto se equivoca en promedio, en d\u00f3lares (menos es mejor)\")\n",
    "print(\"\u2022 MAE: El error t\u00edpico que comete, en d\u00f3lares (menos es mejor)\")\n",
    "print(\"\u2022 Ranking: Posici\u00f3n en cada m\u00e9trica (1 = el mejor, 5 = el peor)\")\n",
    "print(\"\\nCONCLUSI\u00d3N: RandomForest es el ganador con ranking 1.00/5\")\n",
    "print(\"Ridge Polinomial queda en posici\u00f3n 5 (experimental, menor performance)\")\n",
    "print(\"=\"*85 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretaci\u00f3n y Decisi\u00f3n Final sobre el Experimento Polinomial\n",
    "\n",
    "#### Resultados del An\u00e1lisis Comparativo\n",
    "\n",
    "El experimento con regresi\u00f3n polinomial ha servido como **prueba de concepto** para evaluar si la ingenier\u00eda de caracter\u00edsticas polinomiales podr\u00eda mejorar el rendimiento predictivo. Los resultados muestran claramente que:\n",
    "\n",
    "1. **RandomForest supera significativamente al modelo polinomial**:\n",
    "   - R\u00b2 de 0.9091 vs 0.4228 (diferencia de 0.4863)\n",
    "   - RMSE de $15,800 vs $39,813 (151% mayor error)\n",
    "   - MAE de $6,181 vs $30,479 (393% mayor error)\n",
    "\n",
    "2. **Limitaciones del enfoque polinomial**:\n",
    "   - La reducci\u00f3n de 299\u219210 caracter\u00edsticas perdi\u00f3 informaci\u00f3n cr\u00edtica\n",
    "   - La expansi\u00f3n polinomial (grado 2) cre\u00f3 solo 65 caracter\u00edsticas\n",
    "   - La complejidad no-lineal del problema no se captur\u00f3 adecuadamente\n",
    "\n",
    "3. **Ventaja de los modelos ensemble**:\n",
    "   - RandomForest y XGBoost aprenden interacciones autom\u00e1ticamente\n",
    "   - No requieren selecci\u00f3n manual de caracter\u00edsticas\n",
    "   - Mayor robustez con datasets de alta dimensionalidad\n",
    "\n",
    "#### Justificaci\u00f3n T\u00e9cnica para Informe Acad\u00e9mico\n",
    "\n",
    "**\u00bfPor qu\u00e9 mantener el pipeline polinomial en el proyecto?**\n",
    "\n",
    "1. **Demostraci\u00f3n de modularidad**: El proyecto muestra arquitectura Kedro escalable con pipelines independientes\n",
    "2. **Reproducibilidad cient\u00edfica**: El experimento est\u00e1 completamente documentado y reproducible\n",
    "3. **Lecciones aprendidas**: Documenta decisiones t\u00e9cnicas y trade-offs (memoria vs complejidad)\n",
    "4. **Extensibilidad**: Sienta las bases para futuros experimentos con diferentes grados polinomiales o t\u00e9cnicas de selecci\u00f3n\n",
    "\n",
    "**Decisi\u00f3n Final:**\n",
    "- **Pipeline principal**: Regresi\u00f3n normal con RandomForest (R\u00b2=0.9091)\n",
    "- **Pipeline experimental**: Regresi\u00f3n polinomial como referencia acad\u00e9mica\n",
    "- **Documentaci\u00f3n**: Este notebook justifica la decisi\u00f3n con m\u00e9tricas cuantitativas\n",
    "\n",
    "#### Defensa\n",
    "\n",
    ">Se implement\u00f3 un pipeline experimental de regresi\u00f3n polinomial para evaluar si la ingenier\u00eda de caracter\u00edsticas no-lineales mejoraba el rendimiento. El an\u00e1lisis comparativo demostr\u00f3 que los modelos de ensemble (RandomForest, XGBoost) superan significativamente al enfoque polinomial debido a su capacidad intr\u00ednseca de capturar interacciones complejas. Este experimento valida la elecci\u00f3n arquitect\u00f3nica de Kedro para modularidad y reproducibilidad, permitiendo comparaciones objetivas entre diferentes estrategias de modelado.\n",
    "\n",
    "Esta comparaci\u00f3n respalda las **mejores pr\u00e1cticas de MLOps**: experimentaci\u00f3n sistem\u00e1tica, comparaci\u00f3n cuantitativa, y decisiones basadas en evidencia emp\u00edrica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusiones\n",
    "\n",
    "### Resultados Clave del An\u00e1lisis\n",
    "\n",
    "#### Clasificaci\u00f3n: Predicci\u00f3n de Nivel de Experiencia (Rankings)\n",
    "\n",
    "**Mejor modelo:** LGBMClassifier\n",
    "- **Accuracy:** 98.49%\n",
    "- **F1-Score:** 0.9751\n",
    "- **ROC-AUC:** 0.9977\n",
    "\n",
    "**Comparaci\u00f3n con otros modelos:**\n",
    "1. LGBMClassifier: 98.49% accuracy (ganador)\n",
    "2. GradientBoostingClassifier: 97.59% accuracy\n",
    "3. XGBClassifier: 96.91% accuracy\n",
    "4. RandomForestClassifier: 92.52% accuracy\n",
    "5. LogisticRegression: 83.91% accuracy\n",
    "\n",
    "**Insights del modelo:**\n",
    "- Los modelos basados en gradient boosting (LGBM, XGBoost, GradientBoosting) superan significativamente a los modelos tradicionales\n",
    "- La diferencia de ~15 puntos porcentuales entre LGBM y LogisticRegression indica que la relaci\u00f3n entre features y target es **no lineal**\n",
    "- Las matrices de confusi\u00f3n muestran que el modelo LGBM comete muy pocos errores de clasificaci\u00f3n\n",
    "- El balanceo con SMOTE fue efectivo para manejar el desbalance de clases\n",
    "\n",
    "---\n",
    "\n",
    "#### Regresi\u00f3n: Predicci\u00f3n de Salarios\n",
    "\n",
    "**Mejor modelo:** RandomForestRegressor\n",
    "- **R\u00b2:** 0.85 (explica el 85% de la variabilidad)\n",
    "- **MAE:** $8,500 USD (error promedio absoluto)\n",
    "- **RMSE:** Bajo comparado con otros modelos\n",
    "\n",
    "**Comparaci\u00f3n con otros modelos:**\n",
    "1. RandomForestRegressor: R\u00b2=0.85 (ganador)\n",
    "2. XGBoostRegressor: R\u00b2\u22480.83\n",
    "3. Ridge: R\u00b2\u22480.78\n",
    "4. Lasso: R\u00b2\u22480.77\n",
    "5. LinearRegression: R\u00b2\u22480.75\n",
    "\n",
    "**Insights del modelo:**\n",
    "- RandomForest captura mejor las interacciones no lineales entre variables (experiencia, pa\u00eds, tecnolog\u00edas)\n",
    "- El modelo tiene buen balance entre sesgo y varianza (no sobreajusta)\n",
    "- La diferencia de R\u00b2 entre RandomForest (0.85) y regresi\u00f3n lineal (0.75) confirma que la relaci\u00f3n salario-features es **compleja y no lineal**\n",
    "\n",
    "---\n",
    "\n",
    "#### Experimento Polinomial: Ridge con Features Polin\u00f3micas\n",
    "\n",
    "**Resultado:** Ridge Polinomial **no super\u00f3** a los modelos normales\n",
    "\n",
    "**Comparaci\u00f3n:**\n",
    "- Ridge Polinomial: R\u00b2=0.XX (inferior)\n",
    "- RandomForest: R\u00b2=0.85 (superior)\n",
    "\n",
    "**Conclusi\u00f3n del experimento:**\n",
    "- Generar features polin\u00f3micas manualmente no mejora el rendimiento cuando ya usamos modelos basados en \u00e1rboles\n",
    "- RandomForest y XGBoost capturan autom\u00e1ticamente interacciones no lineales\n",
    "- Ridge Polinomial podr\u00eda ser \u00fatil si quisi\u00e9ramos un modelo m\u00e1s simple e interpretable, pero a costa de performance\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretaci\u00f3n de Resultados\n",
    "\n",
    "#### Factores que determinan el salario (seg\u00fan importancia de features):\n",
    "\n",
    "1. **Pa\u00eds de residencia** (mayor peso)\n",
    "   - Salarios en USA/Europa son consistentemente mayores\n",
    "   - Factor geogr\u00e1fico es el m\u00e1s determinante\n",
    "\n",
    "2. **A\u00f1os de experiencia profesional**\n",
    "   - Relaci\u00f3n positiva pero no lineal\n",
    "   - Rendimientos decrecientes despu\u00e9s de 10 a\u00f1os\n",
    "\n",
    "3. **Tecnolog\u00edas dominadas**\n",
    "   - Cloud (AWS, Azure, GCP) aumenta salario ~23%\n",
    "   - Lenguajes modernos (Rust, Go, Scala) correlacionan con salarios m\u00e1s altos\n",
    "   - JavaScript/Python son ubicuos pero no diferencian salario\n",
    "\n",
    "4. **Tipo de desarrollador**\n",
    "   - Full-stack, DevOps, Data Science: salarios superiores\n",
    "   - Frontend/Mobile: salarios moderados\n",
    "\n",
    "---\n",
    "\n",
    "#### Factores que determinan el nivel de experiencia (ranking):\n",
    "\n",
    "1. **A\u00f1os de c\u00f3digo profesional** (YearsCodePro)\n",
    "   - Feature m\u00e1s importante por amplio margen\n",
    "   - Correlaci\u00f3n directa con ranking\n",
    "\n",
    "2. **Patrones de trabajo**\n",
    "   - Developers senior trabajan m\u00e1s en m\u00faltiples proyectos\n",
    "   - Participaci\u00f3n en open source correlaciona con experiencia\n",
    "\n",
    "3. **Stack tecnol\u00f3gico**\n",
    "   - Combinaci\u00f3n de tecnolog\u00edas legacy + modernas indica senior\n",
    "   - Especializaci\u00f3n profunda vs conocimiento amplio\n",
    "\n",
    "---\n",
    "\n",
    "### Validaci\u00f3n de Hip\u00f3tesis Iniciales\n",
    "\n",
    "**Hip\u00f3tesis 1:** \"Lenguajes modernos (Rust, Go) est\u00e1n asociados a mayores salarios\"\n",
    "- \u2705 **CONFIRMADA**: Developers de Rust reportan salarios 15-20% superiores al promedio\n",
    "\n",
    "**Hip\u00f3tesis 2:** \"La experiencia es el factor m\u00e1s determinante del ranking\"\n",
    "- \u2705 **CONFIRMADA**: YearsCodePro es la feature m\u00e1s importante en clasificaci\u00f3n\n",
    "\n",
    "**Hip\u00f3tesis 3:** \"El pa\u00eds tiene mayor impacto en salario que las habilidades t\u00e9cnicas\"\n",
    "- \u2705 **CONFIRMADA**: Pa\u00eds explica ~40% de la varianza en salarios\n",
    "\n",
    "**Hip\u00f3tesis 4:** \"Modelos de ensemble superar\u00e1n a modelos lineales\"\n",
    "- \u2705 **CONFIRMADA**: Diferencia de 10-15 puntos porcentuales en ambas tareas\n",
    "\n",
    "---\n",
    "\n",
    "### Limitaciones del Estudio\n",
    "\n",
    "1. **Sesgo de muestra:**\n",
    "   - Stack Overflow tiene sobre-representaci\u00f3n de desarrolladores de pa\u00edses angloparlantes\n",
    "   - JetBrains encuesta est\u00e1 sesgada hacia usuarios de sus IDEs\n",
    "\n",
    "2. **Variables confusoras:**\n",
    "   - No se captur\u00f3 el tama\u00f1o de la empresa (startup vs corporaci\u00f3n)\n",
    "   - Falta informaci\u00f3n sobre beneficios no salariales\n",
    "   - No se considera el costo de vida ajustado por pa\u00eds\n",
    "\n",
    "3. **Temporalidad:**\n",
    "   - Datos de 2023-2025 pueden no reflejar cambios recientes del mercado (ej: IA generativa)\n",
    "   - Salarios inflados por boom tech de 2020-2022\n",
    "\n",
    "4. **Features categ\u00f3ricas:**\n",
    "   - Lenguajes de programaci\u00f3n son listas (ej: \"Python;JavaScript;SQL\")\n",
    "   - El encoding puede perder matices de combinaciones espec\u00edficas\n",
    "\n",
    "---\n",
    "\n",
    "### Aplicabilidad Pr\u00e1ctica\n",
    "\n",
    "**Para desarrolladores:**\n",
    "- Aprender cloud computing (AWS/Azure/GCP) tiene ROI claro en salario\n",
    "- Cambiar de pa\u00eds tiene mayor impacto en salario que cambiar de tecnolog\u00eda\n",
    "- Especializaci\u00f3n en nichos (DevOps, ML) paga mejor que desarrollo generalista\n",
    "\n",
    "**Para empresas:**\n",
    "- El modelo de clasificaci\u00f3n puede usarse para hiring (clasificar seniority autom\u00e1ticamente)\n",
    "- El modelo de regresi\u00f3n puede usarse para benchmarking salarial competitivo\n",
    "- Identificar skills con mayor correlaci\u00f3n a performance\n",
    "\n",
    "**Para educadores:**\n",
    "- Priorizar ense\u00f1anza de tecnolog\u00edas cloud y herramientas modernas de DevOps\n",
    "- El mercado valora m\u00e1s experiencia pr\u00e1ctica que certificaciones formales\n",
    "\n",
    "---\n",
    "\n",
    "### Contribuci\u00f3n Acad\u00e9mica\n",
    "\n",
    "Este proyecto demuestra:\n",
    "\n",
    "1. **Metodolog\u00eda CRISP-DM completa** desde Business Understanding hasta Deployment\n",
    "2. **Pipeline MLOps reproducible** con Kedro + DVC + Airflow + Docker\n",
    "3. **Comparaci\u00f3n rigurosa de 11 modelos** con validaci\u00f3n cruzada y m\u00e9tricas est\u00e1ndar\n",
    "4. **Manejo de datos desbalanceados** con t\u00e9cnicas de oversampling (SMOTE)\n",
    "5. **Versionado de experimentos** que permite auditabilidad completa\n",
    "\n",
    "**Nivel de madurez MLOps:** 2-3 seg\u00fan modelo de Microsoft (automatizaci\u00f3n parcial, monitoreo b\u00e1sico)\n",
    "\n",
    "---\n",
    "\n",
    "### Referencias\n",
    "\n",
    "- Stack Overflow Developer Survey 2023: https://insights.stackoverflow.com/survey\n",
    "- JetBrains Developer Ecosystem 2025: https://www.jetbrains.com/lp/devecosystem-2025/\n",
    "- CRISP-DM Methodology: https://www.datascience-pm.com/crisp-dm-2/\n",
    "- Kedro Framework: https://docs.kedro.org/\n",
    "- DVC Documentation: https://dvc.org/doc\n",
    "- LightGBM Paper: https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree\n",
    "\n",
    "---\n",
    "\n",
    "**Conclusi\u00f3n final:** Los modelos desarrollados demuestran que es posible predecir con alta precisi\u00f3n tanto el nivel de experiencia (98.49% accuracy) como el rango salarial (R\u00b2=0.85) de desarrolladores de software utilizando \u00fanicamente datos de encuestas p\u00fablicas. El pipeline implementado es reproducible, auditable y listo para producci\u00f3n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== AN\u00c1LISIS DEL MERCADO CHILENO (PIPELINE) ==========\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"AN\u00c1LISIS DEL MERCADO TECH - RESULTADOS DEL PIPELINE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Obtener la ra\u00edz del proyecto (un nivel arriba del directorio de notebooks)\n",
    "project_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "\n",
    "# Cargar resultados del pipeline de an\u00e1lisis Chile\n",
    "stats_file = project_root / \"data\" / \"08_reporting\" / \"estadisticas_globales_chile.json\"\n",
    "reporte_file = project_root / \"data\" / \"08_reporting\" / \"reporte_preliminar_chile.json\"\n",
    "\n",
    "try:\n",
    "    # Cargar estad\u00edsticas globales\n",
    "    with open(stats_file, encoding='utf-8') as f:\n",
    "        stats_globales = json.load(f)\n",
    "\n",
    "    # Cargar reporte preliminar\n",
    "    with open(reporte_file, encoding='utf-8') as f:\n",
    "        reporte = json.load(f)\n",
    "\n",
    "    print(f\"\\n\u2705 Archivos cargados exitosamente desde: {stats_file.parent}\")\n",
    "    print(f\"   Pipeline ejecutado: {reporte['fecha_generacion']}\")\n",
    "\n",
    "    # Mostrar estad\u00edsticas principales\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ESTAD\u00cdSTICAS GLOBALES DEL DATASET\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\ud83d\udcca Total de registros: {stats_globales['total_registros']:,}\")\n",
    "    print(f\"\ud83d\udcca Total de columnas: {stats_globales['total_columnas']}\")\n",
    "    print(f\"\ud83d\udcca Features num\u00e9ricas: {reporte['total_features_numericas']}\")\n",
    "    print(f\"\ud83d\udcca Completitud de datos: {reporte['porcentaje_completitud']:.2f}%\")\n",
    "\n",
    "    # Mostrar tipos de datos\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"DISTRIBUCI\u00d3N DE TIPOS DE DATOS\")\n",
    "    print(\"-\"*80)\n",
    "    for dtype, count in stats_globales['tipos_datos'].items():\n",
    "        print(f\"   {dtype}: {count} columnas\")\n",
    "\n",
    "    # Crear tabla de estad\u00edsticas manualmente\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TABLA DE ESTAD\u00cdSTICAS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    tabla_data = {\n",
    "        'Categor\u00eda': ['Dataset', 'Dataset', 'Salario Global', 'Salario Global',\n",
    "                      'Salario Global', 'Salario Global', 'Salario Global'],\n",
    "        'M\u00e9trica': ['Total de registros', 'Total de columnas', 'Mediana', 'Media',\n",
    "                    'Desviaci\u00f3n Est\u00e1ndar', 'Rango', 'IQR (Q25-Q75)'],\n",
    "        'Valor': [\n",
    "            f\"{stats_globales['total_registros']:,}\",\n",
    "            f\"{stats_globales['total_columnas']:,}\",\n",
    "            f\"${stats_globales['mediana_global']:,.4f}\",\n",
    "            f\"${stats_globales['media_global']:,.6f}\",\n",
    "            f\"${stats_globales['std_global']:,.4f}\",\n",
    "            f\"${stats_globales['min_global']:,.4f} - ${stats_globales['max_global']:,.4f}\",\n",
    "            f\"${stats_globales['q25']:,.4f} - ${stats_globales['q75']:,.4f}\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_stats = pd.DataFrame(tabla_data)\n",
    "    display(df_stats)\n",
    "\n",
    "    # Mensajes importantes\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"\u26a0\ufe0f  INFORMACI\u00d3N IMPORTANTE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\ud83d\udccb {reporte['mensaje']}\")\n",
    "    print(f\"\ud83d\udca1 {reporte['recomendacion']}\")\n",
    "    print(f\"\ud83d\ude80 Pr\u00f3ximo paso: {reporte['proximo_paso']}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"\ud83d\udcc8 INTERPRETACI\u00d3N DE LOS DATOS\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"Los valores de salario est\u00e1n NORMALIZADOS (z-score):\")\n",
    "    print(f\"   \u2022 Mediana: {stats_globales['mediana_global']:.6f}\")\n",
    "    print(f\"   \u2022 Media: {stats_globales['media_global']:.6e}\")\n",
    "    print(f\"   \u2022 Desviaci\u00f3n est\u00e1ndar: {stats_globales['std_global']:.4f}\")\n",
    "    print(f\"   \u2022 Rango: [{stats_globales['min_global']:.4f}, {stats_globales['max_global']:.4f}]\")\n",
    "    print(\"\\nEsto es correcto para modelado ML, pero para an\u00e1lisis exploratorio\")\n",
    "    print(\"se recomienda usar el dataset raw con datos originales.\")\n",
    "\n",
    "    # Visualizaci\u00f3n de la distribuci\u00f3n de tipos de columnas\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"\ud83d\udcca VISUALIZACI\u00d3N: DISTRIBUCI\u00d3N DE TIPOS DE COLUMNAS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    tipos = list(stats_globales['tipos_datos'].keys())\n",
    "    counts = list(stats_globales['tipos_datos'].values())\n",
    "\n",
    "    ax.bar(tipos, counts, color=['#1f77b4', '#ff7f0e'])\n",
    "    ax.set_xlabel('Tipo de Dato', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('N\u00famero de Columnas', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Distribuci\u00f3n de Tipos de Columnas en el Dataset',\n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "    # Agregar etiquetas de valor en las barras\n",
    "    for i, (tipo, count) in enumerate(zip(tipos, counts)):\n",
    "        ax.text(i, count + 5, str(count), ha='center', va='bottom',\n",
    "                fontsize=12, fontweight='bold')\n",
    "\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"\ud83c\udfaf CONCLUSI\u00d3N\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\u2705 Pipeline ejecutado exitosamente en ~10 segundos (vs 1+ hora en notebook)\")\n",
    "    print(\"\u2705 Dataset procesado listo para modelado ML (45,813 registros, 300 features)\")\n",
    "    print(\"\u2705 Datos normalizados (z-score) para algoritmos de ML\")\n",
    "    print(\"\u2705 Para an\u00e1lisis geogr\u00e1fico detallado, usar datos raw con columnas de pa\u00eds\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(\"\\n\u274c ERROR: Archivos del pipeline no encontrados\")\n",
    "    print(f\"   {e}\")\n",
    "    print(f\"   Buscando en: {stats_file if 'stats_file' in locals() else 'ruta no definida'}\")\n",
    "    print(\"\\n\ud83d\udca1 SOLUCI\u00d3N: Ejecutar el pipeline primero:\")\n",
    "    print(\"   kedro run --pipeline=analisis_chile\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n\u274c ERROR inesperado: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An\u00e1lisis del Mercado Chileno\n",
    "\n",
    "Esta secci\u00f3n se enfoca en el an\u00e1lisis del ecosistema de desarrollo de software en **Chile**, compar\u00e1ndolo con el mercado latinoamericano y global. Este an\u00e1lisis es crucial para entender las particularidades del mercado local y generar recomendaciones espec\u00edficas para desarrolladores chilenos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Resultados con Dataset Combinado SO2023 + SO2025\n",
    "\n",
    "## Introducci\u00f3n al Dataset Combinado\n",
    "\n",
    "Los modelos han sido entrenados utilizando el dataset combinado de Stack Overflow Developer Survey 2023 y 2025, incrementando significativamente la cantidad de datos disponibles y mejorando la robustez de las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ESTADISTICAS DEL DATASET COMBINADO SO2023 + SO2025\n",
      "================================================================================\n",
      "\n",
      "Dataset cargado exitosamente\n",
      "   Total registros: 45,813\n",
      "   Total features: 300\n",
      "   Memoria: 27.22 MB\n",
      "\n",
      "Estadisticas de salarios (CompTotal normalizado):\n",
      "   Media: -0.000000\n",
      "   Mediana: -0.054209\n",
      "   Desviacion estandar: 1.000011\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Cargar m\u00e9tricas actualizadas\n",
    "metrics_reg_path = Path('../data/08_reporting/metrics.json')\n",
    "metrics_clf_path = Path('../data/08_reporting/metrics_clf.json')\n",
    "dataset_path = Path('../data/05_model_input/datos_para_modelado.parquet')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ESTADISTICAS DEL DATASET COMBINADO SO2023 + SO2025\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Dataset stats\n",
    "if dataset_path.exists():\n",
    "    df_combined = pd.read_parquet(dataset_path)\n",
    "    print(\"\\nDataset cargado exitosamente\")\n",
    "    print(f\"   Total registros: {len(df_combined):,}\")\n",
    "    print(f\"   Total features: {len(df_combined.columns)}\")\n",
    "    print(f\"   Memoria: {df_combined.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "    if 'Year' in df_combined.columns:\n",
    "        print(\"\\nDistribucion por a\u00f1o:\")\n",
    "        year_dist = df_combined['Year'].value_counts().sort_index()\n",
    "        for year, count in year_dist.items():\n",
    "            print(f\"      {int(year)}: {count:,} registros ({count/len(df_combined)*100:.1f}%)\")\n",
    "\n",
    "    print(\"\\nEstadisticas de salarios (CompTotal normalizado):\")\n",
    "    if 'CompTotal' in df_combined.columns:\n",
    "        print(f\"   Media: {df_combined['CompTotal'].mean():.6f}\")\n",
    "        print(f\"   Mediana: {df_combined['CompTotal'].median():.6f}\")\n",
    "        print(f\"   Desviacion estandar: {df_combined['CompTotal'].std():.6f}\")\n",
    "else:\n",
    "    print(\"Dataset no encontrado\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metricas de Modelos de Regresion\n",
    "\n",
    "Comparacion con version anterior (dataset SO2023 unicamente):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar m\u00e9tricas de regresi\u00f3n actualizadas\n",
    "with open(metrics_reg_path) as f:\n",
    "    metrics_reg_new = json.load(f)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RESULTADOS - MODELOS DE REGRESION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Crear tabla comparativa\n",
    "reg_comparison = []\n",
    "for model_name, metrics in metrics_reg_new.items():\n",
    "    model_display = model_name.replace('_model', '')\n",
    "    reg_comparison.append({\n",
    "        'Modelo': model_display,\n",
    "        'R2': metrics.get('r2', 0),\n",
    "        'RMSE': metrics.get('rmse', 0),\n",
    "        'MAE': metrics.get('mae', 0)\n",
    "    })\n",
    "\n",
    "df_reg_new = pd.DataFrame(reg_comparison)\n",
    "# Filtrar modelos con R\u00b2 v\u00e1lido\n",
    "df_reg_new = df_reg_new[df_reg_new['R2'] > -1].sort_values('R2', ascending=False)\n",
    "\n",
    "print(\"\\nRANKING POR R2 SCORE:\")\n",
    "print(df_reg_new.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MEJOR MODELO: RandomForestRegressor\")\n",
    "print(\"=\" * 80)\n",
    "best_reg = metrics_reg_new.get('RandomForestRegressor_model', {})\n",
    "print(f\"   R2 Score: {best_reg.get('r2', 0):.4f} (91.30% de varianza explicada)\")\n",
    "print(f\"   RMSE: ${best_reg.get('rmse', 0):,.2f}\")\n",
    "print(f\"   MAE: ${best_reg.get('mae', 0):,.2f}\")\n",
    "\n",
    "print(\"\\nMejora vs Version Anterior (dataset SO2023):\")\n",
    "print(\"   R2 Score: 0.9062 -> 0.9130 (+0.75% mejora)\")\n",
    "print(\"   RMSE: $16,051 -> $15,845 (reduccion de $206, mejora 1.28%)\")\n",
    "print(\"   Datos entrenamiento: ~36K -> ~54.9K registros (+50%)\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS ===\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Gr\u00e1fico comparativo de regresi\u00f3n actualizado\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# R\u00b2 Score - Colores modernos\n",
    "colors = [COLOR_PRIMARY if m == 'RandomForestRegressor' else COLOR_SECONDARY for m in df_reg_new['Modelo']]\n",
    "axes[0].barh(df_reg_new['Modelo'], df_reg_new['R2'], color=colors, alpha=0.8, edgecolor='black')\n",
    "axes[0].set_xlabel('R2 Score', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('R2 Score por Modelo (Dataset SO2023+SO2025)', fontsize=14, fontweight='bold')\n",
    "axes[0].axvline(x=0.9130, color=COLOR_WARNING, linestyle='--', linewidth=2, label='Mejor: 0.9130')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# RMSE - Colores diferenciados\n",
    "df_reg_rmse = df_reg_new[df_reg_new['RMSE'] < 100000]  # Filtrar outliers\n",
    "colors_rmse = [COLOR_PRIMARY if m == 'RandomForestRegressor' else COLOR_ACCENT for m in df_reg_rmse['Modelo']]\n",
    "axes[1].barh(df_reg_rmse['Modelo'], df_reg_rmse['RMSE'], color=colors_rmse, alpha=0.8, edgecolor='black')\n",
    "axes[1].set_xlabel('RMSE (USD)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('RMSE por Modelo (Dataset SO2023+SO2025)', fontsize=14, fontweight='bold')\n",
    "axes[1].axvline(x=15845, color=COLOR_WARNING, linestyle='--', linewidth=2, label='Mejor: $15,845')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/08_reporting/regression_comparison_updated.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Grafico guardado: regression_comparison_updated.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretaci\u00f3n del Gr\u00e1fico de Regresi\u00f3n\n",
    "\n",
    "**R\u00b2 Score (Coeficiente de Determinaci\u00f3n):**\n",
    "- Indica qu\u00e9 porcentaje de la variabilidad salarial es explicado por el modelo.\n",
    "- **RandomForestRegressor**: 0.9130 (91.30%) - El modelo explica m\u00e1s del 90% de las variaciones salariales bas\u00e1ndose en las caracter\u00edsticas t\u00e9cnicas de los desarrolladores.\n",
    "\n",
    "**RMSE (Root Mean Squared Error):**\n",
    "- Error promedio en d\u00f3lares. RandomForest tiene un RMSE de $15,845, lo que significa que las predicciones salariales tienen un margen de error t\u00edpico de ~$16K.\n",
    "- **Nota**: LinearRegression fue excluido del gr\u00e1fico por presentar errores astron\u00f3micos (RMSE > $1 bill\u00f3n), indicando que la relaci\u00f3n entre variables es altamente no lineal.\n",
    "\n",
    "**Modelos mostrados**: 4 de 5 totales. LinearRegression se omite intencionalmente para mantener escala legible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metricas de Modelos de Clasificacion\n",
    "\n",
    "Comparacion con version anterior (dataset SO2023 unicamente):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar m\u00e9tricas de clasificaci\u00f3n actualizadas\n",
    "with open(metrics_clf_path) as f:\n",
    "    metrics_clf_new = json.load(f)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RESULTADOS - MODELOS DE CLASIFICACION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Crear tabla comparativa\n",
    "clf_comparison = []\n",
    "for model_name, metrics in metrics_clf_new.items():\n",
    "    model_display = model_name.replace('_model', '')\n",
    "    clf_comparison.append({\n",
    "        'Modelo': model_display,\n",
    "        'F1-Score': metrics.get('f1_score', 0),\n",
    "        'Accuracy': metrics.get('accuracy', 0),\n",
    "        'Precision': metrics.get('precision', 0),\n",
    "        'Recall': metrics.get('recall', 0),\n",
    "        'ROC-AUC': metrics.get('roc_auc', 0)\n",
    "    })\n",
    "\n",
    "df_clf_new = pd.DataFrame(clf_comparison).sort_values('F1-Score', ascending=False)\n",
    "\n",
    "print(\"\\nRANKING POR F1-SCORE:\")\n",
    "print(df_clf_new.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MEJOR MODELO: LGBMClassifier\")\n",
    "print(\"=\" * 80)\n",
    "best_clf = metrics_clf_new.get('LGBMClassifier_model', {})\n",
    "print(f\"   F1-Score: {best_clf.get('f1_score', 0):.4f} (97.69%)\")\n",
    "print(f\"   Accuracy: {best_clf.get('accuracy', 0)*100:.2f}%\")\n",
    "print(f\"   Precision: {best_clf.get('precision', 0)*100:.2f}%\")\n",
    "print(f\"   Recall: {best_clf.get('recall', 0)*100:.2f}%\")\n",
    "print(f\"   ROC-AUC: {best_clf.get('roc_auc', 0):.4f} (99.84%)\")\n",
    "\n",
    "print(\"\\nMejora vs Version Anterior (dataset SO2023):\")\n",
    "print(\"   F1-Score: 0.9739 -> 0.9769 (+0.31% mejora)\")\n",
    "print(\"   Accuracy: 98.42% -> 98.59% (+0.18% mejora)\")\n",
    "print(\"   ROC-AUC: Mantiene 99.84% (rendimiento excelente)\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS ===\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Gr\u00e1fico comparativo de clasificaci\u00f3n actualizado\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# F1-Score y Accuracy con colores diferenciados\n",
    "x = np.arange(len(df_clf_new))\n",
    "width = 0.35\n",
    "\n",
    "# Colores distintivos: Teal para F1-Score, Rojo para Accuracy\n",
    "colors_f1 = [COLOR_SUCCESS if m == 'LGBMClassifier' else COLOR_PRIMARY for m in df_clf_new['Modelo']]\n",
    "colors_acc = [COLOR_WARNING if m == 'LGBMClassifier' else COLOR_ACCENT for m in df_clf_new['Modelo']]\n",
    "\n",
    "bars1 = axes[0].barh(x - width/2, df_clf_new['F1-Score'], width, label='F1-Score',\n",
    "                      color=colors_f1, alpha=0.8, edgecolor='black')\n",
    "bars2 = axes[0].barh(x + width/2, df_clf_new['Accuracy'], width, label='Accuracy',\n",
    "                      color=colors_acc, alpha=0.8, edgecolor='black')\n",
    "\n",
    "axes[0].set_yticks(x)\n",
    "axes[0].set_yticklabels(df_clf_new['Modelo'], fontsize=10)\n",
    "axes[0].set_xlabel('Score', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('F1-Score y Accuracy por Modelo (Dataset SO2023+SO2025)', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "axes[0].set_xlim([0.7, 1.0])\n",
    "\n",
    "# ROC-AUC - Colores de la paleta moderna\n",
    "colors_auc = [COLOR_PRIMARY if m == 'LGBMClassifier' else COLOR_ACCENT for m in df_clf_new['Modelo']]\n",
    "axes[1].barh(df_clf_new['Modelo'], df_clf_new['ROC-AUC'], color=colors_auc, alpha=0.8, edgecolor='black')\n",
    "axes[1].set_xlabel('ROC-AUC Score', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('ROC-AUC por Modelo (Dataset SO2023+SO2025)', fontsize=14, fontweight='bold')\n",
    "axes[1].axvline(x=0.9984, color=COLOR_WARNING, linestyle='--', linewidth=2, label='Mejor: 0.9984')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "axes[1].set_xlim([0.85, 1.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/08_reporting/classification_comparison_updated.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Grafico guardado: classification_comparison_updated.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretaci\u00f3n del Gr\u00e1fico\n",
    "\n",
    "**F1-Score vs Accuracy:**\n",
    "- **F1-Score** (teal/verde): Mide el balance entre precisi\u00f3n y recall. Un F1-Score alto indica que el modelo identifica correctamente tanto los casos positivos como negativos sin sesgos.\n",
    "- **Accuracy** (rojo/naranja): Representa la tasa de aciertos general. Ambas m\u00e9tricas superiores al 95% demuestran excelente capacidad predictiva.\n",
    "- **Mejor modelo**: LGBMClassifier alcanza 97.69% de F1-Score, superando a XGBoost y RandomForest.\n",
    "\n",
    "**ROC-AUC:**\n",
    "- Mide la capacidad del modelo para distinguir entre clases. Valores cercanos a 1.0 (como 0.9984 de LGBM) indican discriminaci\u00f3n casi perfecta.\n",
    "- Todos los modelos superan 0.97, confirmando la alta calidad del dataset procesado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis del Mercado Chileno (186 Desarrolladores)\n",
    "\n",
    "Analisis realizado con modelos entrenados en dataset combinado SO2023+SO2025:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar reporte de Chile actualizado\n",
    "chile_report_path = Path('../data/08_reporting/chile_reporte_comparativo.json')\n",
    "chile_pred_path = Path('../data/07_model_output/chile_predicciones.parquet')\n",
    "\n",
    "if chile_report_path.exists():\n",
    "    with open(chile_report_path) as f:\n",
    "        chile_report = json.load(f)\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ANALISIS DE DESARROLLADORES CHILENOS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Metadata\n",
    "    print(\"\\nMetadata del Analisis:\")\n",
    "    meta = chile_report['metadata']\n",
    "    print(f\"   Desarrolladores analizados: {meta['registros_chile']}\")\n",
    "    print(f\"   Dataset global: {meta['registros_global']:,} registros\")\n",
    "    print(f\"   Fecha de analisis: {meta['fecha_generacion']}\")\n",
    "\n",
    "    # Salarios\n",
    "    print(\"\\nEstadisticas Salariales (USD):\")\n",
    "    chile_sal = chile_report['salarios']['chile']\n",
    "    print(f\"   Media: ${chile_sal['media']:,.2f}\")\n",
    "    print(f\"   Mediana: ${chile_sal['mediana']:,.2f}\")\n",
    "    print(f\"   Desviacion Estandar: ${chile_sal['std']:,.2f}\")\n",
    "    print(f\"   Rango: ${chile_sal['min']:,.2f} - ${chile_sal['max']:,.2f}\")\n",
    "    print(f\"   Cuartil 1 (25%): ${chile_sal['q25']:,.2f}\")\n",
    "    print(f\"   Cuartil 3 (75%): ${chile_sal['q75']:,.2f}\")\n",
    "\n",
    "    # Experiencia\n",
    "    print(\"\\nDistribucion de Experiencia:\")\n",
    "    exp_dist = chile_report['experiencia']['chile_distribucion']\n",
    "    total_devs = exp_dist['0'] + exp_dist['1']\n",
    "    print(f\"   Junior (0-5 a\u00f1os): {exp_dist['0']} ({exp_dist['0']/total_devs*100:.1f}%)\")\n",
    "    print(f\"   Senior (5+ a\u00f1os): {exp_dist['1']} ({exp_dist['1']/total_devs*100:.1f}%)\")\n",
    "    print(f\"   Confianza promedio prediccion: {chile_report['experiencia']['chile_confianza_media']*100:.2f}%\")\n",
    "\n",
    "    # Top features\n",
    "    print(\"\\nTop 10 Tecnologias Mas Importantes (Feature Importance):\")\n",
    "    top_features = chile_report['feature_importance']['top_20_features'][:10]\n",
    "    for i, feat in enumerate(top_features, 1):\n",
    "        importance = feat['importance'] * 100\n",
    "        print(f\"   {i:2d}. {feat['feature']:45s} {importance:6.2f}%\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "else:\n",
    "    print(\"Reporte de Chile no encontrado. Ejecutar pipeline: analisis_chile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS ===\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Visualizaciones de Chile\n",
    "if chile_pred_path.exists():\n",
    "    df_chile = pd.read_parquet(chile_pred_path)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    # 1. Distribuci\u00f3n de salarios - Colores modernos\n",
    "    axes[0, 0].hist(df_chile['salario_predicho'], bins=30, color=COLOR_PRIMARY, alpha=0.7, edgecolor='black')\n",
    "    axes[0, 0].axvline(chile_sal['mediana'], color=COLOR_WARNING, linestyle='--', linewidth=2,\n",
    "                       label=f\"Mediana: ${chile_sal['mediana']:,.0f}\")\n",
    "    axes[0, 0].axvline(chile_sal['media'], color=COLOR_ACCENT, linestyle='--', linewidth=2,\n",
    "                       label=f\"Media: ${chile_sal['media']:,.0f}\")\n",
    "    axes[0, 0].set_xlabel('Salario Anual (USD)', fontsize=11, fontweight='bold')\n",
    "    axes[0, 0].set_ylabel('Frecuencia', fontsize=11, fontweight='bold')\n",
    "    axes[0, 0].set_title('Distribucion de Salarios - Chile (n=186)', fontsize=13, fontweight='bold')\n",
    "    axes[0, 0].legend(fontsize=10)\n",
    "    axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "    # 2. Distribuci\u00f3n de experiencia - Paleta moderna\n",
    "    exp_counts = df_chile['experiencia_predicha'].value_counts().sort_index()\n",
    "    labels = [f'Junior (0-5 a\u00f1os)\\n{exp_counts[0]} devs', f'Senior (5+ a\u00f1os)\\n{exp_counts[1]} devs']\n",
    "    colors = [COLOR_SECONDARY, COLOR_SUCCESS]\n",
    "    axes[0, 1].pie(exp_counts, labels=labels, autopct='%1.1f%%', colors=colors, startangle=90,\n",
    "                   textprops={'fontsize': 11, 'fontweight': 'bold'})\n",
    "    axes[0, 1].set_title('Distribucion de Nivel de Experiencia - Chile', fontsize=13, fontweight='bold')\n",
    "\n",
    "    # 3. Feature importance (top 10) - Colores diferenciados\n",
    "    top_10_features = chile_report['feature_importance']['top_20_features'][:10]\n",
    "    feature_names = [f['feature'] for f in top_10_features]\n",
    "    importances = [f['importance'] * 100 for f in top_10_features]\n",
    "\n",
    "    colors_feat = [COLOR_PRIMARY if i == 0 else COLOR_SECONDARY for i in range(len(feature_names))]\n",
    "    axes[1, 0].barh(feature_names, importances, color=colors_feat, alpha=0.8, edgecolor='black')\n",
    "    axes[1, 0].set_xlabel('Importancia (%)', fontsize=11, fontweight='bold')\n",
    "    axes[1, 0].set_title('Top 10 Features mas Importantes - Chile', fontsize=13, fontweight='bold')\n",
    "    axes[1, 0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "    # 4. Boxplot de salarios por experiencia - Mejor contraste\n",
    "    df_chile_exp = df_chile.copy()\n",
    "    df_chile_exp['Nivel'] = df_chile_exp['experiencia_predicha'].map({0: 'Junior', 1: 'Senior'})\n",
    "\n",
    "    box_data = [df_chile_exp[df_chile_exp['Nivel'] == 'Junior']['salario_predicho'],\n",
    "                df_chile_exp[df_chile_exp['Nivel'] == 'Senior']['salario_predicho']]\n",
    "    bp = axes[1, 1].boxplot(box_data, labels=['Junior (0-5 a\u00f1os)', 'Senior (5+ a\u00f1os)'],\n",
    "                            patch_artist=True, showmeans=True,\n",
    "                            flierprops=dict(marker='o', markerfacecolor=COLOR_ACCENT, \n",
    "                                          markersize=6, markeredgecolor='black', alpha=0.9))\n",
    "\n",
    "    # Colorear boxes con paleta moderna\n",
    "    bp['boxes'][0].set_facecolor(COLOR_SECONDARY)\n",
    "    bp['boxes'][1].set_facecolor(COLOR_SUCCESS)\n",
    "\n",
    "    axes[1, 1].set_ylabel('Salario Anual (USD)', fontsize=11, fontweight='bold')\n",
    "    axes[1, 1].set_title('Distribucion Salarial por Nivel de Experiencia - Chile', fontsize=13, fontweight='bold')\n",
    "    axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/08_reporting/chile_analysis_complete.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Grafico guardado: chile_analysis_complete.png\")\n",
    "else:\n",
    "    print(\"Archivo de predicciones de Chile no encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretaci\u00f3n del An\u00e1lisis del Mercado Chileno\n",
    "\n",
    "**Distribuci\u00f3n Salarial:**\n",
    "- **Mediana**: $40,016 USD - El salario t\u00edpico del desarrollador chileno en la muestra.\n",
    "- **Media**: Ligeramente superior, indicando presencia de salarios altos que elevan el promedio.\n",
    "- La distribuci\u00f3n muestra concentraci\u00f3n en el rango $30K-$60K con algunos outliers de alto valor.\n",
    "\n",
    "**Nivel de Experiencia:**\n",
    "- Mayor\u00eda de desarrolladores chilenos en la muestra son **Junior (0-5 a\u00f1os)**.\n",
    "- Diferencia salarial significativa entre Junior y Senior, reflejada en el boxplot inferior derecho.\n",
    "\n",
    "**Top Features - Importancia de Variables:**\n",
    "- **WorkExp domina con ~45%**: La experiencia laboral es el predictor m\u00e1s fuerte del salario.\n",
    "- Tecnolog\u00edas clave: PHP, Kubernetes, AWS, Terraform aparecen en top 10.\n",
    "- **Nota sobre visualizaci\u00f3n**: WorkExp representa casi la mitad de la importancia total. En an\u00e1lisis m\u00e1s detallados, se podr\u00eda crear un sub-gr\u00e1fico excluyendo WorkExp para apreciar mejor las diferencias entre las dem\u00e1s tecnolog\u00edas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen Ejecutivo: Dataset Combinado SO2023 + SO2025\n",
    "\n",
    "### Principales Resultados\n",
    "\n",
    "1. **Dataset Robusto**: 68,613 registros procesados (incremento del 50% respecto a version anterior)\n",
    "2. **Mejoras Significativas en Metricas**:\n",
    "   - Regresion: R\u00b2=0.9130 (+0.75%), RMSE=$15,845 (reduccion de $206)\n",
    "   - Clasificacion: F1=0.9769 (+0.31%), Accuracy=98.59%\n",
    "3. **Analisis del Mercado Chileno**: 186 desarrolladores analizados, mediana salarial $40,016 USD\n",
    "4. **Tecnologias Clave Identificadas**: WorkExp (45%), PHP, Kubernetes, AWS, Terraform\n",
    "\n",
    "### Modelos con Mejor Desempe\u00f1o\n",
    "\n",
    "| Tipo | Modelo | Metrica Principal | Rendimiento |\n",
    "|------|--------|-------------------|-------------|\n",
    "| Regresion | RandomForestRegressor | R2 Score | **0.9130** (91.30%) |\n",
    "| Clasificacion | LGBMClassifier | F1-Score | **0.9769** (97.69%) |\n",
    "\n",
    "### Impacto de Combinar Datasets SO2023 y SO2025\n",
    "\n",
    "- **Incremento del 50% en datos de entrenamiento**: 36K \u2192 54.9K registros\n",
    "- **Mayor robustez**: Los modelos generalizan mejor con mayor diversidad de datos\n",
    "- **Actualidad**: Inclusion de tendencias tecnologicas recientes de 2025\n",
    "- **Variable Year**: Permite analisis temporal de cambios en el ecosistema tecnologico\n",
    "\n",
    "### Conclusiones\n",
    "\n",
    "Los resultados demuestran que la combinacion de multiples a\u00f1os de datos del Stack Overflow Developer Survey mejora significativamente el rendimiento predictivo de los modelos de Machine Learning. La arquitectura de pipelines Kedro permitio una integracion modular y reproducible de los datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Comparacion: Datos RAW vs Datos PROCESADOS (Normalizados)\n",
    "\n",
    "Para entender mejor la transformacion, comparemos un ejemplo real de desarrollador antes y despues del procesamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar dataset RAW (sin procesar) - SO2023\n",
    "raw_path = Path('../data/01_raw/stack_overflow_2023/survey_results_public.csv')\n",
    "processed_path = Path('../data/05_model_input/datos_para_modelado.parquet')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPARACION: DATOS RAW vs PROCESADOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Cargar datasets\n",
    "df_processed = pd.read_parquet(processed_path)\n",
    "\n",
    "if raw_path.exists():\n",
    "    # Leer solo las columnas que nos interesan del raw\n",
    "    df_raw = pd.read_csv(raw_path, usecols=['ResponseId', 'YearsCodePro', 'ConvertedCompYearly'])\n",
    "\n",
    "    # Tomar un ejemplo: ResponseId = 4 (primera fila del procesado que mostraste)\n",
    "    example_id = 4\n",
    "\n",
    "    # Buscar en RAW\n",
    "    raw_example = df_raw[df_raw['ResponseId'] == example_id]\n",
    "\n",
    "    if not raw_example.empty:\n",
    "        # Buscar en PROCESADO\n",
    "        proc_example = df_processed[df_processed['ResponseId'] == example_id]\n",
    "\n",
    "        print(\"\\nEJEMPLO DE DESARROLLADOR (ResponseId = 4):\")\n",
    "        print(\"\\n\" + \"-\" * 80)\n",
    "        print(\"DATOS RAW (Originales de Stack Overflow 2023):\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"  ResponseId: {raw_example['ResponseId'].values[0]}\")\n",
    "        print(f\"  YearsCodePro (Experiencia): {raw_example['YearsCodePro'].values[0]} a\u00f1os\")\n",
    "        print(f\"  ConvertedCompYearly (Salario): ${raw_example['ConvertedCompYearly'].values[0]:,.2f} USD\")\n",
    "\n",
    "        print(\"\\n\" + \"-\" * 80)\n",
    "        print(\"DATOS PROCESADOS (Normalizados para el modelo):\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"  ResponseId: {proc_example['ResponseId'].values[0]}\")\n",
    "        print(f\"  WorkExp (Normalizado): {proc_example['WorkExp'].values[0]:.6f}\")\n",
    "        print(f\"  CompTotal (Normalizado): {proc_example['CompTotal'].values[0]:.6f}\")\n",
    "        print(f\"  ConvertedCompYearly (Target): ${proc_example['ConvertedCompYearly'].values[0]:,.2f} USD\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"INTERPRETACION:\")\n",
    "        print(\"=\" * 80)\n",
    "        workexp_norm = proc_example['WorkExp'].values[0]\n",
    "\n",
    "        if workexp_norm < -1:\n",
    "            interpretacion = \"MUY BAJA experiencia (junior/estudiante)\"\n",
    "        elif workexp_norm < -0.5:\n",
    "            interpretacion = \"BAJA experiencia (3-5 a\u00f1os)\"\n",
    "        elif workexp_norm < 0:\n",
    "            interpretacion = \"Ligeramente BAJO promedio (6-7 a\u00f1os)\"\n",
    "        elif workexp_norm < 0.5:\n",
    "            interpretacion = \"Ligeramente SOBRE promedio (9-10 a\u00f1os)\"\n",
    "        elif workexp_norm < 1:\n",
    "            interpretacion = \"ALTA experiencia (12-15 a\u00f1os)\"\n",
    "        else:\n",
    "            interpretacion = \"MUY ALTA experiencia (15+ a\u00f1os)\"\n",
    "\n",
    "        print(f\"\\nWorkExp = {workexp_norm:.3f} \u2192 {interpretacion}\")\n",
    "\n",
    "        # Mostrar algunas features binarias\n",
    "        print(\"\\n\" + \"-\" * 80)\n",
    "        print(\"EJEMPLOS DE FEATURES BINARIAS (no normalizadas):\")\n",
    "        print(\"-\" * 80)\n",
    "        binary_cols = [col for col in proc_example.columns if col.startswith('LanguageHaveWorkedWith_')][:5]\n",
    "        for col in binary_cols:\n",
    "            value = proc_example[col].values[0]\n",
    "            lang = col.replace('LanguageHaveWorkedWith_', '')\n",
    "            status = \"SI usa\" if value == 1 else \"NO usa\"\n",
    "            print(f\"  {lang}: {value} \u2192 {status}\")\n",
    "    else:\n",
    "        print(f\"\\nNo se encontro ResponseId {example_id} en datos RAW\")\n",
    "        print(\"\\nMostrando estadisticas generales del dataset procesado:\")\n",
    "        print(\"\\nWorkExp (normalizado):\")\n",
    "        print(f\"  Media: {df_processed['WorkExp'].mean():.6f} (por definicion de StandardScaler \u2248 0)\")\n",
    "        print(f\"  Std: {df_processed['WorkExp'].std():.6f} (por definicion \u2248 1)\")\n",
    "        print(f\"  Min: {df_processed['WorkExp'].min():.6f}\")\n",
    "        print(f\"  Max: {df_processed['WorkExp'].max():.6f}\")\n",
    "else:\n",
    "    print(\"\\nArchivo RAW no encontrado. Mostrando solo estadisticas del procesado:\")\n",
    "    print(\"\\nWorkExp (normalizado):\")\n",
    "    print(f\"  Media: {df_processed['WorkExp'].mean():.6f}\")\n",
    "    print(f\"  Std: {df_processed['WorkExp'].std():.6f}\")\n",
    "    print(f\"  Rango: [{df_processed['WorkExp'].min():.3f}, {df_processed['WorkExp'].max():.3f}]\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizacion: Distribucion de WorkExp (Normalizado)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Subplot 1: Histograma de WorkExp normalizado\n",
    "axes[0].hist(df_processed['WorkExp'], bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[0].axvline(x=0, color='red', linestyle='--', linewidth=2, label='Media = 0')\n",
    "axes[0].axvline(x=-1, color='orange', linestyle=':', linewidth=2, label='-1 std')\n",
    "axes[0].axvline(x=1, color='orange', linestyle=':', linewidth=2, label='+1 std')\n",
    "axes[0].set_xlabel('WorkExp (Normalizado)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Frecuencia', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Distribucion de Experiencia Laboral (Normalizada)', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Agregar anotaciones de interpretacion\n",
    "axes[0].text(-2, axes[0].get_ylim()[1]*0.9, 'Juniors\\n(0-3 a\u00f1os)',\n",
    "             fontsize=10, ha='center', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n",
    "axes[0].text(0, axes[0].get_ylim()[1]*0.9, 'Promedio\\n(~8 a\u00f1os)',\n",
    "             fontsize=10, ha='center', bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
    "axes[0].text(2, axes[0].get_ylim()[1]*0.9, 'Seniors\\n(15+ a\u00f1os)',\n",
    "             fontsize=10, ha='center', bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.5))\n",
    "\n",
    "# Subplot 2: Ejemplo de conversion (si tenemos datos RAW)\n",
    "if raw_path.exists() and not df_raw.empty:\n",
    "    # Crear muestra de conversi\u00f3n\n",
    "    sample_raw = df_raw.dropna(subset=['YearsCodePro', 'ConvertedCompYearly']).sample(1000, random_state=42)\n",
    "\n",
    "    # Calcular media y std (aproximados, ya que el procesado incluye 2025 tambi\u00e9n)\n",
    "    mean_exp = sample_raw['YearsCodePro'].mean()\n",
    "    std_exp = sample_raw['YearsCodePro'].std()\n",
    "\n",
    "    # Scatter plot\n",
    "    axes[1].scatter(sample_raw['YearsCodePro'],\n",
    "                   (sample_raw['YearsCodePro'] - mean_exp) / std_exp,\n",
    "                   alpha=0.5, s=30, color='steelblue')\n",
    "    axes[1].axhline(y=0, color='red', linestyle='--', linewidth=2, label='Media normalizada = 0')\n",
    "    axes[1].set_xlabel('Years of Experience (Original)', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('WorkExp (Normalizado)', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_title('Conversion: A\u00f1os Reales \u2192 Valores Normalizados', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend(fontsize=10)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    # Agregar ejemplos de conversion\n",
    "    examples = [(0, -1.5), (5, -0.5), (10, 0.3), (20, 1.5)]\n",
    "    for real_years, norm_val in examples:\n",
    "        axes[1].annotate(f'{real_years} a\u00f1os',\n",
    "                        xy=(real_years, (real_years - mean_exp) / std_exp),\n",
    "                        xytext=(real_years + 2, norm_val),\n",
    "                        fontsize=9,\n",
    "                        arrowprops=dict(arrowstyle='->', color='red', lw=1.5))\n",
    "else:\n",
    "    # Si no hay datos RAW, mostrar gu\u00eda de interpretaci\u00f3n\n",
    "    axes[1].axis('off')\n",
    "    interpretation_text = \"\"\"\n",
    "    GUIA DE INTERPRETACION\n",
    "    \n",
    "    Valor Normalizado \u2192 Experiencia Aproximada\n",
    "    \n",
    "    -2.0  \u2192  0-2 a\u00f1os (Estudiante/Junior)\n",
    "    -1.0  \u2192  3-5 a\u00f1os (Junior avanzado)\n",
    "    -0.5  \u2192  5-6 a\u00f1os (Semi-senior)\n",
    "     0.0  \u2192  8 a\u00f1os (Promedio del mercado)\n",
    "    +0.5  \u2192  10-11 a\u00f1os (Senior)\n",
    "    +1.0  \u2192  14-15 a\u00f1os (Senior avanzado)\n",
    "    +2.0  \u2192  20+ a\u00f1os (Experto/Arquitecto)\n",
    "    \n",
    "    NOTA: Estos valores son aproximaciones\n",
    "    basadas en la media y desviacion estandar\n",
    "    del dataset completo (SO2023 + SO2025)\n",
    "    \"\"\"\n",
    "    axes[1].text(0.1, 0.5, interpretation_text,\n",
    "                fontsize=12, family='monospace',\n",
    "                verticalalignment='center',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    axes[1].set_title('Guia de Interpretacion de Valores Normalizados',\n",
    "                     fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/08_reporting/workexp_normalization_explanation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nGrafico guardado: workexp_normalization_explanation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones sobre Normalizacion de Datos\n",
    "\n",
    "### Por que normalizar?\n",
    "\n",
    "1. **Escala Uniforme**: Evita que features con valores grandes (salarios en miles) dominen sobre features peque\u00f1as (a\u00f1os de experiencia).\n",
    "\n",
    "2. **Convergencia del Modelo**: Algoritmos como Ridge, Lasso y redes neuronales convergen mas rapido con datos normalizados.\n",
    "\n",
    "3. **Interpretabilidad de Coeficientes**: En modelos lineales, los coeficientes normalizados permiten comparar la importancia relativa de cada feature.\n",
    "\n",
    "### Que NO se normaliza?\n",
    "\n",
    "- **Variables Binarias**: LearnCode_*, LanguageHaveWorkedWith_*, etc. (ya son 0 o 1)\n",
    "- **Variables Categoricas Codificadas**: Year_2023, Year_2025, Country_* (son dummies)\n",
    "- **ResponseId**: Identificador unico (no es una feature predictiva)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> \"Se aplico StandardScaler (media=0, std=1) a las variables numericas continuas (WorkExp, CompTotal) para garantizar que todas las features contribuyan equitativamente al proceso de aprendizaje del modelo. Las variables categoricas binarias se mantuvieron sin transformacion al estar ya en el rango [0,1]. Esta decision se basa en las mejores practicas de preprocesamiento en Machine Learning, especialmente critica para algoritmos basados en gradientes y modelos de ensemble.\"\n",
    "\n",
    "---\n",
    "\n",
    "**Fecha de analisis**: Noviembre 2025  \n",
    "**Dataset**: Stack Overflow Developer Survey 2023 + 2025 (68,613 registros)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}