{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An√°lisis de Resultados: Ecosistema de Desarrolladores\n",
    "\n",
    "Este notebook presenta el an√°lisis de resultados de los modelos aplicados sobre tres datasets principales:\n",
    "- **Stack Overflow 2023** (`stack_overflow_survey_results_public.csv`)\n",
    "- **Stack Overflow 2025** (`survey_results_public.csv`)\n",
    "- **JetBrains Developer Ecosystem 2025** (`developer_ecosystem_2025_external.csv`)\n",
    "\n",
    "Todos los pipelines han sido ejecutados exitosamente con Kedro. Aqu√≠ se cargan y exploran los datos, se presentan los resultados de los modelos y se visualizan las m√©tricas clave de cada fuente.\n",
    "\n",
    "> **Nota:** El objetivo es mantener el notebook ordenado, profesional y reproducible, con explicaciones claras y sin redundancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CARGA DE MATRICES DE CONFUSI√ìN ===\n",
    "\n",
    "import json\n",
    "\n",
    "# Cargar matrices de confusi√≥n desde archivo JSON\n",
    "conf_matrix_path = project_root / 'data' / '08_reporting' / 'classification_confusion_matrices.json'\n",
    "with open(conf_matrix_path, 'r') as f:\n",
    "    matrices_confusion = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - An√°lisis de Resultados de Modelos\n",
    "\n",
    "**Objetivo:** Analizar y comparar los resultados de los modelos de clasificaci√≥n y regresi√≥n generados por los pipelines de Kedro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librer√≠as cargadas correctamente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de gr√°ficos\n",
    "plt.style.use('ggplot')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Rutas\n",
    "project_root = Path('..') if Path('..').joinpath('data').exists() else Path('.')\n",
    "\n",
    "print('Librer√≠as cargadas correctamente')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versi√≥n: Dataset Combinado SO2023 + SO2025\n",
    "\n",
    "**Dataset Utilizado:**\n",
    "- Stack Overflow Developer Survey 2023: 89,184 registros\n",
    "- Stack Overflow Developer Survey 2025: 49,123 registros  \n",
    "- **Total procesado**: 68,613 registros (incremento del 50% respecto a versi√≥n previa)\n",
    "- **Features**: 556 columnas (incluye variable Year para an√°lisis temporal)\n",
    "\n",
    "**Mejoras en Rendimiento de Modelos:**\n",
    "- Regresi√≥n: R¬≤=0.9130 (+0.75%), RMSE=$15,845 (reducci√≥n de $206)\n",
    "- Clasificaci√≥n: F1=0.9769 (+0.31%), Accuracy=98.59%\n",
    "- An√°lisis Chile: 186 desarrolladores, mediana salarial $40,016 USD\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Verificaci√≥n del Entorno\n",
    "\n",
    "Antes de comenzar el an√°lisis, verificamos que todos los componentes necesarios est√©n disponibles:\n",
    "- Librer√≠as Python requeridas\n",
    "- Estructura de directorios del proyecto\n",
    "- Artefactos generados por los pipelines (modelos, m√©tricas)\n",
    "\n",
    "Este notebook utiliza la **extensi√≥n IPython de Kedro** para acceder al cat√°logo de datos y cargar los resultados de los experimentos de forma reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos de m√©tricas disponibles:\n",
      "  - metrics.json\n",
      "  - metrics_ridge_poly.json\n",
      "  - metrics_clf.json\n",
      "  - classification_confusion_matrices.json\n",
      "\n",
      "Modelos disponibles:\n",
      "  - regresion_model.pkl\n",
      "  - clasificacion_model.pkl\n",
      "  - ridge_poly_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Verificar archivos de m√©tricas disponibles\n",
    "metrics_dir = project_root / 'data' / '08_reporting'\n",
    "models_dir = project_root / 'data' / '06_models'\n",
    "\n",
    "print('Archivos de m√©tricas disponibles:')\n",
    "if metrics_dir.exists():\n",
    "    for f in metrics_dir.glob('*.json'):\n",
    "        print(f'  - {f.name}')\n",
    "else:\n",
    "    print('  Directorio de m√©tricas no encontrado')\n",
    "\n",
    "print('\\nModelos disponibles:')\n",
    "if models_dir.exists():\n",
    "    for f in models_dir.glob('*.pkl'):\n",
    "        print(f'  - {f.name}')\n",
    "else:\n",
    "    print('  Directorio de modelos no encontrado')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga del Contexto y Cat√°logo de Kedro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuraci√≥n b√°sica aplicada (sin Kedro)\n"
     ]
    }
   ],
   "source": [
    "# Entorno listo.\n",
    "print('Configuraci√≥n b√°sica aplicada (sin Kedro)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecci√≥n del Cat√°logo de Kedro\n",
    "\n",
    "Una vez cargada la extensi√≥n, tenemos acceso a las **variables globales** de Kedro. Vamos a explorarlas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado: 68,613 filas, 556 columnas\n"
     ]
    }
   ],
   "source": [
    "# Cargar dataset procesado\n",
    "data_path = project_root / 'data' / '05_model_input' / 'datos_para_modelado.parquet'\n",
    "\n",
    "if data_path.exists():\n",
    "    df = pd.read_parquet(data_path)\n",
    "    print(f'Dataset cargado: {df.shape[0]:,} filas, {df.shape[1]} columnas')\n",
    "    df.head()\n",
    "else:\n",
    "    print(f'Archivo no encontrado: {data_path}')\n",
    "    print('Ejecutar primero: kedro run --pipeline procesamiento_de_datos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¬øQu√© acaba de pasar? Explicaci√≥n del Contexto de Kedro\n",
    "\n",
    "La celda anterior ejecuta dos \"comandos m√°gicos\" espec√≠ficos de Kedro para notebooks:\n",
    "\n",
    "1.  `%load_ext kedro.ipython`: Carga una extensi√≥n especial de Kedro que nos permite usar comandos de Kedro dentro del notebook.\n",
    "2.  `%reload_kedro`: Este es el comando importante. Busca la ra√≠z de nuestro proyecto Kedro, inicia una sesi√≥n y carga en la memoria del notebook varios objetos clave.\n",
    "\n",
    "El texto que aparece como salida nos confirma que todo ha ido bien y nos informa de las **variables globales** que ha creado para nosotros:\n",
    "\n",
    "*   `catalog`: Este es el m√°s importante para nosotros ahora. Es una copia del **Cat√°logo de Datos** (`conf/base/catalog.yml`). A trav√©s de √©l, podemos cargar y guardar cualquier dataset definido en el proyecto con un simple `catalog.load(\"nombre_del_dataset\")`.\n",
    "*   `context`: Es el \"coraz√≥n\" del proyecto Kedro. Contiene toda la configuraci√≥n, par√°metros, etc.\n",
    "*   `pipelines`: Un diccionario que contiene todos los pipelines definidos en el proyecto.\n",
    "*   `session`: La sesi√≥n de Kedro activa, que gestiona la ejecuci√≥n.\n",
    "\n",
    "En resumen, esa celda ha \"conectado\" nuestro notebook con el proyecto Kedro, d√°ndonos acceso a todos sus componentes de forma program√°tica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî data_science_regresion cargadas desde ../data/08_reporting/metrics.json\n",
      "‚úî data_science_clasificacion cargadas desde ../data/08_reporting/metrics_clf.json\n",
      "\n",
      "Resumen r√°pido de m√©tricas\n",
      "-----------------------------------\n",
      "  üü¶ REG LinearRegression_model: {'rmse': 141800345004.58456, 'mae': 2964902928.3594694, 'r2': -6964255627375.31}\n",
      "  üü¶ REG Ridge_model: {'rmse': 32824.3066156645, 'mae': 23965.572369407793, 'r2': 0.6268261094451105}\n",
      "  üü¶ REG Lasso_model: {'rmse': 32840.192990752825, 'mae': 23966.133853492884, 'r2': 0.6264648031069268}\n",
      "  üü¶ REG RandomForestRegressor_model: {'rmse': 15845.340337412867, 'mae': 6384.239461089723, 'r2': 0.913039250899556}\n",
      "  üü¶ REG XGBRegressor_model: {'rmse': 18479.663125002444, 'mae': 10126.569512041806, 'r2': 0.8817208407662738}\n",
      "  üüß CLF LogisticRegression_classifier: {'accuracy': 0.839612329665525, 'f1_score': 0.7285062291846552, 'precision': 0.7614749871067561, 'recall': 0.6982738235989596, 'roc_auc': 0.9015754022789367}\n",
      "  üüß CLF RandomForestClassifier_classifier: {'accuracy': 0.9073817678350214, 'f1_score': 0.8385621745205132, 'precision': 0.9058726673984633, 'recall': 0.7805627807992433, 'roc_auc': 0.971590101610142}\n",
      "  üüß CLF XGBClassifier_classifier: {'accuracy': 0.9678641696422066, 'f1_score': 0.9461472707290267, 'precision': 0.9782828282828283, 'recall': 0.9160558051548829, 'roc_auc': 0.9925667730158555}\n",
      "  üüß CLF LGBMClassifier_classifier: {'accuracy': 0.9859360198207389, 'f1_score': 0.9769111137695896, 'precision': 0.9886198547215497, 'recall': 0.9654764719791913, 'roc_auc': 0.9984271531302293}\n",
      "  üüß CLF GradientBoostingClassifier_classifier: {'accuracy': 0.9726736136413321, 'f1_score': 0.9548138329919268, 'precision': 0.9734643734643734, 'recall': 0.9368645069756444, 'roc_auc': 0.9948908254982811}\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path('..') if Path('..').joinpath('data').exists() else Path('.')\n",
    "metrics_dir = project_root / 'data' / '08_reporting'\n",
    "reg_path = metrics_dir / 'metrics.json'\n",
    "clf_path = metrics_dir / 'metrics_clf.json'\n",
    "\n",
    "def _leer_metricas(ruta, etiqueta):\n",
    "    if ruta.exists():\n",
    "        with ruta.open() as f:\n",
    "            datos = json.load(f)\n",
    "        print(f\"‚úî {etiqueta} cargadas desde {ruta}\")\n",
    "        return datos\n",
    "    print(f\"‚úó FALTA archivo {ruta}. Ejecuta 'kedro run --pipeline {etiqueta}' para generarlo.\")\n",
    "    return {}\n",
    "\n",
    "metrics_regresion = _leer_metricas(reg_path, 'data_science_regresion')\n",
    "metrics_clasificacion = _leer_metricas(clf_path, 'data_science_clasificacion')\n",
    "\n",
    "if metrics_regresion or metrics_clasificacion:\n",
    "    print(\"\\nResumen r√°pido de m√©tricas\\n\" + \"-\"*35)\n",
    "    for nombre, valor in list(metrics_regresion.items())[:5]:\n",
    "        print(f\"  üü¶ REG {nombre}: {valor}\")\n",
    "    for nombre, valor in list(metrics_clasificacion.items())[:5]:\n",
    "        print(f\"  üüß CLF {nombre}: {valor}\")\n",
    "    print(\"-\"*35)\n",
    "else:\n",
    "    print(\"No hay m√©tricas disponibles todav√≠a.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî data_science_regresion cargadas desde ../data/08_reporting/metrics.json\n",
      "‚úî data_science_clasificacion cargadas desde ../data/08_reporting/metrics_clf.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_2e79a\">\n",
       "  <caption>M√©tricas de Regresi√≥n</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2e79a_level0_col0\" class=\"col_heading level0 col0\" >M√©trica</th>\n",
       "      <th id=\"T_2e79a_level0_col1\" class=\"col_heading level0 col1\" >Valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2e79a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_2e79a_row0_col0\" class=\"data row0 col0\" >LinearRegression_model</td>\n",
       "      <td id=\"T_2e79a_row0_col1\" class=\"data row0 col1\" >{'rmse': 141800345004.58456, 'mae': 2964902928.3594694, 'r2': -6964255627375.31}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2e79a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_2e79a_row1_col0\" class=\"data row1 col0\" >Ridge_model</td>\n",
       "      <td id=\"T_2e79a_row1_col1\" class=\"data row1 col1\" >{'rmse': 32824.3066156645, 'mae': 23965.572369407793, 'r2': 0.6268261094451105}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2e79a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_2e79a_row2_col0\" class=\"data row2 col0\" >Lasso_model</td>\n",
       "      <td id=\"T_2e79a_row2_col1\" class=\"data row2 col1\" >{'rmse': 32840.192990752825, 'mae': 23966.133853492884, 'r2': 0.6264648031069268}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2e79a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_2e79a_row3_col0\" class=\"data row3 col0\" >RandomForestRegressor_model</td>\n",
       "      <td id=\"T_2e79a_row3_col1\" class=\"data row3 col1\" >{'rmse': 15845.340337412867, 'mae': 6384.239461089723, 'r2': 0.913039250899556}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2e79a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_2e79a_row4_col0\" class=\"data row4 col0\" >XGBRegressor_model</td>\n",
       "      <td id=\"T_2e79a_row4_col1\" class=\"data row4 col1\" >{'rmse': 18479.663125002444, 'mae': 10126.569512041806, 'r2': 0.8817208407662738}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x13a4acc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_b5ea6\">\n",
       "  <caption>M√©tricas de Clasificaci√≥n</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b5ea6_level0_col0\" class=\"col_heading level0 col0\" >M√©trica</th>\n",
       "      <th id=\"T_b5ea6_level0_col1\" class=\"col_heading level0 col1\" >Valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b5ea6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b5ea6_row0_col0\" class=\"data row0 col0\" >LogisticRegression_classifier</td>\n",
       "      <td id=\"T_b5ea6_row0_col1\" class=\"data row0 col1\" >{'accuracy': 0.839612329665525, 'f1_score': 0.7285062291846552, 'precision': 0.7614749871067561, 'recall': 0.6982738235989596, 'roc_auc': 0.9015754022789367}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5ea6_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b5ea6_row1_col0\" class=\"data row1 col0\" >RandomForestClassifier_classifier</td>\n",
       "      <td id=\"T_b5ea6_row1_col1\" class=\"data row1 col1\" >{'accuracy': 0.9073817678350214, 'f1_score': 0.8385621745205132, 'precision': 0.9058726673984633, 'recall': 0.7805627807992433, 'roc_auc': 0.971590101610142}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5ea6_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b5ea6_row2_col0\" class=\"data row2 col0\" >XGBClassifier_classifier</td>\n",
       "      <td id=\"T_b5ea6_row2_col1\" class=\"data row2 col1\" >{'accuracy': 0.9678641696422066, 'f1_score': 0.9461472707290267, 'precision': 0.9782828282828283, 'recall': 0.9160558051548829, 'roc_auc': 0.9925667730158555}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5ea6_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b5ea6_row3_col0\" class=\"data row3 col0\" >LGBMClassifier_classifier</td>\n",
       "      <td id=\"T_b5ea6_row3_col1\" class=\"data row3 col1\" >{'accuracy': 0.9859360198207389, 'f1_score': 0.9769111137695896, 'precision': 0.9886198547215497, 'recall': 0.9654764719791913, 'roc_auc': 0.9984271531302293}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b5ea6_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b5ea6_row4_col0\" class=\"data row4 col0\" >GradientBoostingClassifier_classifier</td>\n",
       "      <td id=\"T_b5ea6_row4_col1\" class=\"data row4 col1\" >{'accuracy': 0.9726736136413321, 'f1_score': 0.9548138329919268, 'precision': 0.9734643734643734, 'recall': 0.9368645069756444, 'roc_auc': 0.9948908254982811}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x13a170290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizar m√©tricas en tabla amigable\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path('..') if Path('..').joinpath('data').exists() else Path('.')\n",
    "metrics_dir = project_root / 'data' / '08_reporting'\n",
    "reg_path = metrics_dir / 'metrics.json'\n",
    "clf_path = metrics_dir / 'metrics_clf.json'\n",
    "\n",
    "def _leer_metricas(ruta, etiqueta):\n",
    "    if ruta.exists():\n",
    "        with ruta.open() as f:\n",
    "            datos = json.load(f)\n",
    "        print(f\"‚úî {etiqueta} cargadas desde {ruta}\")\n",
    "        return datos\n",
    "    print(f\"‚úó FALTA archivo {ruta}. Ejecuta 'kedro run --pipeline {etiqueta}' para generarlo.\")\n",
    "    return {}\n",
    "\n",
    "metrics_regresion = _leer_metricas(reg_path, 'data_science_regresion')\n",
    "metrics_clasificacion = _leer_metricas(clf_path, 'data_science_clasificacion')\n",
    "\n",
    "# Mostrar tabla de m√©tricas de regresi√≥n\n",
    "if metrics_regresion:\n",
    "    df_reg = pd.DataFrame(list(metrics_regresion.items()), columns=['M√©trica', 'Valor'])\n",
    "    df_reg['Valor'] = df_reg['Valor'].apply(lambda x: f\"{x:.4f}\" if isinstance(x, float) else x)\n",
    "    display(df_reg.head(5).style.set_caption('M√©tricas de Regresi√≥n').format(precision=4))\n",
    "else:\n",
    "    print(\"No hay m√©tricas de regresi√≥n disponibles.\")\n",
    "\n",
    "# Mostrar tabla de m√©tricas de clasificaci√≥n\n",
    "if metrics_clasificacion:\n",
    "    df_clf = pd.DataFrame(list(metrics_clasificacion.items()), columns=['M√©trica', 'Valor'])\n",
    "    df_clf['Valor'] = df_clf['Valor'].apply(lambda x: f\"{x:.4f}\" if isinstance(x, float) else x)\n",
    "    display(df_clf.head(5).style.set_caption('M√©tricas de Clasificaci√≥n').format(precision=4))\n",
    "else:\n",
    "    print(\"No hay m√©tricas de clasificaci√≥n disponibles.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RESUMEN COMPARATIVO DE LOS 5 MODELOS DE CLASIFICACI√ìN\n",
      "================================================================================\n",
      "\n",
      "LGBMClassifier (Mejor Modelo - 98.49%):\n",
      "  ‚Ä¢ Accuracy:  0.9859\n",
      "  ‚Ä¢ F1-Score:  0.9769\n",
      "  ‚Ä¢ Precision: 0.9886\n",
      "  ‚Ä¢ Recall:    0.9655\n",
      "  ‚Ä¢ ROC-AUC:   0.9984\n",
      "\n",
      "GradientBoostingClassifier (97.59%):\n",
      "  ‚Ä¢ Accuracy:  0.9727\n",
      "  ‚Ä¢ F1-Score:  0.9548\n",
      "  ‚Ä¢ Precision: 0.9735\n",
      "  ‚Ä¢ Recall:    0.9369\n",
      "  ‚Ä¢ ROC-AUC:   0.9949\n",
      "\n",
      "XGBClassifier (96.91%):\n",
      "  ‚Ä¢ Accuracy:  0.9679\n",
      "  ‚Ä¢ F1-Score:  0.9461\n",
      "  ‚Ä¢ Precision: 0.9783\n",
      "  ‚Ä¢ Recall:    0.9161\n",
      "  ‚Ä¢ ROC-AUC:   0.9926\n",
      "\n",
      "RandomForestClassifier (92.52%):\n",
      "  ‚Ä¢ Accuracy:  0.9074\n",
      "  ‚Ä¢ F1-Score:  0.8386\n",
      "  ‚Ä¢ Precision: 0.9059\n",
      "  ‚Ä¢ Recall:    0.7806\n",
      "  ‚Ä¢ ROC-AUC:   0.9716\n",
      "\n",
      "LogisticRegression (83.91%):\n",
      "  ‚Ä¢ Accuracy:  0.8396\n",
      "  ‚Ä¢ F1-Score:  0.7285\n",
      "  ‚Ä¢ Precision: 0.7615\n",
      "  ‚Ä¢ Recall:    0.6983\n",
      "  ‚Ä¢ ROC-AUC:   0.9016\n",
      "\n",
      "================================================================================\n",
      "MODELO GANADOR: LGBMClassifier con 98.49% de accuracy\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Imprimir m√©tricas clave de los 5 modelos\n",
    "if 'metrics_clasificacion' not in globals():\n",
    "    print(\"ERROR: La variable 'metrics_clasificacion' no est√° definida.\")\n",
    "    print(\"Ejecuta la celda que carga las m√©tricas de clasificaci√≥n antes de esta celda (ver celda 11).\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RESUMEN COMPARATIVO DE LOS 5 MODELOS DE CLASIFICACI√ìN\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    for modelo_key, titulo in modelos_viz:\n",
    "        print(f\"\\n{titulo}:\")\n",
    "        print(f\"  ‚Ä¢ Accuracy:  {metrics_clasificacion[modelo_key]['accuracy']:.4f}\")\n",
    "        print(f\"  ‚Ä¢ F1-Score:  {metrics_clasificacion[modelo_key]['f1_score']:.4f}\")\n",
    "        print(f\"  ‚Ä¢ Precision: {metrics_clasificacion[modelo_key]['precision']:.4f}\")\n",
    "        print(f\"  ‚Ä¢ Recall:    {metrics_clasificacion[modelo_key]['recall']:.4f}\")\n",
    "        print(f\"  ‚Ä¢ ROC-AUC:   {metrics_clasificacion[modelo_key]['roc_auc']:.4f}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MODELO GANADOR: LGBMClassifier con 98.49% de accuracy\")\n",
    "    print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANTE: Entendiendo la Normalizacion de Datos\n",
    "\n",
    "**NOTA CRITICA**: Los valores numericos en el dataset procesado estan **NORMALIZADOS** usando StandardScaler.\n",
    "\n",
    "### Que significa esto?\n",
    "\n",
    "Los modelos de Machine Learning funcionan mejor cuando todas las variables tienen escalas similares. Por ejemplo:\n",
    "- WorkExp: valores entre 0-50 (a√±os)\n",
    "- ConvertedCompYearly: valores entre 0-500,000 (USD)\n",
    "\n",
    "Sin normalizacion, el modelo daria mas importancia a CompTotal solo por tener valores mas grandes.\n",
    "\n",
    "### Formula de Normalizacion (StandardScaler):\n",
    "\n",
    "```\n",
    "valor_normalizado = (valor_original - media) / desviacion_estandar\n",
    "```\n",
    "\n",
    "### Como Interpretar Valores Normalizados:\n",
    "\n",
    "| Valor Normalizado | Significado | Ejemplo WorkExp |\n",
    "|-------------------|-------------|-----------------|\n",
    "| -2.0 | Muy por debajo del promedio | ~0 a√±os (recien graduado) |\n",
    "| -1.0 | Bajo el promedio | ~2-3 a√±os |\n",
    "| -0.5 | Ligeramente bajo | ~5-6 a√±os |\n",
    "| 0.0 | Promedio exacto | ~8 a√±os |\n",
    "| +0.5 | Ligeramente alto | ~10-11 a√±os |\n",
    "| +1.0 | Sobre el promedio | ~14-15 a√±os |\n",
    "| +2.0 | Muy alto | ~20+ a√±os |\n",
    "\n",
    "### Ejemplo Real:\n",
    "\n",
    "**Desarrollador con WorkExp = -0.256558 (normalizado)**\n",
    "- Interpretacion: Experiencia ligeramente BAJO el promedio\n",
    "- Valor aproximado real: 6-7 a√±os de experiencia\n",
    "\n",
    "**Variables Binarias (LearnCode_*, LanguageHaveWorkedWith_*, etc.)**\n",
    "- NO se normalizan (son 0 o 1)\n",
    "- 1 = La persona tiene esa caracteristica\n",
    "- 0 = La persona NO tiene esa caracteristica\n",
    "\n",
    "---\n",
    "\n",
    "###  Visualizaci√≥n de Salarios: Datos Reales vs Normalizados\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANTE**: Para la **visualizaci√≥n de distribuci√≥n de salarios**, se cargan los **datos REALES** (no normalizados) desde StackOverflow 2023, ya que los datos procesados est√°n en escala normalizada (-3 a +3) y no son interpretables en gr√°ficos.\n",
    "\n",
    "**Filtrado de Outliers Extremos:**\n",
    "- Se muestran salarios en el rango **$0 - $300,000 USD** para mejor legibilidad\n",
    "- Los outliers extremos (>$300K) se excluyen de la visualizaci√≥n pero NO del entrenamiento\n",
    "- Ejemplo de outliers: Algunos registros reportan salarios de $74 millones (probablemente errores de captura)\n",
    "- **Total real**: ~48,000 desarrolladores, de los cuales ~975 tienen salarios >$300K\n",
    "\n",
    "**Estad√≠sticas del mercado real:**\n",
    "- **Mediana**: $74,963 USD (salario t√≠pico de un desarrollador)\n",
    "- **Media**: $103,110 USD (inflada por outliers altos)\n",
    "- **Q1 (25%)**: $43,907 USD\n",
    "- **Q3 (75%)**: $121,641 USD\n",
    "\n",
    "A continuacion se muestra el dataset procesado (normalizado) que es el input al modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Data Understanding: Exploraci√≥n del Dataset\n",
    "\n",
    "Antes de analizar los resultados de los modelos, es fundamental entender la estructura y caracter√≠sticas de los datos con los que trabajamos. Esta secci√≥n cumple con los requisitos de la metodolog√≠a **CRISP-DM** (fase de Data Understanding)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cargar los Artefactos de los Pipelines\n",
    "\n",
    "Ahora que tenemos acceso al `catalog`, lo usamos para cargar todos los \"artefactos\" (resultados) que fueron generados y guardados por nuestros pipelines de `regresion` y `clasificacion`.\n",
    "\n",
    "Cada l√≠nea de c√≥digo `catalog.load(\"...\")` busca en el archivo `conf/base/catalog.yml` el dataset con ese nombre y lo carga en una variable de Python:\n",
    "\n",
    "*   `catalog.load(\"metrics\")`: Carga el archivo `metrics.json` con los resultados del pipeline de regresi√≥n.\n",
    "*   `catalog.load(\"metrics_clf\")`: Carga el archivo `metrics_clf.json` con los resultados del pipeline de clasificaci√≥n.\n",
    "*   `catalog.load(\"classification_confusion_matrices\")`: Carga las matrices de confusi√≥n.\n",
    "*   `catalog.load(\"regresion_model\")` y `catalog.load(\"clasificacion_model\")`: Cargan los archivos `.pkl` que contienen los objetos de los modelos entrenados.\n",
    "\n",
    "**Significado de la Salida:**\n",
    "\n",
    "La salida de la celda es simplemente la impresi√≥n (`print`) de los diccionarios de m√©tricas que acabamos de cargar. Esto nos sirve como una verificaci√≥n r√°pida para confirmar que los datos se han cargado correctamente en las variables `metrics_regresion` y `metrics_clasificacion` antes de proceder a analizarlos en detalle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Modelo",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "RMSE (USD)",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "MAE (USD)",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "R¬≤ Score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "d7a42867-2e29-4975-a685-861665ffeb13",
       "rows": [
        [
         "0",
         "RandomForestRegressor_model",
         "15845",
         "6384",
         "0.913"
        ],
        [
         "1",
         "XGBRegressor_model",
         "18480",
         "10127",
         "0.8817"
        ],
        [
         "2",
         "Ridge_model",
         "32824",
         "23966",
         "0.6268"
        ],
        [
         "3",
         "Lasso_model",
         "32840",
         "23966",
         "0.6265"
        ],
        [
         "4",
         "LinearRegression_model",
         "141800345005",
         "2964902928",
         "-6964255627375.31"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RMSE (USD)</th>\n",
       "      <th>MAE (USD)</th>\n",
       "      <th>R¬≤ Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestRegressor_model</td>\n",
       "      <td>15845</td>\n",
       "      <td>6384</td>\n",
       "      <td>9.130000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBRegressor_model</td>\n",
       "      <td>18480</td>\n",
       "      <td>10127</td>\n",
       "      <td>8.817000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge_model</td>\n",
       "      <td>32824</td>\n",
       "      <td>23966</td>\n",
       "      <td>6.268000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso_model</td>\n",
       "      <td>32840</td>\n",
       "      <td>23966</td>\n",
       "      <td>6.265000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LinearRegression_model</td>\n",
       "      <td>141800345005</td>\n",
       "      <td>2964902928</td>\n",
       "      <td>-6.964256e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "                        Modelo    RMSE \u001b[1m(\u001b[0mUSD\u001b[1m)\u001b[0m   MAE \u001b[1m(\u001b[0mUSD\u001b[1m)\u001b[0m      R¬≤ Score\n",
       "\u001b[1;36m0\u001b[0m  RandomForestRegressor_model         \u001b[1;36m15845\u001b[0m        \u001b[1;36m6384\u001b[0m  \u001b[1;36m9.130000e-01\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m           XGBRegressor_model         \u001b[1;36m18480\u001b[0m       \u001b[1;36m10127\u001b[0m  \u001b[1;36m8.817000e-01\u001b[0m\n",
       "\u001b[1;36m2\u001b[0m                  Ridge_model         \u001b[1;36m32824\u001b[0m       \u001b[1;36m23966\u001b[0m  \u001b[1;36m6.268000e-01\u001b[0m\n",
       "\u001b[1;36m3\u001b[0m                  Lasso_model         \u001b[1;36m32840\u001b[0m       \u001b[1;36m23966\u001b[0m  \u001b[1;36m6.265000e-01\u001b[0m\n",
       "\u001b[1;36m4\u001b[0m       LinearRegression_model  \u001b[1;36m141800345005\u001b[0m  \u001b[1;36m2964902928\u001b[0m \u001b[1;36m-6.964256e+12\u001b[0m"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar m√©tricas de regresi√≥n en formato tabular\n",
    "# metrics_regresion ya est√° disponible en el notebook (dict)\n",
    "df_metrics_reg = pd.DataFrame.from_dict(metrics_regresion, orient='index').reset_index()\n",
    "df_metrics_reg = df_metrics_reg.rename(columns={'index': 'Modelo', 'rmse': 'RMSE (USD)', 'mae': 'MAE (USD)', 'r2': 'R¬≤ Score'})\n",
    "df_metrics_reg = df_metrics_reg.sort_values('R¬≤ Score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Formateo para presentaci√≥n\n",
    "df_metrics_reg['R¬≤ Score'] = df_metrics_reg['R¬≤ Score'].round(4)\n",
    "df_metrics_reg['RMSE (USD)'] = df_metrics_reg['RMSE (USD)'].round(0).astype('Int64')\n",
    "df_metrics_reg['MAE (USD)'] = df_metrics_reg['MAE (USD)'].round(0).astype('Int64')\n",
    "\n",
    "df_metrics_reg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaci√≥n de M√©tricas con JSON\n",
    "\n",
    "Esta celda toma la variable `metrics_regresion` (que es un diccionario de Python) y la muestra en un formato m√°s legible.\n",
    "\n",
    "*   `import json`: Importa la librer√≠a est√°ndar de Python para trabajar con el formato JSON.\n",
    "*   `json.dumps(..., indent=4)`: Esta funci√≥n, a menudo llamada \"pretty-print\" (impresi√≥n bonita), convierte el diccionario de Python en un texto con formato JSON, usando 4 espacios de indentaci√≥n.\n",
    "\n",
    "**Es exactamente la misma informaci√≥n** que se carg√≥ del cat√°logo, pero en lugar de verla como un diccionario de Python en una sola l√≠nea, la vemos estructurada y anidada, lo que facilita enormemente su lectura y comparaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mFigure\u001b[0m\u001b[39m size 140\u001b[0m\u001b[1;36m0x700\u001b[0m\u001b[39m with \u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m Axes\u001b[0m\u001b[1m>\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configurar estilo moderno y elegante\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# --- Preparar los datos para el gr√°fico ---\n",
    "# Extraemos el nombre del modelo y su m√©trica R2\n",
    "# Ignoramos LinearRegression porque su valor es tan bajo que distorsionar√≠a el gr√°fico\n",
    "r2_scores = {\n",
    "    model.replace('_model', ''): result['r2']\n",
    "    for model, result in metrics_regresion.items()\n",
    "    if 'LinearRegression' not in model\n",
    "}\n",
    "\n",
    "# Creamos un DataFrame de pandas para facilitar el ploteo\n",
    "df_r2 = pd.DataFrame(list(r2_scores.items()), columns=['Modelo', 'R2 Score']).sort_values('R2 Score', ascending=False)\n",
    "\n",
    "# Paleta de colores moderna: de mejor a peor (verde oscuro -> amarillo)\n",
    "colores_modernos = ['#2ECC71', '#3498DB', '#F39C12', '#E74C3C']\n",
    "\n",
    "# --- Crear el gr√°fico ---\n",
    "plt.figure(figsize=(14, 7))\n",
    "barplot = sns.barplot(x='R2 Score', y='Modelo', data=df_r2, palette=colores_modernos, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# A√±adir el valor exacto en cada barra para mayor claridad\n",
    "for index, value in enumerate(df_r2['R2 Score']):\n",
    "    plt.text(value + 0.02, index, f'{value:.4f}', color='black', ha=\"left\", va=\"center\", weight='bold', fontsize=13)\n",
    "\n",
    "# --- T√≠tulos y etiquetas---\n",
    "plt.title('Comparaci√≥n de Modelos de Regresi√≥n por R¬≤ Score', fontsize=18, weight='bold', pad=20)\n",
    "plt.xlabel('R¬≤ Score (M√°s alto es mejor)', fontsize=13, weight='bold')\n",
    "plt.ylabel('Modelo', fontsize=13, weight='bold')\n",
    "plt.xlim(0, 1.05)  # El R2 Score va de 0 a 1\n",
    "plt.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones del An√°lisis de Regresi√≥n\n",
    "\n",
    "El gr√°fico de barras anterior compara el rendimiento de los diferentes modelos de regresi√≥n utilizando la m√©trica **R¬≤ Score**.\n",
    "\n",
    "**Observaciones:**\n",
    "\n",
    "1.  **Ganador Claro:** El modelo `RandomForestRegressor` es notablemente superior a los dem√°s, con un **R¬≤ de 0.909**. Esto indica que es capaz de explicar casi el 91% de la variabilidad en los salarios, lo cual es un resultado excelente.\n",
    "2.  **Modelos de Boosting:** `XGBRegressor` tambi√©n muestra un rendimiento muy fuerte con un R¬≤ de 0.876, consolidando la idea de que los modelos basados en ensambles de √°rboles son muy efectivos para este conjunto de datos.\n",
    "3.  **Modelos Lineales:** Los modelos `Ridge` y `Lasso`, aunque muy superiores a la regresi√≥n lineal simple (cuyo R¬≤ era masivamente negativo), se quedan en un R¬≤ de ~0.60. Esto sugiere que la relaci√≥n entre las caracter√≠sticas y el salario no es puramente lineal y que estos modelos no pueden capturar la complejidad de los datos tan bien como los modelos de √°rboles.\n",
    "\n",
    "**Conclusi√≥n:** Para la tarea de predecir el salario, el `RandomForestRegressor` es la elecci√≥n recomendada debido a su alto poder predictivo y su bajo error promedio (como vimos en las m√©tricas, un MAE de solo ~$6,181)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo: LGBMClassifier ‚Äî F1: 0.9769, Accuracy: 0.9859, ROC-AUC: 0.9984\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Rank",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Modelo",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Accuracy",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "F1-Score",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Precision",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Recall",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ROC-AUC",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "813af02a-cac5-4ea3-a56a-17f583637331",
       "rows": [
        [
         "0",
         "1",
         "LGBMClassifier",
         "98.59%",
         "97.69%",
         "98.86%",
         "96.55%",
         "99.84%"
        ],
        [
         "1",
         "2",
         "GradientBoostingClassifier",
         "97.27%",
         "95.48%",
         "97.35%",
         "93.69%",
         "99.49%"
        ],
        [
         "2",
         "3",
         "XGBClassifier",
         "96.79%",
         "94.61%",
         "97.83%",
         "91.61%",
         "99.26%"
        ],
        [
         "3",
         "4",
         "RandomForestClassifier",
         "90.74%",
         "83.86%",
         "90.59%",
         "78.06%",
         "97.16%"
        ],
        [
         "4",
         "5",
         "LogisticRegression",
         "83.96%",
         "72.85%",
         "76.15%",
         "69.83%",
         "90.16%"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>98.59%</td>\n",
       "      <td>97.69%</td>\n",
       "      <td>98.86%</td>\n",
       "      <td>96.55%</td>\n",
       "      <td>99.84%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>97.27%</td>\n",
       "      <td>95.48%</td>\n",
       "      <td>97.35%</td>\n",
       "      <td>93.69%</td>\n",
       "      <td>99.49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>96.79%</td>\n",
       "      <td>94.61%</td>\n",
       "      <td>97.83%</td>\n",
       "      <td>91.61%</td>\n",
       "      <td>99.26%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>90.74%</td>\n",
       "      <td>83.86%</td>\n",
       "      <td>90.59%</td>\n",
       "      <td>78.06%</td>\n",
       "      <td>97.16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>83.96%</td>\n",
       "      <td>72.85%</td>\n",
       "      <td>76.15%</td>\n",
       "      <td>69.83%</td>\n",
       "      <td>90.16%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "   Rank                      Modelo Accuracy F1-Score Precision  Recall  \\\n",
       "\u001b[1;36m0\u001b[0m     \u001b[1;36m1\u001b[0m              LGBMClassifier   \u001b[1;36m98.59\u001b[0m%   \u001b[1;36m97.69\u001b[0m%    \u001b[1;36m98.86\u001b[0m%  \u001b[1;36m96.55\u001b[0m%   \n",
       "\u001b[1;36m1\u001b[0m     \u001b[1;36m2\u001b[0m  GradientBoostingClassifier   \u001b[1;36m97.27\u001b[0m%   \u001b[1;36m95.48\u001b[0m%    \u001b[1;36m97.35\u001b[0m%  \u001b[1;36m93.69\u001b[0m%   \n",
       "\u001b[1;36m2\u001b[0m     \u001b[1;36m3\u001b[0m               XGBClassifier   \u001b[1;36m96.79\u001b[0m%   \u001b[1;36m94.61\u001b[0m%    \u001b[1;36m97.83\u001b[0m%  \u001b[1;36m91.61\u001b[0m%   \n",
       "\u001b[1;36m3\u001b[0m     \u001b[1;36m4\u001b[0m      RandomForestClassifier   \u001b[1;36m90.74\u001b[0m%   \u001b[1;36m83.86\u001b[0m%    \u001b[1;36m90.59\u001b[0m%  \u001b[1;36m78.06\u001b[0m%   \n",
       "\u001b[1;36m4\u001b[0m     \u001b[1;36m5\u001b[0m          LogisticRegression   \u001b[1;36m83.96\u001b[0m%   \u001b[1;36m72.85\u001b[0m%    \u001b[1;36m76.15\u001b[0m%  \u001b[1;36m69.83\u001b[0m%   \n",
       "\n",
       "  ROC-AUC  \n",
       "\u001b[1;36m0\u001b[0m  \u001b[1;36m99.84\u001b[0m%  \n",
       "\u001b[1;36m1\u001b[0m  \u001b[1;36m99.49\u001b[0m%  \n",
       "\u001b[1;36m2\u001b[0m  \u001b[1;36m99.26\u001b[0m%  \n",
       "\u001b[1;36m3\u001b[0m  \u001b[1;36m97.16\u001b[0m%  \n",
       "\u001b[1;36m4\u001b[0m  \u001b[1;36m90.16\u001b[0m%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Mejorar la visualizaci√≥n de metrics_clasificacion en formato tabular ordenado y legible\n",
    "df_clf = pd.DataFrame.from_dict(metrics_clasificacion, orient='index').reset_index().rename(columns={'index': 'Modelo'})\n",
    "\n",
    "# Limpiar nombres de modelo\n",
    "df_clf['Modelo'] = df_clf['Modelo'].str.replace('_classifier', '', regex=False).str.replace('_model', '', regex=False)\n",
    "\n",
    "# Ordenar por F1-Score descendente (mejor a peor)\n",
    "df_clf = df_clf.sort_values('f1_score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Crear columnas formateadas en porcentaje con 2 decimales para mostrar\n",
    "df_display = df_clf.copy()\n",
    "for col in ['accuracy', 'f1_score', 'precision', 'recall', 'roc_auc']:\n",
    "    df_display[col] = (df_display[col] * 100).round(2).astype(str) + '%'\n",
    "\n",
    "# Renombrar columnas para presentaci√≥n\n",
    "df_display = df_display.rename(columns={\n",
    "    'accuracy': 'Accuracy',\n",
    "    'f1_score': 'F1-Score',\n",
    "    'precision': 'Precision',\n",
    "    'recall': 'Recall',\n",
    "    'roc_auc': 'ROC-AUC'\n",
    "})\n",
    "\n",
    "# Agregar columna de ranking\n",
    "df_display.insert(0, 'Rank', range(1, len(df_display) + 1))\n",
    "\n",
    "# Mostrar resumen r√°pido y la tabla ordenada\n",
    "best = df_clf.iloc[0]\n",
    "print(f\"Mejor modelo: {best['Modelo']} ‚Äî F1: {best['f1_score']:.4f}, Accuracy: {best['accuracy']:.4f}, ROC-AUC: {best['roc_auc']:.4f}\\n\")\n",
    "\n",
    "display(df_display[['Rank', 'Modelo', 'Accuracy', 'F1-Score', 'Precision', 'Recall', 'ROC-AUC']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaci√≥n Pretty-Print\n",
    "\n",
    "Esta celda toma la variable `metrics_clasificacion` (que es un diccionario de Python) y la muestra en un formato m√°s legible.\n",
    "\n",
    "**Es exactamente la misma informaci√≥n** que se carg√≥ del cat√°logo, pero en lugar de verla como un diccionario de Python en una sola l√≠nea, la vemos estructurada y anidada, lo que facilita enormemente su lectura y comparaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matrices_confusion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m ax \u001b[38;5;241m=\u001b[39m axes_flat[idx]\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 35\u001b[0m     matriz \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mmatrices_confusion\u001b[49m[modelo_key])\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# Dibujamos el heatmap con el colormap moderno\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     sns\u001b[38;5;241m.\u001b[39mheatmap(matriz, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m, cmap\u001b[38;5;241m=\u001b[39mcmap_moderno, ax\u001b[38;5;241m=\u001b[39max,\n\u001b[1;32m     39\u001b[0m                 xticklabels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicho No\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicho S√≠\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     40\u001b[0m                 yticklabels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReal No\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReal S√≠\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     41\u001b[0m                 cbar_kws\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCantidad\u001b[39m\u001b[38;5;124m'\u001b[39m},\n\u001b[1;32m     42\u001b[0m                 linewidths\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, linecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhite\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matrices_confusion' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABkwAAARRCAYAAABkJa4+AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAhwRJREFUeJzs3QuYHFWZMP4zMQlIHHAVSDTITSXhQwVhQaJi1ACS4MpFDKjLZb1w3V34QMEgCoIksEJwBSSoGCP6gbi7KHhZJLtxuZh4CYqgwIIGgWACGE3ikpAA9X/e+juzPT09M92TmemZPr/f89STdE9fqk+dqjp13jrvaUspFQkAAAAAACBjo5q9AgAAAAAAAM0mYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyNzr7EgAgGyeccEKaMGFC+f+nn346XXbZZenZZ59t9moBMII5twAw0k2aNCkdddRRnY8XLlyY7rzzzqauE0CzCJgAkIUjjjgizZs3r/x/BEkOP/xwwRIAnFsAyNqYMWPSddddl17/+teXj2+77bZ00UUXNXu1AJpGSi4AhrX58+enoii6LFOnTm3oM2JUSUewpONu4JtvvjmNRPHbq8sjyoiRYdGiRd223w477NDs1RpRjj322G5leO655zZ7tbK1xx57pGuuuSY98MAD6c9//nOX7fLHP/4xDVfOLbTyedu5ZmD28ZEg2hDVvzO2fyvtE+3t7enjH/94Wrx4cVq1alV5w1Plew855JDyddEWqP7caDO0soHa/p/61Kc6gyW//OUv09/8zd+kZ555ZhDWGGBkEDABBsQuu+ySPvrRj6bvfve76cEHHywbsxs2bCj/vfvuu9NXv/rVdMwxx6QXv/jFSpwh9+Uvfzm99KUvLf8/a9as8jEDr/qCrWN5+OGHU1tbW6/v3X///Xt8v85wRqotttgiHX300WVAITogfv/735cdEGvXrk3Lli0rz5lxTNptt93SSPT+978//eQnP0kf+MAHynbAuHHjUk5a8dxSq6O9r+Ud73jHgHb2dSy33357n+//0Ic+1OP7W72jlNYxceLE9A//8A/pX//1X8vg81NPPVVeR/3pT39Kv/71r9M3vvGNLqn/cvKyl70s/fznP0+f/vSn07777pv+6q/+Kr3gBS9o9mq1lDe+8Y3pzDPPLP8fbZM4pq9Zs6bZqwXQVFJyAZtkp512Sv/0T/+UDjvssJqN12jUxvK6172u7DT6n//5n3TqqaeWnUcwFE466aQ0ffr08v+f/exnDS9vgugQO/jgg9N3vvOdHl9z8sknp2aJTrWvfOUrXZ4777zzyrvtoD/ifHjWWWel008/vbNDvdLYsWPTi170orTjjjumGTNmpNmzZ6cf/OAHm9TxPNTiBojPf/7zZRqPHDm3DL43v/nN6TWveU269957e90OMFJtvfXWZbs0rpHivFBtq622Kpddd901zZw5M33uc59LF154YTr//PNTLuI685WvfGWzV6NlxY0OcWNjtFueeOKJsh2yYsWKZq8WQNMJmAD99s53vrNsYEVApJFGWVz8Qr2iEzHusKv02GOP1fXeV73qVekzn/lM+f//9//+X/q///f/KvgmiU6tngImcWdlDP3Pwb/8y7+kX/ziF12ecxdfaxk/fny5naOztxH77LNPGkkOPPDAtOWWW3Z5bt26delb3/pWWrlyZefj4cq5ZeScO0455ZSaf4u7zffcc88hXycYCG94wxvKc8V2221X93siqNKRNmkki3Z83MRUKUYrVhs1alRnuq1KMRF5jDqJ1FzhN7/5TfnvkiVLun1ujNBpZdGGrP7NDz30UN3vv+yyy8qAVIx8jRs4IlMEAAImQD+99a1vLYeN17obKnKW/9d//VeZeuSFL3xheQdtXBTE/6FRMQFhLP0RFwxxFzfNF3esxbEg0nNVO/7449Po0Xncw3HllVc2exUY5BRc//7v/17O61EtOnZ+/OMfl+lWItVKBFbi3Pjyl798xI4wrRYjZSJtykjg3FJ/YKmvDsdax/WB8rd/+7dlqpgYoVzN6BJGqhgxcsstt5SjR6rFXFAx4fYjjzxSjuB7xSteUQYHqwPUI1kEOOq5iWmbbbYp5y+pFB36Pd2QEGUaS07iuntTbgiLNngsAHSVR+8EMKAivUjcEVUdLNm4cWM6++yz0z//8z+X/6+0+eabp/e9733pYx/7mK0BGYqh/pF/O/L8V4pASeSgh1Zw1VVX1QyWfO973yvTzv3ud7/r9rcpU6akM844I7397W9PI0mc16s9+uijTVkXBk+MzlywYEHTijg6iSNocvXVV3d5/iUveUl6z3ve07T1gv6KIMi3v/3tmsGSSD8V6baqA4TRhjr88MPLVI85qXWeWb58eVPWBYC8mPQdaFgEPWrlZD/qqKPSJZdc0i1YEtavX19OhhrpuL72ta/1+Nlx8XDaaaeVE+HGnVVxwRBL/P/mm28uJ0TsbcTA1KlTu036OX/+/PJvb3vb29JNN91UpgqJYccxlDu+qzL/+mabbVbmnI+/xWvirp3//M//7PWivLfvjN8b87XEBHqRmiRG3cTInP3226/Hz4v1iVQnEXz6t3/7tzJ9T/z+uOMsJgt+8skn009/+tOyY+4tb3lL6k2sR/W6xfrGEPcPf/jD5R1s8XnPPfdc5zqHnXfeOR133HHpiiuuSHfccUd5R3S8Lu6KjqHfcTdpbI+YjyY6LeoR3xlz3cT3xN2qf/jDH8rf8/jjj6elS5eWd96/613v6jbSoKff0JO4qIy6GJ08cRfa6tWry/oXZR+/Ny5Et99++17XNbZX9Xd2XLhFx2akDYg0YbFNYvvEPlHroq6/8wJEfuooo6effrrMJxx3+B5xxBGbdCdjXIRHqoLISxzlHuV/1113lSnLInXZYInv6hATQ1fPdxB1ovIO+8rX95XeL9ICxjwjcbyICbUjxUOUWexrsZ9HyoZINdBT+oqOyY2r5y/pmMOkt8nn4/89TTAcx4sYZRB1LkYVxPdUf2flEnO8DPR+M9DbP+ahirKMERJxLIjPiPofx4I4Hl177bXlHY4DkSok6kPkaY8RYrEt47dGmqdp06b1+zMj3VV8Zvzm2Kdi/ePfxYsXl3UoJpXdVHG8j47dajfeeGOZcq5WsCTEOsT+HfW5NzEPUJxH77vvvvLcFL8h6nlsk9iO/+f//J9e399T3es4H8TI0JhoOPah+++/P82ZM6dmh17H8TH2kWqxL9XaZ2pN7F25X9SzntVivY888sh0ww03lOsb56Zof8RviMfxObHN42aNGM1TrRXOLXHM6e04NVJVnwdqjST54Ac/2GXkcr3njurj2ty5c8tjWMdxYdWqVelXv/pV+tKXvlS2xXI5b0c9i+NAtDujnkYbOI6/0Tl96623lnUx5tvoS6T0iQDbPffcU9blaDfG8Sr2mWhPzps3L/3d3/1dn/tKPWKEXkyGHueIWNdY7/j8XXbZpV+f19bWlt797neX6YbjGBLrHft4lMH3v//9Mug9EG29uJv/1a9+dbfn4/ojAiK1RlNFO/2b3/xm2nvvvdPFF1/cr+8diHbTQLULert2qmxj1Rq9FlkOKt8X272etllv7YNIaRXH3yiD+B1xHom5k2IkYlwPVaefHshrtUoxmuiTn/xk+o//+I+y3sW2iXPbf//3f5d1MOpI9XwujZxfK6/z4pgV+2TH8SX21/ieuE6PY1ecY/tz7ok6Gts+yiP2n/j8uNHyr//6r+suB4DhIlrqFmWgDqgDddWBMWPGFGvWrCmqXXvttZtch4499thi9erVRV9WrVpVzJw5s+ZnTJ06tdvr58+fX1xwwQU9ft5//ud/Fi984QuLCRMmFD/72c96fN1nPvOZhr7zhBNOKJ555pman/Xcc88V5557bs3P22233YpG3HTTTcWWW25Z87NiPaq9853vLG677baa69zxvm9+85t1f39sj8MPP7zXbbvPPvsUDzzwQF2ft8MOO/T5G6LMa33P3nvvXTz44IN9fseGDRuK2bNnF6NGjar5OcuWLev2nl122aXXz77zzjvLerQp+0Bs++XLl/f4HTfccEOx//7797rtKpdYn2uuuaasb32Vx6c//emira1tk9a/lq9//etdHr/3ve/t8p5FixZ1+fvXvva1bp9Ra185+OCDi0Z86UtfKkaPHt3rd/elcj3i/9U++MEPltuoWnxPb99ZXecHYr8ZyO3/iU98os/P6LBx48ZNqkNvfetbiz/96U89fv5ll11Wniuq9XQ8felLX1oeI/vyP//zP8Upp5yySet+9dVXd/vc+C1/9Vd/tUmf+6pXvarXc1OH2EaxvXs6DtWqe294wxuKn/zkJz1+5v33319su+22fR4fe9KxXaJ+9rZf9LWe1fX7JS95SbFkyZK61+OLX/xit+9phXNLI/tCvUt1+V9yySXFP/7jPxZz5swp21Lx/ze96U1le3BTvqdjqVU3opzid1eaMmVK53viWPXQQw91qfvV55oQ5VPrO1/0ohfVfH0tP/rRj4rtt99+xJ23GznXTJ8+vVixYkVdx8nY/rU+Y7PNNituvvnmol633nrrJtWbj3zkI8Wzzz7b43oeddRRDe3ju+++e/HrX/+6z/V+7LHHiv3222+T1r3WeT3a5QO5D9U6vg5Eu2mg2gU9XTv11sbqSRwventfT8eBuO77/ve/X9d3VH/GQF6rxRLH07lz55b7dV+qjx2NnF9je0Y7KrZJX2J/eN3rXtfQuSeOST3tl/Hb3v3ud2/SvmNRBuqAOpCGtgwUuDJQB9SB+utArQZuiM6ETSnHM888s2jUSSedVNf6Pfnkk31+VjQe46K4L9OmTavrO3/3u9/VdSFx/PHHd/u8RhvhIS5Sa5VrrYvFRx55pOZn9DdgEiIwtO+++9Zch3e84x09Bo4GMmASF7Dr169vaL2vu+66uju16ulMuPDCC/u9D0TH7uOPP97nd9xzzz11dbxE50U9dbr64nhT9uNaomOtp06BXXfdtcvfohPhuOOOG5SASbj88ssHNWDS077Vn4DJpu43A7X9I4DRiE0JmLz61a8u1q5d2699oFYdiU71//7v/25o/c8555x+r3+t48aVV165SfvUpEmTyqB0I2Ifq9WZXavu1XNci47lvn7nUAdMvvKVrxSN2JSAyXA+twxFwKQncb46/fTTNznQ3lPA5P3vf3+X57761a92vueggw7q8rcf/OAHdXeURkDipz/9adGI2Ea1gibD+bxd77kmAgv1dnx3uOiii7p9znnnndfQZ2xKwKS6bvTUORsB33r28Wi/RpClXnFufvvb3z5g9T285z3vGXYBk1rtpoFqFzQ7YLLddtsVjz76aN3fsakBk96u1SKIEftDvfobMIljdSNBzfDnP/+52Guvveo699RzLoubSLbeeutNOmdYlIE6oA6kISoDc5gADYlhy9UiLcXPfvazfpfkG9/4xjL1R7UYyhtpAGJIcEwYXT0xbsyVEkOJY9h/bzpSCMQ6RiqD+L5InVIpUnN1DHmPYeqRkiGGrVenH4iUYDFMui8dqQZiaHMMi44c3JFOpXrCxkhhFulaYuh2tRgeH0O8428xNDyGecfEh5F2JYY7Vw6VjnWNNF+33357XcO9Q6SHiXWL37zbbrt1pgapFMPcIy1OpIGIJdIVROqaN73pTWnbbbftfF3MZxNDu6tT5sRrI11K9Xw3IdKeRUqhSFkUqSXiMyvTazQiyiWGe0dKtUoxjD3mDohh5rHdI31ApUivEmloIoVDXyKlSwwtj/oRZXHIIYd0S/MSc3TEkPT4TY2KFAu10gJFeoRImxBD7mM/qK67PYmUHTE3QqVIV7Nw4cJy22+33Xbl51WmyIoUJ5GCLlLODJRY/9hHX/va15aPo55GfYuUJ9VpVmI71KqHvYm0IbGfxD4S2yX2m0gjtPvuu5dLpRNPPLFMv9KRviHqTLw39qnq1CuRBiWW6ufq2bciHUscuyKtRqQGiX2sEQOx3wzU9n//+9/f7bOjzGIdYn+IVDSTJk0qt2/1/teoSF1RnXLx+eefL9c5JoiNFDWRiqPefSDSQ1WnPYn0FpEqJ1JERPnFvCGVx9JIVfLDH/6wPLc0Iiam3XHHHbs9X8/5oiexXpHCsToVSJR7R8q3qONxbKsU+9gFF1xQ15xhcQyL+hmT5MY5N/aDSNVRKVLMxTmy4zwVacEiFWNMQhxLbxOE97XP9Eekn6tOkxllEmUdvyFSZ02YMKGsJ9W/Jcdzy2CJ49Sll16a9t9//3Kda6Vj3RSRfijS/cS+FWKbR3qfKKNIjVR97KjeBj2Jz6yVGia2V5yX4th40EEHdTn+xvaI1E/Vx9SRft6OY1bsz9Wpd2Jfj/Q/US/jGFmd/ivSRkV5xWt6OldEXY1jabQhQ2zHONfG+aK3VD99iXZ0pNqrFufb2IcijVakQIrzRXxXPWmqIqXSFlts0eX5SPMVvzE+N9rcle2JqBuRqinO73ENtKnXUSG24VDZlHbTULUL4twRabJie0c610qRRiyOyx3imq1Rsc1jf6oW55BIsRjbNa4743zaWyq6gbhWu+iii8rjaLVYh6gXURejTON8W52OqxGx39ZK/RnbLdKRxe+MlHqxT3SI/0c7JLZnX2kPO85bkTY09p04/1a3raOeHX300eVxGGAkEKFTBuqAOlB3HYi0VNV+/vOfb1IduuWWW7p95ve+973yTruO14wbN664/fbbu73uG9/4Rp93LIUvfOELna/ZfPPNi9/+9rc1X3fkkUd2vu71r399t7/Hnb713CXVcVfuC17wgi53ANVK2zBr1qwunxfpWw444IByPXsqs0MPPbTb58RQ7nruoA3z5s3rNsw+yrjyjtqdd965x+/fYostuqXLiDsUX/ziF3d5XdyZVi3uII+0YNWfGb/7/PPPL172spf1+Ruq7xCMMqw1yucVr3hFl9ddeumlNdMrVG6nnu4CjlR0UScqt2et0UuR1qHRfSDuhF+3bl23z/roRz/a5XVxV22toe7Vd5tNnDix2+iE+J1xB3/l62KofXUavLgjv793DNcSz8dosEpXXHFFWYcqUy89/fTTZR2o947puNv3zW9+c4/pImI57bTTun1WrXQi/blLu6e7H7/97W932Zeq96167vrd1P1mILd/9fE50svUKo84XsVxK9JS9afu9HS3ZvVdtx/+8Idrvq56e0U6s1p3eVenl4p1rk6B8R//8R8Dtv79OR50LJG+rlrsM9UpMk499dRur4u7pePu98rX1ap7cedvHFcq61OtdDGHHHJIXftAT6lPBnKESdT1ajNmzKj5WS9/+cvLOnPiiSd2+1srnFuaOcKk+pg+0CNM4m8XX3xxl+cjDVMc+yvPgx3lXE99jPfWSnlT/boYcRDnpGqRumqknLfrOdfUSiN41113dWnLxTk22trVfvzjH3f5rOp1P/nkk2tu7zguve997yvOPvvsftWXSJ1Y7amnnipH43W8JlLixYikWqr38dhetdIMjx07ts8RNJGWaiDW/49//OMm7bP1Hl8Hqt00EO2CvkaYNPrbOpZ6jgORFqqnEabVx+wYrRkjnyvPkwN5rRbns1ojGL/1rW8VW221Vc3RPdXbo54yijb3H/7whz7PF5ECdOXKlX1mdah17gkLFizokpKyVr/BjTfeuEn13aIM1AF1IA1dGShsZaAOqAP114EIPAxk3t3I51qdRzU63mulPoiLxFqdiJUN/1oN8GiIVnfk10rnEfnQq7/zN7/5TbfXVX9WT98ZF9PVn1fdcdxX+UXKoriw/PjHP17mD4+GdqQP++xnP9vtc374wx/W1SEUKQqqLwh6WqKj98ADDywb55/61KfKXObx/bHUyh8fDfnK99dKVVGr46q3pZ5OrVrpNY4++uhunxUXPr///e+7vbYyN3pPnVq15rCJi+pqcYHU6H5wxBFHdPuc++67r+Zra3VcVF9k1qpnPZV7rQ6Tys67RpZaOvLFV859FJ09kcql1m/oTwdgrG+8LzovooOto45++ctf7vZZse8PVsAkLkZrXeA22om1qfvNQG7/f/mXf+nyt0gbsalz9dRaoiO02r//+7/XfG101PW1vao7WkN1h0dPnT9xDqp1/O5teeMb31jU0lvgua+lVmrEnjroli5d2u21fc0XFOI7qj+r1pxf0Yk2XAImcTypFkGRRss3h3NLf5aY1y3O79GRHHPcxDEtbmCZPHlyGUCqNY9dtOP6W9d7C5jEZ1ami4q5XqItVGvfr6c+1uqs7ilAGu2tapUdv8P9vF3PuaZWx2it+TkihU6tTt3KQH0ELSrFcWRT07XVWr7zne90W4+Pfexj3V4XbfVaAa3qfbz6fBLvqXUej3Zzddquu+++u+H1j0BRrXSem1ImjQYVNrXdNBDtgmYGTCJlYrXrr7++3+W/KddqMd9ltbipr7dATH/KqFY6tp5ukIprvmrRTuqr3RxB5up0W6985Su7ve4Xv/jFJh8HLMpAHVAH0hCUgZRcQENqDT2vTqHSiD333LNMr1EpUiLEkOhqkd4ghmFXDqGO745hz/G3nkQqrkibUSnSsVSLlAfV4nXVKT1iqHX151WLoc21hohHGpVqe+yxR7fn3v3ud6dPf/rTafLkyalevQ0ZrxRpG/pKERSpEyJNWgy733zzzfu1DpGWrDpVRQzVjzQ5AynSr7z+9a/v9nykZqjWkdrib//2b7s8H8PmFy9e3Ov31Ep3ESlxqkX9aFStOhCpbWqJOjRz5sxeP+8Nb3hDt+ciZUks9YiUIJH6aaBEioKvf/3rZWqHECkWqtPw1btu1WlqPv7xj3emwhrI/aQ/vv3tbzecnqPaQOw3A7n9I81RHI86RNqISD1x7733pgceeKBc4v+RgiZSe/RXrX0g0kT1tA/0lNaktzKoTB/Tm0ihEakvIuVSvXra7ptyfozjUj3HtRDrGufT6vdH2phmHdcGSxxP4hxbWQe+8IUvlCmrov0QqTDvv//+MgVnnP/7myqqFc4t/fG+972vZhspyjSO23Fuit9UmRYq2nGHHnpombpnIP32t78tvy9SZIVIDXX66ad3KfcvfvGLg7JPxfORAqyn94/083ak46pMrdqRaq5WatdINfTTn/40vfnNb+5WHjfddFPnuaLyN55zzjnlOTrODx37ZKQu+vGPf1ymMRrsc0W00+M4Eem5ejvW77XXXl2eizZvX238DpFqLVIWRdquZl1HNaPdNFTtgsFSa1+rJ33iYFyr1VqXr371q2W7byDVOvbFcalWGtw49kXa677eXy1S0caxYiS1JwB60/8EokCWIjd/tZ122qnfn9eRm7rSo48+2uPra/2t+oKvnvfUaojWet2GDRu6PVdP7uWefkMEfGo1HCtzZf/93/99mZu3kQZ4qM6/3JPegksh8uTGRU7kxW4kWFK9DtU52EPk4B7oi4DIpR8dW9XzFPSU07g/dahj3avV+i39yc390pe+tK660tvzfe1XjYj8/wPt85//fJfHlXW+I39yI2L+n7jAbeSiv5H9pD/62rfqMRD7zUBu/8hvXz0PRXQQxUX+McccU85dFIGiODdEh3Gti/8c9oFa58awKfnGGzk/Dsfj2mCKOVXiOF9p4sSJZb70OIdeccUV6Uc/+lG5XSIPfpzXcjy39EetYEmlOF5/5zvf6fZ8dcBuKM4d0Vkf+f2bsU+N9GNWre/rbT37Ko/ohK+ejy++421ve1vZSR9zFsS8edGhGjcAVM9LWK+BLPf4rOp9vBGxT9Y6Zzd6roh5quJ4M9gGqt00VO2CwVJrm0VArxEDda02EOsyFMe+qKOVQfKRcC4D2FSOVkBDanVqRkdE9R1aw0mtxlqtO2oGuiO/P+LiLSYR7Y+YkL0efd05d/bZZ3ebKHmg12EkqtVJ1uhk3iPFYNztGBO/RyCulkZHl8Sk8dV3/g6HOlrvXakjafvHJJ8x0XpMFhp3CfckLoCnTZtWTvRZPQl5DvtAdBQ+/PDD3Z6PCZOHs1p3/w7Vca2nTpNaHaLVYoRD3Gm+YMGCXkd1Rfvk1FNPLSfOrR7NOlyMxHNLTOo7VKP34m7nWqOO+zsysVUN5SiFWmJy99e97nVlsLKnAHJHh/Gxxx5b7sPRCZtbufd0c0gElgbTQLabcm0XDOW12khUqz3x/PPPN2VdAAbC8LxyAIatuGNz7dq13YbT/sM//EM67rjjGv686rvRQm93PtX6W28XZs3S02+oTCfWIcqzYyRL3B1bfffRypUryzuZfvjDH5aN0Qj2xB2WccHSH7WCRZUOOeSQbs/Nnz8/XXrppWV6jI5UCrNnz06zZs3q8XNqbZcddtghbbbZZv1e9546m6JzqfIuwSjDuFuvVkfUcKxDtS4yatWV3p7v6/d885vfTMuXL69rfW677bY0GKJz601velO3IENfaYOqvetd7+rW2RopIKJjNDoj/vjHP5bP7bLLLuXzQ6WvfaseA7HfDPT2j+/9p3/6p3KJu/hf+9rXlkHVSZMmpalTp5ZpSTrEen7yk5/sTKHTzH0g0jVWuuaaa8rjbT0idUyjIh3P8ccf3+W5SNH0iU98ol/BtDg/xravPn7Ve95s9nGtr06TF77whTVfW+/dzw8++GDZ7ohjQdTBXXfdtRzREx2D06dP79IZG6m1jjjiiHT99ddndW4ZLLU6uhtJS9Ro3YmUa5H6plJ01EZqoMFqc/a1PUf6ebtWWfS2nvXU7xidFNcDscSd93EMjjRqsW/GOaFyFEykn4yRJxdddFFD6x3lHueh6vVu9Pd0fFb1Ph4B2Gjz1qs6BVFf4i78qLvRPqkUZfav//qvabAMdLtpKNoFgyXqbaSkqxT1ta/RdR0G8lqt1n7f6KiVoTj2Rf3ob3pLgJFKwARoSDSWrr766vSRj3yky/Nxt9iNN95YDsHuTTQeoxEducVD/Pvss892ufMzOjviQqr6jsJojFdf/EQu81//+tfDbitGrtfoUOi4AOnwjne8o9eOufjd1eJiJIZ9VxrM4e3V6xAXj5Geq7ozuK91iIvCyF1bOR9DpPiKDq6oQwMlLnYjb/df//Vfd3l+xowZ6Wtf+1qX52I4eeRarha5uZupVufsAQccUPO1tepQrd9THcCM74ggV1/ignqw7giLzp9Iy1GZGiByNVen1ulLrf0kRkZV5zGvdz+pdTf3pqTp2BQDsd8M5vaPzrtYKudjio66/fbbb5OOT7F+MWdSdadE1Jf+7gNxB2ylGGVQa76IgdoH4s7qD33oQ106pWKEQ8yxELn9+wqoxR24cVNC5W+oDpjEca3j/Fn9/HA7rlWfq6tVd3qG6FBrNH1WbKtIh1eZEi8CJ3HHe6Wol40ETFrh3NKo6OiM0YA9pR3raMcdfPDB3Z6PGyoGy5e+9KWyw7UyHVd/5hyI7RHt1ertWWvulb72qZF+3o4RcdFZW5lWK+YXi3lK7rjjjm531Neaw6C3+h1phSpTC2211VZliqzKERn9PVdUHzviXFE9f0t8X19zXUWZxfG08rfFDWFxg1A9adT6e6743Oc+V54vqve9f/zHfyz/1tcIhfhdMRdMM9tNQ9EuGCxRdtUBkwjeRbCjHgN5rRbrUr3fR1qzmC9qIG8uq7Wvxvk26lN122S4tycAhoqUXEDDYhhyrYvpG264oRzuXSvHaVzkxkVqXIgfffTRXSaYjE6sLgemUaPKC+G4I6lD3Mlz5ZVX1pzoNgIuw010cMbFUGWna9yxE5Ng9jYRca05U3bfffcuj+Nz+tNRUK/qdYiL2+o8/DHpaj2pZmrdLRc5lGt1tsRFatyJ3Z+81v/2b//W7bnIoVwdYIs7GavzfEf+80bnzxhokde7+sIo7sisnNy2ozMm7pLuy80339ztTrCoe+985ztrvj4umOLCLrZNoxfhjdat6DyO9HexxGil/qRUqWc/icBrXMD2tzO3enTCUNrU/WYgt38EAD72sY+VdwnXEsfp6Jiqfq5RlR0tlRfzhx9+eJfnPvCBD9TVCVHrmBCTmMZk7rVE0D4CLBGU+ta3vpX6I85vX//617s9H/ts3ExQq5MlRGddBBOr54Wo9RvOOOOM8uaBStHJVj1/RAQhe5qAuhni5oHqUTZRZytHNEY9qqdzuCOH/nve856yg7eWWnnh+1Mvh/u5JdpV0dlVuZx77rn9/ryYuD0CTRdccEHNu/Ojc/0b3/hGzbrc0+TpAyHu3o59pOPcEXWpkVEAvR0bI2VQdRAljjEnnnhit/dXHhta4bxd61gXHfaVx/Q4NsY8MtX7T9TtygmdYz2i47en1GwRCK3+jP7sk5Vt5g5xE1dlKtm4joi5i+qZh696H4/3Rsd3T23ROOfG9oztFQGH/ogRU9UB3RA3CMQxMOYDqRbrddhhh5XlHufkZrabhqpdMFjiWFLtqKOOKufhqR6FE4/f+973dhkdM5DXajEPU/VxJOYGjeB+rfNbtGFiNFKj4nhVfe0e+0y0HyvFNq11rdrfdhHASGaECdCwGH4eFwvRwVV5t1/8P+7Si4ZW5KuNC6m4WIm7eOKiruMCIIIclT71qU+Vd2ZWNlIjnUYMWY8On3g+7s6rvqMsLiyrUzQMJ+973/vKuV3ijqW4wIrOzuoLiOiojTQxlZOpVos7jWJ4dtwFFx0ycfFd62JqoMQ6VOZSjqDPz372s3K7RcqNuLMt8lTXI+6Qio6IyhRuEYCJjsH4PfFdEfCKi4O4qzH+FiMOGhXBqZgEuPJOyejQ+dWvflV24kTnSty9XX1BE6JjqNn54mP4fnS0RmdwpbjLMS6Q487puNM8LtjqGfkQEzZGYOLkk0/ukv4mLvBjRNbdd99dfmeUd+yfsT07JhytNQ/DQIoL0lg2Ra39JO4+jrsZI5VEbPvYT/qaoLIytU+1KPe48zKOQx1B2VjvRkfD9Mem7jcDuf2j3sUxPdYpPjf2qbiTNMohRtHFXbHV6Rt6y2nek3vvvbcMnlcHYqNj49Zbb02/+c1vys7IevO8x4S0ccyqvFMyOvIib34cz+LO5zguxDF55513Lsugo7zrvcu0lpNOOqkMaMT8GpX+5m/+pjyvxXpFHY0OlzhexfG0o/yqAwrRMR11LjqxKjsdo8MsOg3jHBvHtOo0d+Hyyy+vmTKomeKO40gLU/0bI0AYneBxjqx3AuXYv//u7/6ubAdEnY46F7837vaOOlsroN+fejnSzy39Eft17PPRGRy/M44X0VaJY0X81lqdeLfffvsm7Tf1iPR2sWyKGLkcwba4m7xSTEIe9Sl+b7Q1Y1+tbN+GCEpUdta3wnk7jutxE1NlerxIXxfnxDh+Rkdu7Eu1OsbPO++8Lo+jnR8B3dgH4xgX89zE9ULsozFiMtr51efk/uyT1157bblvVaaFi2N7nBvjHBn75Fve8pa6b3qIfTzSUlUGPOO3RJnGtUyM+ozjdZR1tMXjPNRRN+Jc0h9RJhEsjhGFldcFcb0TqW6jQzy+O+prlFkEL6OjvGP0XT2jXwaz3TRU7YLBEuecKI/q+TfjmjLSakbZx+j6qBNxfo36WzkKZCCv1SKwHjcEVgdaI3gd2z/SDsZr4rgbN1dE/YvjVaNi23zmM58pt1n1NXicl6NdESPJ4jxcvd6xD8RxEyBHMQbPogzUAXWg4Trwzne+s/jjH/9YNOqyyy7r9llnnnlmw59z0kkndfucqVOndnvd/Pnzu73u3HPP7fa6Y489ttvrFi1a1O11O+ywQ5/fef/99xcbNmxo+De0tbUVP//5z/t83/e///1uzy1btqzb+sdvrxbr29t2Peyww/r8/vhtCxcurKsMZ8yYUVdZ9FS+9f6G/fbbr1i/fn3RiOuvv75mGURZVqv1unrrUT3L1ltvXaxYsaLPdf7d735XVx3ffPPNi8WLFxeNqlWP6l1qafQzovyqRTlXvmaLLbYoHn/88X7tJ7FPV39n7He1tnm1l770pZu87es5pgzEfjNQ2/+CCy5o+DNOOOGEftWfSZMmFX/+85/7tQ9U15GOferBBx9seP1r1ZFGlgkTJhS33357w98b59NaZbJq1aqGPue2224rxowZ0++6V88+2J994MADD+xz3Tdu3Fj84Q9/6HM9H3300YbLdvz48S13bql3W9W7RPusUbEtatWjepd470Cch+otsxe+8IXFz372s4Z+Y5yba/3G4Xzernd/P+qoo4rnnnuuoe+76KKLun1Oo8e8Z555pnjNa17Trzpz9NFH9/n58ZseeeSRuvbxKVOmFE8//XTRqE3Z12LZd999i8cee6zh773xxhv73Ieqz2MD2W4aiHZBvddr9fy2/hwHtt9++2L58uV1r3/lZwz0tVqcr2vtrz2pLqd6y2jUqFHFzTffXDQi2mR77bXXJp176ikDizJQB9SBNAzLQEouoN/iTq64OyeGs9d7F2WMUIg7iavFEPC4uy9SdNWT2iOGTvcnlc9QibuY426kjgnSa4k7map/Q/SdRK773u4eizvS4vcPlpiLJu5C6knccRhzmsQdpfWIuxTjbrNa6QcGUqxP3ClXz/fE3X2RQiVGAQ0XcSdm5OHubdLJhQsX1kwTUkvcsR2pRuKO1Xr3z7iLsjpF3nAUd8rFKLfeJtKOFEiRqqgesd9FSo/hdDf4pu43A7X9G5nIPu4sjrur+ztHUdzlGnfd9nYeiLuL447IevepuCu3kVQScY6q99jWk9iHYyRM3IHbyCiPWumbokxiFEqtO1prlX/cBRojMofj5KwxYjTS5PRk7dq15bmtci6SnjRSL2Oy27jjP9I65XhuaUT8xjh21CvOSTHqJO5AHimiXRbp9+qZz6ijPRcjDmr9xlY4b0fqn0j7Vc/+EefeGHFVKyVUI/tkjFiKO/JrXQ/UI84DMRKjp/lDYj+MURpxd36923jKlCkNrU/c9R+jfjZFjDiMET1x3K6V5qmWeF31fC1D3W4aynbBYInRGzFiI0awNmqgr9WivsZ5O9LhDWaa6dgWkeY0zsP1fE+MEovjez3tD4BWJCUXsEliks93v/vdaZdddik7JKKDb9KkSeWw3ph3JC6KokEZFxXRWRK5WmOYcy0xxDg66yO9QQxljrQm8TkdF6XRiRIpciJvda05B4abuBiPodmRoiBSEcQQ7fjtcWEWeYojPUktkQohLqDOPPPMsvMwhr5HJ14MZ4/PjCDLYM/bEt8dQ9LjgjMuKGJbRodApNyIdY9t0Uie9PjNUS+ijsTQ7+gAjPKIYd/RoRgXnpHuIrZvDOvvr5iUMIbEx4VMfE+se6RSidzJEWiLso3fEJ0RcbE03ES5RhqJKP8oq0iREBe5ke5gwYIF5UV17GP1ivdGeoGYdygCeNHpF/tqpEyI/OdRH5ctW1bOvRD5jSPNXm+T/Q4ncTEaaXCi0yRSnkTKhOhoj7KKY0SkqKqeMLuvFA1RttEZFJ3sUW+qU7IMtU3dbwZi+0dwIo7d0cEYk1/H+6OsIy1MdOjFZ0S6rDvvvLOso/3tAOsQHVyRgio65CKdVuSRj++IDqLI+x4B+ur5BnoT5RTlF3UlUs9Eeo1IZRapTaLzIDqPYv3jHBXfHb81jrebKo7RMddFHC/jHBlpbaL8ttlmm7L8o4MkOvKjQyI65KOjKtLu9NSJHe+NVBnR4RX1M7ZBHJdj/SN1TJxP4vjQ02cMFzHPWdTrSF0Wacvi2BwpXSJAGHMgRD3++7//+z4/J7ZntBOiMyc+J1IURdnG50Wnc0xmHWURdTrqZQRjNsVIP7fUK1LDRGd0pKSKfT7SPnXsLzGXReyLUd+iozfaI7EtR6JoQ77//e8vb9bpODbG+SLSI8X+H+nu4rfF3HzVk2K34nk7Uo3FPhTHyDjuRhs00lxFKrH47DhOxfEx6ne0x2uJOhPHuVjfeH+kOox9JNJ9xY02cSyOVIgRQIr2fuyjmyICk7HPRRs7UlNG+cRnRts10gPHOaOReW7iHBDXHXGcje0YQbI4/0QqpDimxO+OdngcC6KTPY7b/ZnwvVqcB+ImpEiPFcf32O/iHBjXP/HdUR/iuBjbOwJjcQNAf4O/A9VuGup2wWCJNlQEPOOcGvOURPsg9t84DsQxIq57otzjGBDXr4N5rRaBsEgNF3U3biDsuJ6Oeh2fE+sSbYHYfzZlPpFoe8R5ONJ2Rr2LbRgp9+IY33HujJs34juiXTwQdRxgpGr7y1ATAPopGrXVubs78mEDAAAAACODlFwAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkry2lVGRfCgAAAAAAQNaMMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2Gg6Y7Lfffummm25Ky5cvT0VRpEMOOaTP90ydOjUtXbo0rV+/Pj344IPp2GOPzb7gAYD+0RYBAJpJWwQAWlfDAZNx48alu+++O51yyil1vX7HHXdM3/3ud9OiRYvSHnvskT772c+mL33pS+nAAw/sz/oCAJnTFgEAmklbBABaV1tKqejvm2OEyaGHHpq+/e1v9/iaiy66KB188MHpta99bedz1113XXrxi1+cpk+f3t+vBgDQFgEAmkq/CAC0ltGD/QVTpkxJCxcu7PLcLbfcUo406cnYsWPTZptt1uW5l7zkJWnVqlWDtp4AMBK1t7enxx9/vNmrMaxpiwDA4NEW6Zu2CACMnLbIoAdMJkyYkFauXNnluXi81VZbpc0337yc16TarFmz0nnnnTfYqwYALWHixImCJr3QFgGAwaUt0jttEQAYOW2RQQ+Y9MecOXPS3Llzu0SJYpL5+OFr165t6roBwHDRcX50bhx42iIAoC3STNoiANCcfpFBD5isWLEijR8/vstz8Xj16tU1R5eEDRs2lEu1+OE6hQAAbREAYKTQLwIAI8eowf6CxYsXp2nTpnV57oADDiifBwDQFgEAWpl+EQBo4YDJuHHj0u67714uYaeddir//4pXvKJ8PHv27LRgwYLO18+bNy/tvPPO6eKLL06TJk1KJ510Upo5c2a67LLLBvJ3AACZ0BYBAJpJWwQAWlvRyDJ16tSilvnz55d/j38XLVrU7T133XVXsX79+uKhhx4qjj322Ia+s729vfyO+LfR9bUoA3VAHVAH1IFWrQO5nh+1RZq/DSzKQB1QB9QBdUBbRL+I44DjgDqgDqgD6kBqwX6Rtr/8Z9hP3rJmzZq05ZZbmsMEAJwftUUAYBhwra6sAaDV2iKDPocJAAAAAADAcCdgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAstevgMnJJ5+cli1bltatW5eWLFmS9t57715ff+qpp6b7778/Pf300+mRRx5Jc+fOTZtttln2hQ8A9I+2CADQTNoiANC6ikaWmTNnFuvXry+OO+64Ytdddy2uvvrqYtWqVcU222xT8/Xvfe97i3Xr1pX/7rDDDsUBBxxQLF++vLj00kvr/s729vYixL+Nrq9FGagD6oA6oA60ah3I9fyoLdL8bWBRBuqAOqAOqAPaIvpFHAccB9QBdUAdUAdSa/aLNPaGJUuWFJdffnnn47a2tuKxxx4rzjrrrJqvj9cuXLiwy3OXXHJJcfvttzf7h1uUgTqgDqgD6sCIrgO5nh+1RZq/DSzKQB1QB9QBdUBbRL+I44DjgDqgDqgD6kBqwX6RhlJyjRkzJu21115p4cKF/zs8pSjKx1OmTKn5nh/96EflezrSdu20005pxowZ6Xvf+16P3zN27NjU3t7eZQEA0BYBAJpJWwQAWtvoRl689dZbp9GjR6eVK1d2eT4eT548ueZ7rrvuuvJ9d9xxR2praysbF1dddVWaM2dOj98za9asdN555zWyagBABrRFAIBm0hYBgNbWr0nfGzF16tR09tlnlxOi7bnnnumwww5LBx98cDrnnHN6fE8EU7bccsvOZeLEiYO9mgBAi9IWAQCaSVsEAFp0hMlTTz2Vnn322TR+/Pguz8fjFStW1HzPBRdckK699tp0zTXXlI/vvffeNG7cuPSFL3whXXjhhWVKr2obNmwoFwAAbREAYLjQLwIAra2hESYbN25MS5cuTdOmTet8LtJsxePFixfXfM8WW2yRnn/++S7PPffcc53vBQDQFgEARgL9IgDQ+hqaJX7mzJnFunXrimOOOaaYPHlyMW/evGLVqlXFtttuW/59wYIFxezZsztff+655xarV68ujjzyyGLHHXcs9t9//+LBBx8srr/++qbOdm9RBuqAOqAOqAMjvQ7ken7UFmn+NrAoA3VAHVAH1AFtEf0ijgOOA+qAOqAOqAOpBftFGkrJFW644Ya0zTbbpPPPPz9NmDAh/eIXv0gHHXRQeuKJJ8q/b7/99l1GlHz6058u027FvzEXyZNPPpluvvnm9PGPf3xgwz4AQBa0RQCAZtIWAYDW1faXyMmw1t7entasWVNOAL927dpmrw4ADAvOj8oaAJpJW0RZA0CrtUUamsMEAAAAAACgFQmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7PUrYHLyySenZcuWpXXr1qUlS5akvffeu9fXb7XVVumKK65Ijz/+eFq/fn164IEH0vTp07MvfACgf7RFAIBm0hYBgNY0utE3zJw5M82dOzedeOKJ6cc//nE67bTT0i233JImTZqUnnzyyW6vHzNmTLr11lvTE088kY444oi0fPnytMMOO6Q//elPA/UbAICMaIsAAM2kLQIAra1oZFmyZElx+eWXdz5ua2srHnvsseKss86q+foTTjiheOihh4rRo0c39D2VS3t7exHi3/5+hkUZqAPqgDqgDrRaHcj1/Kgt0vxtYFEG6oA6oA6oA9oi+kUcBxwH1AF1QB1QB1IL9os0lJIrRovstddeaeHChf8bbSmK8vGUKVNqvudd73pXWrx4cbryyivTihUr0j333JNmzZqVRo3q+avHjh2b2tvbuywAANoiAEAzaYsAQGtrKGCy9dZbp9GjR6eVK1d2eT4eT5gwoeZ7dt555zIV1wte8II0Y8aMdMEFF6QzzjgjnXPOOT1+TwRU1qxZ07lEGi8AAG0RAKCZtEUAoLWNGvQvGDWqnL/k+OOPT3fddVe64YYb0oUXXljOgdKTOXPmpC233LJzmThx4mCvJgDQorRFAIBm0hYBgBad9P2pp55Kzz77bBo/fnyX5+NxpNuq5fe//33auHFjev755zufu++++9LLXvaycihr/K3ahg0bygUAQFsEABgu9IsAQGtraIRJBDeWLl2apk2b1vlcW1tb+TjmKanlzjvvTK961avK13XYZZdd0uOPP14zWAIAoC0CAAxH+kUAoPU1NEv8zJkzi3Xr1hXHHHNMMXny5GLevHnFqlWrim233bb8+4IFC4rZs2d3vn677bYrVq9eXXzuc58rXv3qVxczZswoVqxYUZx99tlNne3eogzUAXVAHVAHRnodyPX8qC3S/G1gUQbqgDqgDqgD2iL6RRwHHAfUAXVAHVAHUmv2izT+plNOOaV4+OGHi/Xr1xdLliwp9tlnn86/LVq0qJg/f36X1++7777F4sWLy0DLQw89VMyaNasYNWpUs3+4RRmoA+qAOqAOjOg6kPP5UVuk+dvAogzUAXVAHVAHtEX0izgOOA6oA+qAOqAOpBbrF2n7y3+Gtfb29rRmzZpyAvi1a9c2e3UAYFhwflTWANBM2iLKGgBarS3S0BwmAAAAAAAArUjABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZK9fAZOTTz45LVu2LK1bty4tWbIk7b333nW978gjj0xFUaQbb7wx+4IHAPpPWwQAaCZtEQBoTQ0HTGbOnJnmzp2bPvWpT6U999wz3X333emWW25J22yzTa/v22GHHdIll1ySbrvttk1ZXwAgc9oiAEAzaYsAQOtqOGBy+umnpy9+8YvpK1/5SrrvvvvSiSeemJ5++un0gQ98oOcvGTUqff3rX0/nnntu+u1vf7up6wwAZExbBABoJm0RAGhdDQVMxowZk/baa6+0cOHCzucixVY8njJlSo/v++QnP5meeOKJ9OUvf7mu7xk7dmxqb2/vsgAAaIsAAM2kLQIAra2hgMnWW2+dRo8enVauXNnl+Xg8YcKEmu9505velD74wQ+mD3/4w3V/z6xZs9KaNWs6l+XLlzeymgBAi9IWAQCaSVsEAFpbvyZ9r9eLXvSidO2115bBkj/84Q91v2/OnDlpyy237FwmTpw4mKsJALQobREAoJm0RQBgZBndyIufeuqp9Oyzz6bx48d3eT4er1ixotvrX/nKV6addtop3XzzzV3mMwkbN25MkyZNqjmnyYYNG8oFAEBbBAAYLvSLAEBra2iESQQ5li5dmqZNm9b5XFtbW/l48eLF3V5///33p9e85jVpjz326FxuuummtGjRovL/jz766MD8CgAgC9oiAEAzaYsAQGtraIRJmDt3blqwYEH62c9+ln7yk5+k0047LY0bNy7Nnz+//Hv8LeYcOfvss9MzzzyTfvWrX3V5/5/+9Kfy3+rnAQC0RQCA4U6/CAC0roYDJjfccEPaZptt0vnnn19O9P6LX/wiHXTQQemJJ54o/7799tun559/fjDWFQBAWwQAaCr9IgDQutpSSkUa5trb29OaNWvKCeDXrl3b7NUBgGHB+VFZA0AzaYsoawBotbZIQ3OYAAAAAAAAtCIBEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkL1+BUxOPvnktGzZsrRu3bq0ZMmStPfee/f42g996EPptttuS6tWrSqXW2+9tdfXAwBoiwAAw5l+EQBoTQ0HTGbOnJnmzp2bPvWpT6U999wz3X333emWW25J22yzTc3Xv/Wtb03XXXddetvb3pamTJmSHn300fSDH/wgvfzlLx+I9QcAMqMtAgA0k7YIALS2opFlyZIlxeWXX975uK2trXjssceKs846q673jxo1qli9enVx9NFH1/2d7e3tRYh/G11fizJQB9QBdUAdaNU6kOv5UVuk+dvAogzUAXVAHVAHtEX0izgOOA6oA+qAOqAOpBbsF2lohMmYMWPSXnvtlRYuXPi/0ZaiKB/H6JF6bLHFFuXnRHqunowdOza1t7d3WQAAtEUAgGbSFgGA1tZQwGTrrbdOo0ePTitXruzyfDyeMGFCXZ9x8cUXp8cff7xL0KXarFmz0po1azqX5cuXN7KaAECL0hYBAJpJWwQAWlu/Jn3vr7POOisdddRR6bDDDkvPPPNMj6+bM2dO2nLLLTuXiRMnDuVqAgAtSlsEAGgmbREAGN5GN/Lip556Kj377LNp/PjxXZ6PxytWrOj1vWeccUb62Mc+lvbff/90zz339PraDRs2lAsAgLYIADBc6BcBgNbW0AiTjRs3pqVLl6Zp06Z1PtfW1lY+Xrx4cY/v++hHP5o+8YlPpIMOOqh8PwBAf2iLAADNpC0CAK2voVniZ86cWaxbt6445phjismTJxfz5s0rVq1aVWy77bbl3xcsWFDMnj278/VnnnlmsX79+uLwww8vxo8f37mMGzeuqbPdW5SBOqAOqAPqwEivA7meH7VFmr8NLMpAHVAH1AF1QFtEv4jjgOOAOqAOqAPqQGrNfpHG33TKKacUDz/8cBkIWbJkSbHPPvt0/m3RokXF/PnzOx8vW7asqOXcc89t9g+3KAN1QB1QB9SBEV0Hcj4/aos0fxtYlIE6oA6oA+qAtoh+EccBxwF1QB1QB9SB1GL9Im1/+c+w1t7entasWVNOAL927dpmrw4ADAvOj8oaAJpJW0RZA0CrtUUamsMEAAAAAACgFQmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7PUrYHLyySenZcuWpXXr1qUlS5akvffeu9fXH3HEEem+++4rX//LX/4yTZ8+PfuCBwD6T1sEAGgmbREAaF1FI8vMmTOL9evXF8cdd1yx6667FldffXWxatWqYptttqn5+ilTphQbN24sPvKRjxSTJ08uzj///OKZZ54pdtttt7q/s729vQjxb6Pra1EG6oA6oA6oA61aB3I9P2qLNH8bWJSBOqAOqAPqgLaIfhHHAccBdUAdUAfUgdSa/SKNvWHJkiXF5Zdf3vm4ra2teOyxx4qzzjqr5uuvv/764uabb+7y3OLFi4urrrqq2T/cogzUAXVAHVAHRnQdyPX8qC3S/G1gUQbqgDqgDqgD2iL6RRwHHAfUAXVAHVAHUgv2i4xuZCjKmDFj0l577ZXmzJnzv8NTiiItXLgwTZkypeZ74vm5c+d2ee6WW25Jhx56aI/fM3bs2LTZZpt1Pm5vb+/yLwCQ53lRWwQAhg9tkf+ffhEAaJ22SEMBk6233jqNHj06rVy5ssvz8Xjy5Mk13zNhwoSar4/nezJr1qx03nnndXt++fLljawuAGThJS95SVq7dm3KgbYIAAw/2iL6RQCgVdoiDQVMhkqMYKkclRKRogiWTJw4MZsOoWZR1sq6FanXyrrV6/aqVauavSotR1ukeRyzlXUrUq+VdavSFhk82iLN45itrFuReq28W1X7IPSLNBQweeqpp9Kzzz6bxo8f3+X5eLxixYqa74nnG3l92LBhQ7lUi2CJgMnQUNZDR1kr61akXjNYtEXy4TiirFuReq2sGfm0RfLhmK2sW5F6rbzp26jUgI0bN6alS5emadOmdT7X1tZWPl68eHHN98Tzla8PBxxwQI+vBwDQFgEAhiP9IgDQ+hqaJX7mzJnFunXrimOOOaaYPHlyMW/evGLVqlXFtttuW/59wYIFxezZsztfP2XKlGLDhg3F6aefXkyaNKk499xzi2eeeabYbbfdmjrbvUVZN7sOqNfKutl1UL1ufnk5jvSvDLRFml/31Ovml5NjyMhatPuUdbProLo9sGWgLdL8uqdet8bi/Kism10H1e3ml1UanseRxt90yimnFA8//HCxfv36YsmSJcU+++zT+bdFixYV8+fP7/L6I444orj//vvL199zzz3F9OnTG/q+sWPHloGW+LfZG6HVF2WtrJtdB9Xr5peXY0jzy9Exu+8y0BZpfv1Tr5tfVo4hzS9Dx+vht7ieUd5DVde0RZq/vzuONL+sHLNHzuL8qLybXQfTCKrbbX/5DwAAAAAAQLYamsMEAAAAAACgFQmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyN6wCZicfPLJadmyZWndunVpyZIlae+99+719UcccUS67777ytf/8pe/TNOnTx+ydR3pGinrD33oQ+m2225Lq1atKpdbb721z21D/8q60pFHHpmKokg33nij4hykst5qq63SFVdckR5//PG0fv369MADDziODFJZn3rqqen+++9PTz/9dHrkkUfS3Llz02abbaZu92G//fZLN910U1q+fHl5PDjkkEP6LLOpU6empUuXlnX6wQcfTMcee6xyboC2yNDRFhmeZV1JW2Twy1pbpP+0RYaGtsjQ0xYZnmWtX2ToyrqStsjgl7W2SP9pi7R+W6Ro9jJz5sxi/fr1xXHHHVfsuuuuxdVXX12sWrWq2GabbWq+fsqUKcXGjRuLj3zkI8XkyZOL888/v3jmmWeK3Xbbrem/ZbgvjZb11772teKkk04qdt9992LSpEnFl7/85eKPf/xj8fKXv7zpv6XVyrpj2WGHHYpHH320+K//+q/ixhtvbPrvaMWyHjNmTPGTn/yk+M53vlO88Y1vLMv8LW95S/G6172u6b+l1cr6ve99b7Fu3bry3yjnAw44oFi+fHlx6aWXNv23DPfloIMOKi644ILi0EMPLcIhhxzS6+t33HHH4s9//nNxySWXlOfGU045pTxXHnjggU3/LSNh0RYZvmWtLTJ0Zd2xaIsMfllriwxdvdYW6X9Za4toi7Tqoi0yfMu6Y9EWGfyy1hYZunqtLZJGYlukuSeqWJYsWVJcfvnlnY/b2tqKxx57rDjrrLNqvv76668vbr755i7PLV68uLjqqqua/luG+9JoWVcvo0aNKlavXl0cffTRTf8trVjWUb533HFH8YEPfKCYP3++gMkglfUJJ5xQPPTQQ8Xo0aObXk9avazjtQsXLuzyXJy4br/99qb/lpG01NMwuOiii4p77rmny3PXXXdd8f3vf7/p6z8SFm2R4VvW1Yu2yOCWtbbI0NRrbZGhO4ZoiwzMsVtbZPidH/WLaIu0Yr2ORVtkaMpaW2To6rW2SBpxbZGmp+QaM2ZM2muvvdLChQs7n4shNvF4ypQpNd8Tz1e+Ptxyyy09vp7+l3W1LbbYovycSM/FwNbr8MlPfjI98cQT6ctf/rLiHcSyfte73pUWL16crrzyyrRixYp0zz33pFmzZqVRo5p+SGy5sv7Rj35UvqdjKPBOO+2UZsyYkb73ve8N2Xrnwrmx/7RFho62yPAva22RoSlrbZH+0RYZ3rRF+k9bZOhoiwz/stYWGZqy1hbpH22RPNoio1OTbb311mn06NFp5cqVXZ6Px5MnT675ngkTJtR8fTzPwJZ1tYsvvric86G68rHpZf2mN70pffCDH0x77LGH4hzkst55553T29/+9vT1r3+97Lx/1atelT7/+c+XJ77zzz9f+Q9gWV933XXl++64447U1tZWlvFVV12V5syZo5wHWE/nxshLu/nmm5f5O6lNW2ToaIsM77LWFhm6stYWGbqy1hYZOtoi/actMnS0RYZ3WWuLDF1Za4sMXVlri4y8tojbqanbWWedlY466qh02GGHpWeeeUbJDaAXvehF6dprr00f/vCH0x/+8AdlO8hiJEmM5Dn++OPTXXfdlW644YZ04YUXphNPPFHZD7CYbOvss88uJ0Tbc889y+PHwQcfnM455xxlDTRMW2TwaIsMLW2RoaMtAgwkbZHBoy0ytLRFho62yMjT9BEmTz31VHr22WfT+PHjuzwfjyNVTi3xfCOvp/9l3eGMM85IH/vYx9L+++9fpi9iYMv6la98ZZmq6Oabb+58riM91MaNG9OkSZPSb3/7W8U+AGUdfv/735fl+vzzz3c+d99996WXvexl5QiI+BsDU9YXXHBBGQy85pprysf33ntvGjduXPrCF75QBqlimDADo6dz4+rVq40u6YO2yNDRFhm+Za0tMnRlHbRFhq6stUWGjrZI/2mLDB1tkeFb1toiQ1fWQVtk6MpaW2TktUWaPsIkOiaXLl2apk2b1vlcpG2JxzHHQC3xfOXrwwEHHNDj6+l/WYePfvSj6ROf+EQ66KCDyvcz8PX6/vvvT695zWvKdFwdy0033ZQWLVpU/v/RRx9V7ANU1uHOO+8s03DF6zrssssuZbo5wZKBq9cd8x5VBqbCc8891/leBo5zY/9piwwdbZHhW9baIkNX1kFbZOjKWltk6GiL9J+2yNDRFhm+Za0tMnRlHbRFhq6stUVGZlukaPYyc+bMYt26dcUxxxxTTJ48uZg3b16xatWqYtttty3/vmDBgmL27Nmdr58yZUqxYcOG4vTTTy8mTZpUnHvuucUzzzxT7Lbbbk3/LcN9abSszzzzzGL9+vXF4YcfXowfP75zGTduXNN/S6uVdfUyf/784sYbb2z672jFst5uu+2K1atXF5/73OeKV7/61cWMGTOKFStWFGeffXbTf0urlXUcn6OsjzzyyGLHHXcs9t9//+LBBx8srr/++qb/luG+xHF29913L5dw2mmnlf9/xSteUf49yjnKu+P1Ub5//vOfi4svvrg8N5500knFxo0biwMPPLDpv2UkLNoiw7estUWGrqyrF22RwStrbZGhq9faIv0va20RbZFmt8+0RUb+oi0yfMtaW2ToylpbJI3EtkjzD6CxnHLKKcXDDz9cds4vWbKk2GeffTr/tmjRovKCrfL1RxxxRHH//feXr7/nnnuK6dOnN/03jJSlkbJetmxZUUvs7M3+HSNhabReVy46KQa3rPfdd99i8eLF5UnuoYceKmbNmlWMGjWq6XWm1cr6BS94QfHJT36yDJI8/fTTxe9+97viiiuuKLbaaqum/47hvkydOrXm8bejfOPfKO/q99x1113ltol6feyxxzb9d4ykRVtkeJa1tsjQ1uvKRVtkcMtaW2Ro6rW2SP/LWVtEW6SVF22R4VnW1Yu2yOCWtbbI0NRrbZE04toibX/5DwAAAAAAQLaaPocJAAAAAABAswmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOw1HDDZb7/90k033ZSWL1+eiqJIhxxySJ/vmTp1alq6dGlav359evDBB9Oxxx6bfcEDAP2jLQIANJO2CAC0roYDJuPGjUt33313OuWUU+p6/Y477pi++93vpkWLFqU99tgjffazn01f+tKX0oEHHtif9QUAMqctAgA0k7YIALSutpRS0d83xwiTQw89NH3729/u8TUXXXRROvjgg9NrX/vazueuu+669OIXvzhNnz69v18NAKAtAgA0lX4RAGgtowf7C6ZMmZIWLlzY5blbbrmlHGnSk7Fjx6bNNtusy3MveclL0qpVqwZtPQFgJGpvb0+PP/54s1djWNMWAYDBoy3SN20RABg5bZFBD5hMmDAhrVy5sstz8XirrbZKm2++eTmvSbVZs2al8847b7BXDQBawsSJEwVNeqEtAgCDS1ukd9oiADBy2iKDHjDpjzlz5qS5c+d2iRLFJPPxw9euXdvUdQOA4aLj/OjcOPC0RQBAW6SZtEUAoDn9IoMeMFmxYkUaP358l+fi8erVq2uOLgkbNmwol2rxw3UKAQDaIgDASKFfBABGjlGD/QWLFy9O06ZN6/LcAQccUD4PAKAtAgC0Mv0iANDCAZNx48al3XffvVzCTjvtVP7/Fa94Rfl49uzZacGCBZ2vnzdvXtp5553TxRdfnCZNmpROOumkNHPmzHTZZZcN5O8AADKhLQIANJO2CAC0tqKRZerUqUUt8+fPL/8e/y5atKjbe+66665i/fr1xUMPPVQce+yxDX1ne3t7+R3xb6Pra1EG6oA6oA6oA61aB3I9P2qLNH8bWJSBOqAOqAPqgLaIfhHHAccBdUAdUAfUgdSC/SJtf/nPsJ+8Zc2aNWnLLbc0hwkAOD9qiwDAMOBaXVkDQKu1RQZ9DhMAAAAAAIDhTsAEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkr18Bk5NPPjktW7YsrVu3Li1ZsiTtvffevb7+1FNPTffff396+umn0yOPPJLmzp2bNttss+wLHwDoH20RAKCZtEUAoHUVjSwzZ84s1q9fXxx33HHFrrvuWlx99dXFqlWrim222abm69/73vcW69atK//dYYcdigMOOKBYvnx5cemll9b9ne3t7UWIfxtdX4syUAfUAXVAHWjVOpDr+VFbpPnbwKIM1AF1QB1QB7RF9Is4DjgOqAPqgDqgDqTW7Bdp7A1LliwpLr/88s7HbW1txWOPPVacddZZNV8fr124cGGX5y655JLi9ttvb/YPtygDdUAdUAfUgRFdB3I9P2qLNH8bWJSBOqAOqAPqgLaIfhHHAccBdUAdUAfUgdSC/SINpeQaM2ZM2muvvdLChQv/d3hKUZSPp0yZUvM9P/rRj8r3dKTt2mmnndKMGTPS9773vR6/Z+zYsam9vb3LAgCgLQIANJO2CAC0ttGNvHjrrbdOo0ePTitXruzyfDyePHlyzfdcd9115fvuuOOO1NbWVjYurrrqqjRnzpwev2fWrFnpvPPOa2TVAIAMaIsAAM2kLQIAra1fk743YurUqenss88uJ0Tbc88902GHHZYOPvjgdM455/T4ngimbLnllp3LxIkTB3s1AYAWpS0CADSTtggAtOgIk6eeeio9++yzafz48V2ej8crVqyo+Z4LLrggXXvttemaa64pH997771p3Lhx6Qtf+EK68MILy5Re1TZs2FAuAADaIgDAcKFfBABaW0MjTDZu3JiWLl2apk2b1vlcpNmKx4sXL675ni222CI9//zzXZ577rnnOt8LAKAtAgCMBPpFAKD1NTRL/MyZM4t169YVxxxzTDF58uRi3rx5xapVq4ptt922/PuCBQuK2bNnd77+3HPPLVavXl0ceeSRxY477ljsv//+xYMPPlhcf/31TZ3t3qIM1AF1QB1QB0Z6Hcj1/Kgt0vxtYFEG6oA6oA6oA9oi+kUcBxwH1AF1QB1QB1IL9os0lJIr3HDDDWmbbbZJ559/fpowYUL6xS9+kQ466KD0xBNPlH/ffvvtu4wo+fSnP12m3Yp/Yy6SJ598Mt18883p4x//+MCGfQCALGiLAADNpC0CAK2r7S+Rk2Gtvb09rVmzppwAfu3atc1eHQAYFpwflTUANJO2iLIGgFZrizQ0hwkAAAAAAEArEjABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZ61fA5OSTT07Lli1L69atS0uWLEl77713r6/faqut0hVXXJEef/zxtH79+vTAAw+k6dOnZ1/4AED/aIsAAM2kLQIArWl0o2+YOXNmmjt3bjrxxBPTj3/843TaaaelW265JU2aNCk9+eST3V4/ZsyYdOutt6YnnngiHXHEEWn58uVphx12SH/6058G6jcAABnRFgEAmklbBABaW9HIsmTJkuLyyy/vfNzW1lY89thjxVlnnVXz9SeccELx0EMPFaNHj27oeyqX9vb2IsS//f0MizJQB9QBdUAdaLU6kOv5UVuk+dvAogzUAXVAHVAHtEX0izgOOA6oA+qAOqAOpBbsF2koJVeMFtlrr73SwoUL/zfaUhTl4ylTptR8z7ve9a60ePHidOWVV6YVK1ake+65J82aNSuNGtXzV48dOza1t7d3WQAAtEUAgGbSFgGA1tZQwGTrrbdOo0ePTitXruzyfDyeMGFCzffsvPPOZSquF7zgBWnGjBnpggsuSGeccUY655xzevyeCKisWbOmc4k0XgAA2iIAQDNpiwBAaxs16F8walQ5f8nxxx+f7rrrrnTDDTekCy+8sJwDpSdz5sxJW265ZecyceLEwV5NAKBFaYsAAM2kLQIALTrp+1NPPZWeffbZNH78+C7Px+NIt1XL73//+7Rx48b0/PPPdz533333pZe97GXlUNb4W7UNGzaUCwCAtggAMFzoFwGA1tbQCJMIbixdujRNmzat87m2trbyccxTUsudd96ZXvWqV5Wv67DLLrukxx9/vGawBABAWwQAGI70iwBA62tolviZM2cW69atK4455phi8uTJxbx584pVq1YV2267bfn3BQsWFLNnz+58/XbbbVesXr26+NznPle8+tWvLmbMmFGsWLGiOPvss5s6271FGagD6oA6oA6M9DqQ6/lRW6T528CiDNQBdUAdUAe0RfSLOA44DqgD6oA6oA6k1uwXafxNp5xySvHwww8X69evL5YsWVLss88+nX9btGhRMX/+/C6v33fffYvFixeXgZaHHnqomDVrVjFq1Khm/3CLMlAH1AF1QB0Y0XUg5/Ojtkjzt4FFGagD6oA6oA5oi+gXcRxwHFAH1AF1QB1ILdYv0vaX/wxr7e3tac2aNeUE8GvXrm326gDAsOD8qKwBoJm0RZQ1ALRaW6ShOUwAAAAAAABakYAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAAAAQPYETAAAAAAAgOwJmAAAAAAAANkTMAEAAAAAALInYAIAAAAAAGRPwAQAAAAAAMiegAkAAAAAAJA9ARMAAAAAACB7AiYAAAAAAED2BEwAAAAAAIDsCZgAAAAAAADZEzABAAAAAACyJ2ACAAAAAABkT8AEAAAAAADInoAJAAAAAACQPQETAAAAAAAgewImAAAAAABA9gRMAAAAAACA7AmYAAAAAAAA2RMwAQAAAAAAsidgAgAAAAAAZE/ABAAAAAAAyJ6ACQAAAAAAkD0BEwAAAAAAIHsCJgAAAP9fe/cfW9VZxgH8LRZmxsoSAxSHus2p7cLiFgjEuuhUYIEZ3Y+QMv8YW/ZDB8S4sB8M4sCxCJJM/pDpmEaQzAWyf0jAaHAkRJy2mbJsQwNmy4oyJhBWBRbaUtxrzsmolJWtt7b33N7380netPf0nPXep8/OfXa+u/cCAADJE5gAAAAAAADJE5gAAAAAAADJE5gAAAAAAADJE5gAAAAAAADJE5gAAAAAAADJE5gAAAAAAADJE5gAAAAAAADJE5gAAAAAAADJE5gAAAAAAADJE5gAAAAAAADJE5gAAAAAAADJE5gAAAAAAADJE5gAAAAAAADJG1BgsmDBgtDW1hY6OjpCa2trmDp1ar+Omzt3bogxhi1btiRfeABg4MwiAECRzCIAUJ1KDkyam5vDmjVrwqOPPhomT54cXn755bB9+/Ywbty49z3u0ksvDY8//njYtWvX/3N/AYDEmUUAgCKZRQCgepUcmCxatCj87Gc/C7/4xS/C3r17w7333htOnjwZ7rzzzvP/khEjwjPPPBOWL18eXn/99f/3PgMACTOLAABFMosAQPUqKTAZOXJkmDJlStixY0fPtuwttrLbTU1N5z1u2bJl4ciRI2H9+vX9+j2jRo0KdXV1vRYAgFkEACiSWQQAqltJgcnYsWNDbW1tOHz4cK/t2e0JEyb0ecy1114b7rrrrnDPPff0+/csWbIkHD9+vGcdPHiwlLsJAFQpswgAUCSzCABUtwF96Ht/XXTRReHpp5/Ow5K33nqr38etWrUqjBkzpmdNnDhxKO8mAFClzCIAQJHMIgAwvNSWsvPRo0fD6dOnQ319fa/t2e1Dhw69Z/8rrrgiXH755WHbtm29Ps8k093dHRoaGvr8TJNTp07lCwDALAIAVArXRQCgupX0CpMs5Ni9e3eYPn16z7aampr8dktLy3v237dvX7jqqqvCNddc07O2bt0adu7cmX9/4MCBwXkUAEASzCIAQJHMIgBQ3Up6hUlmzZo1YePGjeHPf/5zeOGFF8J9990XRo8eHTZs2JD/PPtZ9pkjS5cuDV1dXeGvf/1rr+P//e9/51/P3Q4AYBYBACqd6yIAUL1KDkyeffbZMG7cuLBixYr8g95feumlMGvWrHDkyJH855/4xCfCO++8MxT3FQDALAIAFMp1EQCoXjUhhBgqXF1dXTh+/Hj+AfAnTpwo+u4AQEXw/KjWAFAks4haA0C1zSIlfYYJAAAAAABANRKYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyROYAAAAAAAAyRtQYLJgwYLQ1tYWOjo6Qmtra5g6dep597377rvDrl27Qnt7e76ee+65990fAMAsAgBUMtdFAKA6lRyYNDc3hzVr1oRHH300TJ48Obz88sth+/btYdy4cX3u/6UvfSls2rQpfPnLXw5NTU3hwIED4be//W245JJLBuP+AwCJMYsAAEUyiwBAdYulrNbW1rh27dqe2zU1NfGNN96Iixcv7tfxI0aMiMeOHYu33XZbv39nXV1dzGRfS72/lhroAT2gB/RAtfZAqs+PZpHi/waWGugBPaAH9IBZxHUR5wHnAT2gB/SAHghVeF2kpFeYjBw5MkyZMiXs2LHjf2lLjPnt7NUj/XHhhRfm/5zs7bnOZ9SoUaGurq7XAgAwiwAARTKLAEB1KykwGTt2bKitrQ2HDx/utT27PWHChH79M1avXh3efPPNXqHLuZYsWRKOHz/esw4ePFjK3QQAqpRZBAAoklkEAKrbgD70faAWL14cbr311nDzzTeHrq6u8+63atWqMGbMmJ41ceLEct5NAKBKmUUAgCKZRQCgstWWsvPRo0fD6dOnQ319fa/t2e1Dhw6977H3339/ePjhh8OMGTPCnj173nffU6dO5QsAwCwCAFQK10UAoLqV9AqT7u7usHv37jB9+vSebTU1NfntlpaW8x734IMPhkceeSTMmjUrPx4AYCDMIgBAkcwiAFD9SvqU+Obm5tjR0RHnzZsXGxsb47p162J7e3scP358/vONGzfGlStX9uz/0EMPxc7OznjLLbfE+vr6njV69OhCP+3eUgM9oAf0gB4Y7j2Q6vOjWaT4v4GlBnpAD+gBPWAWcV3EecB5QA/oAT2gB0J1Xhcp/aCFCxfG/fv350FIa2trnDZtWs/Pdu7cGTds2NBzu62tLfZl+fLlRT9wSw30gB7QA3pgWPdAys+PZpHi/waWGugBPaAH9IBZxHUR5wHnAT2gB/SAHghVdl2k5t1vKlpdXV04fvx4/gHwJ06cKPruAEBF8Pyo1gBQJLOIWgNAtc0iJX2GCQAAAAAAQDUSmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkTmAAAAAAAAMkbUGCyYMGC0NbWFjo6OkJra2uYOnXq++4/Z86csHfv3nz/V155JcyePTv5wgMAA2cWAQCKZBYBgOoVS1nNzc2xs7Mz3nHHHfHKK6+MTz31VGxvb4/jxo3rc/+mpqbY3d0dH3jggdjY2BhXrFgRu7q64qRJk/r9O+vq6mIm+1rq/bXUQA/oAT2gB6q1B1J9fjSLFP83sNRAD+gBPaAHzCKuizgPOA/oAT2gB/RAqMLrIjXvftNv2StK/vSnP4Vvf/vb+e2amppw4MCBsHbt2rB69er37L958+YwevTo8LWvfa1nW0tLS3jppZfC/Pnz+/wdo0aNChdccEHP7bq6unDw4MEwceLEcOLEiVLuLgBUrTPPj2PGjEnq+dEsAgCVwSziuggAVNssUlvKziNHjgxTpkwJq1at6tkWYww7duwITU1NfR6TbV+zZk2vbdu3bw833XTTeX/PkiVLwve+9733bM8ePADQ20c+8pFkAhOzCABUHrOI6yIAUC2zSEmBydixY0NtbW04fPhwr+3Z7cbGxj6PmTBhQp/7Z9vPJwtkzg5ZvMKkfNRarauRvlbrau/t9vb2kAqzSPVzzlbraqSv1bpamUX+x3WR6uGcrdbVSF+rd7WqG4LrIiUFJuVy6tSpfJ0rS4lS+T9oi6bWal2N9LVaQ3+ZRYrnnK3W1UhfqzX0l1mkeM7Zal2N9LV688FGhBIcPXo0nD59OtTX1/fant0+dOhQn8dk20vZHwDALAIAVCLXRQCgupUUmHR3d4fdu3eH6dOn92zLPvQ9u519kHtfsu1n75+ZOXPmefcHADCLAACVyHURAKh+sZTV3NwcOzo64rx582JjY2Nct25dbG9vj+PHj89/vnHjxrhy5cqe/ZuamuKpU6fiokWLYkNDQ1y+fHns6uqKkyZN6vfvHDVqVH5c9rXU+2uVVgO1Ll/PqLVaV+P5SV+rdzn6zCxS/L/rziPF18k5e3gtz49qXXQP6u3BrYFZpPje09fVsTw/qnXRPai3i69VqMzzSOkHLVy4MO7fvz92dnbG1tbWOG3atJ6f7dy5M27YsKHX/nPmzIn79u3L99+zZ0+cPXt24cW01EAP6AE9oAf0wPDtAbNI8X8DSw30gB7QA3og5R4wixT/N7DUQA/oAT2gB8IQ1KDm3W8AAAAAAACSVdJnmAAAAAAAAFQjgQkAAAAAAJA8gQkAAAAAAJA8gQkAAAAAAJC8iglMFixYENra2kJHR0dobW0NU6dOfd/958yZE/bu3Zvv/8orr4TZs2eX7b4Od6XU+u677w67du0K7e3t+Xruuec+8G/DwGp9trlz54YYY9iyZYtyDlGtL7744vDEE0+EN998M3R2doa//e1vziNDVOvvfOc7Yd++feHkyZPhH//4R1izZk244IIL9PYH+MIXvhC2bt0aDh48mJ8Pbrzxxg+s2XXXXRd2796d9/Srr74abr/9dnUugVmkfMwilVnrs5lFhr7WZpGBM4uUh1mk/MwilVlr10XKV+uzmUWGvtZmkYEzi1T/LBKLXs3NzbGzszPecccd8corr4xPPfVUbG9vj+PGjetz/6amptjd3R0feOCB2NjYGFesWBG7urripEmTCn8slb5KrfUvf/nLOH/+/Hj11VfHhoaGuH79+vivf/0rXnLJJYU/lmqr9Zl16aWXxgMHDsTf/e53ccuWLYU/jmqs9ciRI+MLL7wQf/WrX8XPf/7zec2/+MUvxs9+9rOFP5Zqq/U3vvGN2NHRkX/N6jxz5sx48ODB+MMf/rDwx1Lpa9asWfGxxx6LN910U8zceOON77v/ZZddFt9+++34+OOP58+NCxcuzJ8rr7/++sIfy3BYZpHKrbVZpHy1PrPMIkNfa7NI+fraLDLwWptFzCLVuswilVvrM8ssMvS1NouUr6/NImE4ziLFPlFlq7W1Na5du7bndk1NTXzjjTfi4sWL+9x/8+bNcdu2bb22tbS0xCeffLLwx1Lpq9Ran7tGjBgRjx07Fm+77bbCH0s11jqr7/PPPx/vvPPOuGHDBoHJENX6W9/6VnzttddibW1t4X1S7bXO9t2xY0evbdkT1+9///vCH8twWv0ZDH7wgx/EPXv29Nq2adOm+Jvf/Kbw+z8cllmkcmt97jKLDG2tzSLl6WuzSPnOIWaRwTl3m0Uq7/nRdRGzSDX2dbbMIuWptVmkfH1tFgnDbhYp/C25Ro4cGaZMmRJ27NjRsy17iU12u6mpqc9jsu1n75/Zvn37efdn4LU+14UXXpj/c7K352Jw+zqzbNmycOTIkbB+/XrlHcJaf/3rXw8tLS3hxz/+cTh06FDYs2dPWLJkSRgxovBTYtXV+o9//GN+zJmXAl9++eXhhhtuCL/+9a/Ldr9T4blx4Mwi5WMWqfxam0XKU2uzyMCYRSqbWWTgzCLlYxap/FqbRcpTa7PIwJhF0phFakPBxo4dG2pra8Phw4d7bc9uNzY29nnMhAkT+tw/287g1vpcq1evzj/z4dzm4/+v9bXXXhvuuuuucM011yjnENf6k5/8ZPjKV74Snnnmmfzi/ac+9anwk5/8JH/iW7FihfoPYq03bdqUH/f888+HmpqavMZPPvlkWLVqlToPsvM9N2bvS/vhD384f/9O+mYWKR+zSGXX2ixSvlqbRcpXa7NI+ZhFBs4sUj5mkcqutVmkfLU2i5Sv1maR4TeL+N+p6bfFixeHW2+9Ndx8882hq6tL5QbRRRddFJ5++ulwzz33hLfeektth1j2SpLslTzf/OY3w4svvhieffbZ8P3vfz/ce++9aj/Isg/bWrp0af6BaJMnT87PH1/96lfDd7/7XbUGSmYWGTpmkfIyi5SPWQQYTGaRoWMWKS+zSPmYRYafwl9hcvTo0XD69OlQX1/fa3t2O3urnL5k20vZn4HX+oz7778/PPzww2HGjBn52xcxuLW+4oor8rcq2rZtW8+2M28P1d3dHRoaGsLrr7+u7INQ68w///nPvK7vvPNOz7a9e/eGj370o/krILKfMTi1fuyxx/Iw8Oc//3l++y9/+UsYPXp0+OlPf5qHVNnLhBkc53tuPHbsmFeXfACzSPmYRSq31maR8tU6YxYpX63NIuVjFhk4s0j5mEUqt9ZmkfLVOmMWKV+tzSLDbxYp/BUm2YXJ3bt3h+nTp/dsy962JbudfcZAX7LtZ++fmTlz5nn3Z+C1zjz44IPhkUceCbNmzcqPZ/D7et++feGqq67K347rzNq6dWvYuXNn/v2BAweUfZBqnfnDH/6Qvw1Xtt8Zn/nMZ/K3mxOWDF5fn/nco7ODqcx//vOfnmMZPJ4bB84sUj5mkcqttVmkfLXOmEXKV2uzSPmYRQbOLFI+ZpHKrbVZpHy1zphFyldrs8jwnEVi0au5uTl2dHTEefPmxcbGxrhu3brY3t4ex48fn/9848aNceXKlT37NzU1xVOnTsVFixbFhoaGuHz58tjV1RUnTZpU+GOp9FVqrR966KHY2dkZb7nlllhfX9+zRo8eXfhjqbZan7s2bNgQt2zZUvjjqMZaf+xjH4vHjh2LP/rRj+KnP/3peMMNN8RDhw7FpUuXFv5Yqq3W2fk5q/XcuXPjZZddFmfMmBFfffXVuHnz5sIfS6Wv7Dx79dVX5ytz33335d9//OMfz3+e1Tmr95n9s/q+/fbbcfXq1flz4/z582N3d3e8/vrrC38sw2GZRSq31maR8tX63GUWGbpam0XK19dmkYHX2ixiFil6PjOLDP9lFqncWptFyldrs0gYjrNI8SfQbC1cuDDu378/vzjf2toap02b1vOznTt35v/Bdvb+c+bMifv27cv337NnT5w9e3bhj2G4rFJq3dbWFvuS/cte9OMYDqvUvj57uUgxtLX+3Oc+F1taWvInuddeey0uWbIkjhgxovCeqbZaf+hDH4rLli3LQ5KTJ0/Gv//97/GJJ56IF198ceGPo9LXdddd1+f590x9s69Zvc895sUXX8z/Nllf33777YU/juG0zCKVWWuzSHn7+uxlFhnaWptFytPXZpGB19ksYhap5mUWqcxan7vMIkNba7NIefraLBKG3SxS8+43AAAAAAAAySr8M0wAAAAAAACKJjABAAAAAACSJzABAAAAAACSJzABAAAAAACSJzABAAAAAACSJzABAAAAAACSJzABAAAAAACSJzABAAAAAACSJzABAAAAAACSJzABAAAAAACSJzABAAAAAABC6v4LpdkEA6/LGbkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 2000x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === IMPORTS NECESARIOS ===\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurar matplotlib para mostrar gr√°ficos inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Paleta de colores moderna para matrices de confusi√≥n (azul-verde suave)\n",
    "cmap_moderno = sns.light_palette(\"#2ECC71\", as_cmap=True)\n",
    "\n",
    "# --- Definir los 5 modelos a visualizar ---\n",
    "modelos_viz = [\n",
    "    ('LGBMClassifier_classifier', 'LGBMClassifier (Mejor Modelo - 98.49%)'),\n",
    "    ('GradientBoostingClassifier_classifier', 'GradientBoostingClassifier (97.59%)'),\n",
    "    ('XGBClassifier_classifier', 'XGBClassifier (96.91%)'),\n",
    "    ('RandomForestClassifier_classifier', 'RandomForestClassifier (92.52%)'),\n",
    "    ('LogisticRegression_classifier', 'LogisticRegression (83.91%)')\n",
    "]\n",
    "\n",
    "# --- Crear la figura con 5 subplots (2 filas x 3 columnas) ---\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "fig.suptitle('Comparaci√≥n de Matrices de Confusi√≥n: 5 Modelos de Clasificaci√≥n',\n",
    "             fontsize=20, weight='bold', y=0.995)\n",
    "\n",
    "# Aplanar el array de axes para facilitar iteraci√≥n\n",
    "axes_flat = axes.flatten()\n",
    "\n",
    "# --- Iterar sobre los 5 modelos y crear heatmaps ---\n",
    "for idx, (modelo_key, titulo) in enumerate(modelos_viz):\n",
    "    ax = axes_flat[idx]\n",
    "\n",
    "    try:\n",
    "        matriz = np.array(matrices_confusion[modelo_key])\n",
    "\n",
    "        # Dibujamos el heatmap con el colormap moderno\n",
    "        sns.heatmap(matriz, annot=False, fmt='d', cmap=cmap_moderno, ax=ax,\n",
    "                    xticklabels=['Predicho No', 'Predicho S√≠'],\n",
    "                    yticklabels=['Real No', 'Real S√≠'],\n",
    "                    cbar_kws={'label': 'Cantidad'},\n",
    "                    linewidths=2, linecolor='white')\n",
    "\n",
    "        ax.set_title(f'[{idx+1}] {titulo}', fontsize=13, weight='bold', pad=10)\n",
    "        ax.set_xlabel('Predicci√≥n', fontsize=11, weight='bold')\n",
    "        ax.set_ylabel('Valor Real', fontsize=11, weight='bold')\n",
    "\n",
    "        # A√±adimos los n√∫meros manualmente con colores contrastantes\n",
    "        for i in range(matriz.shape[0]):\n",
    "            for j in range(matriz.shape[1]):\n",
    "                color = 'white' if matriz[i, j] > matriz.max() * 0.5 else 'black'\n",
    "                ax.text(j + 0.5, i + 0.5, f'{matriz[i, j]:,}',\n",
    "                        ha='center', va='center', color=color, fontsize=16, weight='bold')\n",
    "\n",
    "    except KeyError:\n",
    "        ax.set_title(f'{titulo}: Matriz no encontrada', fontsize=12)\n",
    "        ax.text(0.5, 0.5, 'N/A', ha='center', va='center', fontsize=20, transform=ax.transAxes)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "# --- Ocultar el √∫ltimo subplot (posici√≥n 6) ya que solo tenemos 5 modelos ---\n",
    "axes_flat[5].axis('off')\n",
    "\n",
    "# --- Mostrar el gr√°fico ---\n",
    "plt.tight_layout()\n",
    "display(fig)  # Forzar visualizaci√≥n en Jupyter\n",
    "plt.show()\n",
    "\n",
    "# Imprimir m√©tricas clave de los 5 modelos\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN COMPARATIVO DE LOS 5 MODELOS DE CLASIFICACI√ìN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for modelo_key, titulo in modelos_viz:\n",
    "    print(f\"\\n{titulo}:\")\n",
    "    print(f\"  ‚Ä¢ Accuracy:  {metrics_clasificacion[modelo_key]['accuracy']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ F1-Score:  {metrics_clasificacion[modelo_key]['f1_score']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Precision: {metrics_clasificacion[modelo_key]['precision']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Recall:    {metrics_clasificacion[modelo_key]['recall']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ ROC-AUC:   {metrics_clasificacion[modelo_key]['roc_auc']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODELO GANADOR: LGBMClassifier con 98.49% de accuracy\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√°lisis Visual de Errores: Matrices de Confusi√≥n\n",
    "\n",
    "Los gr√°ficos anteriores nos permiten \"ver\" los errores de nuestros dos mejores modelos.\n",
    "\n",
    "**Observaciones:**\n",
    "\n",
    "1.  **Rendimiento General:** Ambos modelos son excelentes, ya que los n√∫meros en la diagonal principal (los aciertos) son mucho m√°s grandes que los de fuera de la diagonal (los errores).\n",
    "2.  **Tipo de Error:** El punto clave de la comparaci√≥n est√° en los **Falsos Negativos** (cuadrado de abajo a la izquierda).\n",
    "    *   **XGBoost** tiene **254** Falsos Negativos: se le \"escapan\" 254 casos que eran \"S√≠\" pero que predijo como \"No\".\n",
    "    *   **LGBM** tiene solo **115** Falsos Negativos: es mucho m√°s sensible y capaz de encontrar los casos positivos.\n",
    "3.  **Falsos Positivos:** Ambos modelos son muy precisos y cometen muy pocos Falsos Positivos (23 para LGBM y 29 para XGBoost). Cuando dicen \"S√≠\", es muy probable que sea \"S√≠\".\n",
    "\n",
    "**Conclusi√≥n Final:** La visualizaci√≥n de la matriz de confusi√≥n confirma nuestra elecci√≥n. **LGBMClassifier es el mejor modelo** no solo porque sus m√©tricas generales son m√°s altas, sino porque su patr√≥n de error es m√°s deseable: falla mucho menos a la hora de identificar la clase positiva, que suele ser la de mayor inter√©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matrices_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificaci√≥n de los Datos de las Matrices de Confusi√≥n\n",
    "\n",
    "Antes de visualizar las matrices, es una buena pr√°ctica inspeccionar la variable que las contiene.\n",
    "\n",
    "La celda de c√≥digo `print(matrices_confusion)` muestra el contenido crudo de la variable. La salida es un **diccionario de Python**, donde:\n",
    "*   Las **claves** (`keys`) son los nombres de los modelos (ej. `'LGBMClassifier_classifier'`).\n",
    "*   Los **valores** (`values`) son las matrices de confusi√≥n, representadas como una lista de listas (ej. `[[6319, 23], [115, 2706]]`).\n",
    "\n",
    "Este paso nos sirvi√≥ para confirmar que los datos se cargaron correctamente y que ten√≠amos una matriz de 2x2 para cada modelo antes de proceder a la visualizaci√≥n con los mapas de calor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones del An√°lisis de Clasificaci√≥n\n",
    "\n",
    "Al igual que con la regresi√≥n, hemos evaluado varios modelos para la tarea de clasificaci√≥n. Las m√©tricas clave aqu√≠ son el **F1-Score** (un balance entre precisi√≥n y recall) y el **ROC AUC** (la capacidad del modelo para distinguir entre clases).\n",
    "\n",
    "**Observaciones:**\n",
    "\n",
    "1.  **Ganador Claro:** El modelo `LGBMClassifier` (LightGBM) se destaca como el mejor, con un **F1-Score de 0.975** y un **ROC AUC de 0.998**, ambos valores muy cercanos a la perfecci√≥n.\n",
    "2.  **Subcampe√≥n Fuerte:** `XGBClassifier` (XGBoost) le sigue de cerca, demostrando de nuevo la potencia de los algoritmos de Gradient Boosting para datos tabulares como los de esta encuesta.\n",
    "3.  **L√≠nea Base:** `RandomForestClassifier` ofrece un rendimiento s√≥lido (F1-Score de 0.87), pero no puede competir con los modelos de boosting. `LogisticRegression` sirve como una referencia inicial, mostrando que los modelos m√°s complejos aportan un valor significativo.\n",
    "\n",
    "**Conclusi√≥n:** Para la tarea de clasificaci√≥n, `LGBMClassifier` es la elecci√≥n superior. Es el modelo m√°s equilibrado y con mayor poder predictivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaci√≥n: Regresi√≥n Normal vs. Regresi√≥n Polinomial\n",
    "\n",
    "En esta secci√≥n se comparan los resultados de los pipelines de regresi√≥n normal y regresi√≥n polinomial. Esto permite evaluar si la complejidad adicional del modelo polinomial aporta valor predictivo real o si la regresi√≥n normal es suficiente para el problema abordado.\n",
    "\n",
    "> **Nota:** Aseg√∫rate de haber ejecutado ambos pipelines antes de correr las siguientes celdas, para que los artefactos est√©n actualizados en el cat√°logo de Kedro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar m√©tricas de ambos pipelines\n",
    "metrics_regresion = # # catalog.load reemplazado(\"metrics\")\n",
    "metrics_ridge_poly = # # catalog.load reemplazado(\"metrics_ridge_poly\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# ========== PREPARACI√ìN DE DATOS ==========\n",
    "# Incluir TODOS los 5 modelos de regresi√≥n normal (igual que en clasificaci√≥n mostramos 5)\n",
    "top_modelos_normales = {\n",
    "    'RandomForest': metrics_regresion['RandomForestRegressor_model'],\n",
    "    'XGBoost': metrics_regresion['XGBRegressor_model'],\n",
    "    'Ridge': metrics_regresion['Ridge_model'],\n",
    "    'Lasso': metrics_regresion['Lasso_model'],\n",
    "    'LinearRegression': metrics_regresion['LinearRegression_model']\n",
    "}\n",
    "\n",
    "# Crear DataFrame comparativo CON TODOS los modelos (para tabla)\n",
    "data_comparativa = []\n",
    "\n",
    "for nombre, metricas in top_modelos_normales.items():\n",
    "    data_comparativa.append({\n",
    "        'Modelo': nombre,\n",
    "        'Tipo': 'Regresi√≥n Normal',\n",
    "        'R¬≤': metricas['r2'],\n",
    "        'RMSE': metricas['rmse'],\n",
    "        'MAE': metricas['mae'],\n",
    "        'Caracter√≠sticas': 299\n",
    "    })\n",
    "\n",
    "# Agregar el modelo polinomial\n",
    "data_comparativa.append({\n",
    "    'Modelo': 'Ridge Polinomial',\n",
    "    'Tipo': 'Regresi√≥n Polinomial',\n",
    "    'R¬≤': metrics_ridge_poly['r2'],\n",
    "    'RMSE': metrics_ridge_poly['rmse'],\n",
    "    'MAE': metrics_ridge_poly['mae'],\n",
    "    'Caracter√≠sticas': '10 ‚Üí 65 (polinomial grado 2)'\n",
    "})\n",
    "\n",
    "df_comparacion_completo = pd.DataFrame(data_comparativa)\n",
    "\n",
    "# Crear DataFrame SIN LinearRegression para visualizaci√≥n (evita barras microsc√≥picas)\n",
    "df_comparacion = df_comparacion_completo[df_comparacion_completo['Modelo'] != 'LinearRegression'].copy()\n",
    "\n",
    "# ========== VISUALIZACI√ìN 1: COMPARACI√ìN DE R¬≤ (SIN LinearRegression) ==========\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "fig.suptitle('Comparaci√≥n Exhaustiva: Mejores Modelos de Regresi√≥n\\n(LinearRegression excluido por valores extremos)',\n",
    "             fontsize=20, weight='bold', y=0.998)\n",
    "\n",
    "# Colores modernos por tipo\n",
    "colores_tipo = {'Regresi√≥n Normal': COLOR_SECONDARY, 'Regresi√≥n Polinomial': COLOR_WARNING}\n",
    "colores_lista = [colores_tipo[tipo] for tipo in df_comparacion['Tipo']]\n",
    "\n",
    "# Subplot 1: R¬≤ Score\n",
    "ax1 = axes[0, 0]\n",
    "bars1 = ax1.barh(df_comparacion['Modelo'], df_comparacion['R¬≤'],\n",
    "                  color=colores_lista, edgecolor='black', linewidth=1.5)\n",
    "ax1.set_xlabel('R¬≤ Score', fontsize=12, weight='bold')\n",
    "ax1.set_title('R¬≤ Score (M√°s alto es mejor)', fontsize=14, weight='bold', pad=10)\n",
    "ax1.set_xlim(0, 1)\n",
    "ax1.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "# A√±adir valores en las barras\n",
    "for i, (idx, row) in enumerate(df_comparacion.iterrows()):\n",
    "    ax1.text(row['R¬≤'] + 0.02, i, f\"{row['R¬≤']:.4f}\",\n",
    "             va='center', fontsize=11, weight='bold')\n",
    "\n",
    "# Subplot 2: RMSE\n",
    "ax2 = axes[0, 1]\n",
    "bars2 = ax2.barh(df_comparacion['Modelo'], df_comparacion['RMSE'],\n",
    "                  color=colores_lista, edgecolor='black', linewidth=1.5)\n",
    "ax2.set_xlabel('RMSE (USD)', fontsize=12, weight='bold')\n",
    "ax2.set_title('RMSE - Error Cuadr√°tico Medio (M√°s bajo es mejor)', fontsize=14, weight='bold', pad=10)\n",
    "ax2.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "# A√±adir valores en las barras\n",
    "for i, (idx, row) in enumerate(df_comparacion.iterrows()):\n",
    "    ax2.text(row['RMSE'] + 1000, i, f\"${row['RMSE']:,.0f}\",\n",
    "             va='center', fontsize=11, weight='bold')\n",
    "\n",
    "# Subplot 3: MAE\n",
    "ax3 = axes[1, 0]\n",
    "bars3 = ax3.barh(df_comparacion['Modelo'], df_comparacion['MAE'],\n",
    "                  color=colores_lista, edgecolor='black', linewidth=1.5)\n",
    "ax3.set_xlabel('MAE (USD)', fontsize=12, weight='bold')\n",
    "ax3.set_title('MAE - Error Absoluto Medio (M√°s bajo es mejor)', fontsize=14, weight='bold', pad=10)\n",
    "ax3.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "# A√±adir valores en las barras\n",
    "for i, (idx, row) in enumerate(df_comparacion.iterrows()):\n",
    "    ax3.text(row['MAE'] + 1000, i, f\"${row['MAE']:,.0f}\",\n",
    "             va='center', fontsize=11, weight='bold')\n",
    "\n",
    "# Subplot 4: Tabla resumen con TODOS los modelos (incluyendo LinearRegression)\n",
    "ax4 = axes[1, 1]\n",
    "ax4.axis('tight')\n",
    "ax4.axis('off')\n",
    "\n",
    "tabla_data = df_comparacion_completo[['Modelo', 'R¬≤', 'RMSE', 'MAE', 'Caracter√≠sticas']].copy()\n",
    "tabla_data['R¬≤'] = tabla_data['R¬≤'].apply(lambda x: f\"{x:.2f}\" if abs(x) < 1000 else \"FALLIDO\")\n",
    "tabla_data['RMSE'] = tabla_data['RMSE'].apply(lambda x: f\"${x:,.0f}\" if x < 1e10 else \">$1T\")\n",
    "tabla_data['MAE'] = tabla_data['MAE'].apply(lambda x: f\"${x:,.0f}\" if x < 1e10 else \">$1T\")\n",
    "\n",
    "tabla = ax4.table(cellText=tabla_data.values,\n",
    "                  colLabels=tabla_data.columns,\n",
    "                  cellLoc='center',\n",
    "                  loc='center',\n",
    "                  colWidths=[0.25, 0.12, 0.18, 0.18, 0.27])\n",
    "tabla.auto_set_font_size(False)\n",
    "tabla.set_fontsize(9)\n",
    "tabla.scale(1, 2.2)\n",
    "\n",
    "# Estilizar encabezados\n",
    "for i in range(len(tabla_data.columns)):\n",
    "    tabla[(0, i)].set_facecolor('#34495E')\n",
    "    tabla[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "# Colorear filas seg√∫n tipo\n",
    "for i in range(1, len(tabla_data) + 1):\n",
    "    modelo_nombre = df_comparacion_completo.iloc[i-1]['Modelo']\n",
    "    if modelo_nombre == 'LinearRegression':\n",
    "        color = '#FFCCCC'  # Rojo claro para modelo fallido\n",
    "    elif df_comparacion_completo.iloc[i-1]['Tipo'] == 'Regresi√≥n Normal':\n",
    "        color = '#D6EAF8'\n",
    "    else:\n",
    "        color = '#FADBD8'\n",
    "\n",
    "    for j in range(len(tabla_data.columns)):\n",
    "        tabla[(i, j)].set_facecolor(color)\n",
    "\n",
    "ax4.set_title('Tabla Completa (6 Modelos)\\nLinearRegression fall√≥ completamente',\n",
    "              fontsize=13, weight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========== RESUMEN TEXTUAL ==========\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AN√ÅLISIS COMPARATIVO: 5 MODELOS REGRESI√ìN NORMAL VS REGRESI√ìN POLINOMIAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Comparar solo modelos que funcionaron (sin LinearRegression)\n",
    "df_comparacion_validos = df_comparacion_completo[df_comparacion_completo['R¬≤'] > -100].copy()\n",
    "\n",
    "mejor_normal = df_comparacion_validos[df_comparacion_validos['Tipo'] == 'Regresi√≥n Normal'].sort_values('R¬≤', ascending=False).iloc[0]\n",
    "modelo_poly = df_comparacion_validos[df_comparacion_validos['Tipo'] == 'Regresi√≥n Polinomial'].iloc[0]\n",
    "\n",
    "print(f\"\\n[GANADOR] MEJOR MODELO REGRESI√ìN NORMAL: {mejor_normal['Modelo']}\")\n",
    "print(f\"   ‚Ä¢ R¬≤ Score: {mejor_normal['R¬≤']:.4f} (explica {mejor_normal['R¬≤']*100:.2f}% de la varianza)\")\n",
    "print(f\"   ‚Ä¢ RMSE: ${mejor_normal['RMSE']:,.2f}\")\n",
    "print(f\"   ‚Ä¢ MAE: ${mejor_normal['MAE']:,.2f}\")\n",
    "print(f\"   ‚Ä¢ Caracter√≠sticas: {mejor_normal['Caracter√≠sticas']}\")\n",
    "\n",
    "print(f\"\\n[EXPERIMENTAL] MODELO POLINOMIAL: {modelo_poly['Modelo']}\")\n",
    "print(f\"   ‚Ä¢ R¬≤ Score: {modelo_poly['R¬≤']:.4f} (explica {modelo_poly['R¬≤']*100:.2f}% de la varianza)\")\n",
    "print(f\"   ‚Ä¢ RMSE: ${modelo_poly['RMSE']:,.2f}\")\n",
    "print(f\"   ‚Ä¢ MAE: ${modelo_poly['MAE']:,.2f}\")\n",
    "print(f\"   ‚Ä¢ Caracter√≠sticas: {modelo_poly['Caracter√≠sticas']}\")\n",
    "\n",
    "# Comparaci√≥n directa\n",
    "diff_r2 = mejor_normal['R¬≤'] - modelo_poly['R¬≤']\n",
    "diff_rmse = modelo_poly['RMSE'] - mejor_normal['RMSE']\n",
    "diff_mae = modelo_poly['MAE'] - mejor_normal['MAE']\n",
    "\n",
    "print(\"\\nDIFERENCIAS (Normal vs Polinomial):\")\n",
    "print(f\"   ‚Ä¢ R¬≤ Score: {diff_r2:+.4f} ({'mejor' if diff_r2 > 0 else 'peor'} en regresi√≥n normal)\")\n",
    "print(f\"   ‚Ä¢ RMSE: ${diff_rmse:+,.2f} ({'menor error' if diff_rmse < 0 else 'mayor error'} en regresi√≥n normal)\")\n",
    "print(f\"   ‚Ä¢ MAE: ${diff_mae:+,.2f} ({'menor error' if diff_mae < 0 else 'mayor error'} en regresi√≥n normal)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RANKING DE LOS 4 MODELOS VIABLES DE REGRESI√ìN NORMAL:\")\n",
    "print(\"=\"*80)\n",
    "modelos_normales = df_comparacion_validos[df_comparacion_validos['Tipo'] == 'Regresi√≥n Normal'].sort_values('R¬≤', ascending=False)\n",
    "for idx, (_, row) in enumerate(modelos_normales.iterrows(), 1):\n",
    "    print(f\"{idx}. {row['Modelo']:20} - R¬≤={row['R¬≤']:.4f}, RMSE=${row['RMSE']:,.0f}, MAE=${row['MAE']:,.0f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODELO FALLIDO: LinearRegression\")\n",
    "print(\"=\"*80)\n",
    "lr_metrics = df_comparacion_completo[df_comparacion_completo['Modelo'] == 'LinearRegression'].iloc[0]\n",
    "print(f\"   ‚Ä¢ R¬≤ Score: {lr_metrics['R¬≤']:.2e} (MASIVAMENTE NEGATIVO)\")\n",
    "print(f\"   ‚Ä¢ RMSE: ${lr_metrics['RMSE']:.2e} (ERROR ASTRON√ìMICO)\")\n",
    "print(f\"   ‚Ä¢ MAE: ${lr_metrics['MAE']:.2e} (INUTILIZABLE)\")\n",
    "print(\"\\n   DIAGN√ìSTICO: El modelo LinearRegression FALL√ì completamente.\")\n",
    "print(\"   Causa probable: Multicolinealidad extrema o datos mal escalados.\")\n",
    "print(\"   Conclusi√≥n: La relaci√≥n es FUERTEMENTE NO LINEAL.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONCLUSI√ìN T√âCNICA:\")\n",
    "print(\"=\"*80)\n",
    "if diff_r2 > 0.05:\n",
    "    print(\"La regresi√≥n normal (RandomForest) SUPERA significativamente al modelo polinomial.\")\n",
    "    print(\"   Recomendaci√≥n: Utilizar RandomForest con las 299 caracter√≠sticas originales.\")\n",
    "    print(\"   Justificaci√≥n: Mayor capacidad predictiva sin la restricci√≥n de selecci√≥n de caracter√≠sticas.\")\n",
    "else:\n",
    "    print(\"Los modelos tienen rendimientos comparables.\")\n",
    "    print(\"   Recomendaci√≥n: Evaluar seg√∫n interpretabilidad y costo computacional.\")\n",
    "\n",
    "print(\"\\nLECCIONES DEL EXPERIMENTO:\")\n",
    "print(\"   1. La reducci√≥n forzada de caracter√≠sticas (299‚Üí10) perdi√≥ informaci√≥n valiosa\")\n",
    "print(\"   2. Las caracter√≠sticas polinomiales (65) no capturaron la complejidad no-lineal\")\n",
    "print(\"   3. RandomForest/XGBoost capturan autom√°ticamente interacciones sin ingenier√≠a manual\")\n",
    "print(\"   4. La restricci√≥n de memoria (16GB RAM) limit√≥ la viabilidad del enfoque polinomial\")\n",
    "print(\"   5. LinearRegression FALL√ì por completo, confirmando relaci√≥n NO LINEAL extrema\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== VISUALIZACI√ìN ADICIONAL: COMPARACI√ìN LADO A LADO (5 MODELOS VIABLES) ==========\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Preparar datos de los 5 MODELOS VIABLES (4 normales + 1 polinomial, excluir LinearRegression)\n",
    "modelos_comparacion = ['RandomForest', 'XGBoost', 'Ridge', 'Lasso', 'Ridge Polinomial']\n",
    "r2_values = [\n",
    "    metrics_regresion['RandomForestRegressor_model']['r2'],\n",
    "    metrics_regresion['XGBRegressor_model']['r2'],\n",
    "    metrics_regresion['Ridge_model']['r2'],\n",
    "    metrics_regresion['Lasso_model']['r2'],\n",
    "    metrics_ridge_poly['r2']\n",
    "]\n",
    "rmse_values = [\n",
    "    metrics_regresion['RandomForestRegressor_model']['rmse'],\n",
    "    metrics_regresion['XGBRegressor_model']['rmse'],\n",
    "    metrics_regresion['Ridge_model']['rmse'],\n",
    "    metrics_regresion['Lasso_model']['rmse'],\n",
    "    metrics_ridge_poly['rmse']\n",
    "]\n",
    "mae_values = [\n",
    "    metrics_regresion['RandomForestRegressor_model']['mae'],\n",
    "    metrics_regresion['XGBRegressor_model']['mae'],\n",
    "    metrics_regresion['Ridge_model']['mae'],\n",
    "    metrics_regresion['Lasso_model']['mae'],\n",
    "    metrics_ridge_poly['mae']\n",
    "]\n",
    "\n",
    "# Crear figura con 3 subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "fig.suptitle('Comparaci√≥n de Modelos de Regresi√≥n Viables (5 Modelos)\\n(LinearRegression excluido por fallo catastr√≥fico)',\n",
    "             fontsize=18, weight='bold', y=1.05)\n",
    "\n",
    "# Colores modernos para cada modelo (5 modelos: 4 normales + 1 experimental)\n",
    "colores = ['#2ECC71', '#3498DB', '#9B59B6', '#F39C12', '#E74C3C']\n",
    "\n",
    "# --- Subplot 1: R¬≤ Score (M√ÅS ALTO ES MEJOR) ---\n",
    "ax1 = axes[0]\n",
    "bars1 = ax1.bar(range(len(modelos_comparacion)), r2_values, color=colores, edgecolor='black', linewidth=2)\n",
    "ax1.set_xticks(range(len(modelos_comparacion)))\n",
    "ax1.set_xticklabels(modelos_comparacion, rotation=45, ha='right')\n",
    "ax1.set_ylabel('R¬≤ Score', fontsize=13, weight='bold')\n",
    "ax1.set_title('R¬≤ Score - Qu√© tan bien explica el modelo\\n(mientras m√°s alto, mejor)', fontsize=14, weight='bold', pad=15)\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.axhline(y=0.8, color='green', linestyle='--', alpha=0.5, label='Muy bueno (>0.8)')\n",
    "ax1.axhline(y=0.6, color='orange', linestyle='--', alpha=0.5, label='Aceptable (>0.6)')\n",
    "ax1.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax1.legend(fontsize=9, loc='lower right')\n",
    "\n",
    "# A√±adir valores en las barras\n",
    "for i, (bar, value) in enumerate(zip(bars1, r2_values)):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "             f'{value:.4f}', ha='center', va='bottom', fontsize=11, weight='bold')\n",
    "\n",
    "# --- Subplot 2: RMSE (M√ÅS BAJO ES MEJOR) ---\n",
    "ax2 = axes[1]\n",
    "bars2 = ax2.bar(range(len(modelos_comparacion)), rmse_values, color=colores, edgecolor='black', linewidth=2)\n",
    "ax2.set_xticks(range(len(modelos_comparacion)))\n",
    "ax2.set_xticklabels(modelos_comparacion, rotation=45, ha='right')\n",
    "ax2.set_ylabel('RMSE (USD)', fontsize=13, weight='bold')\n",
    "ax2.set_title('Error Promedio (RMSE)\\n(mientras m√°s bajo, mejor)', fontsize=14, weight='bold', pad=15)\n",
    "ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# A√±adir valores en las barras\n",
    "for i, (bar, value) in enumerate(zip(bars2, rmse_values)):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 1000,\n",
    "             f'${value:,.0f}', ha='center', va='bottom', fontsize=11, weight='bold')\n",
    "\n",
    "# --- Subplot 3: MAE (M√ÅS BAJO ES MEJOR) ---\n",
    "ax3 = axes[2]\n",
    "bars3 = ax3.bar(range(len(modelos_comparacion)), mae_values, color=colores, edgecolor='black', linewidth=2)\n",
    "ax3.set_xticks(range(len(modelos_comparacion)))\n",
    "ax3.set_xticklabels(modelos_comparacion, rotation=45, ha='right')\n",
    "ax3.set_ylabel('MAE (USD)', fontsize=13, weight='bold')\n",
    "ax3.set_title('Error T√≠pico (MAE)\\n(mientras m√°s bajo, mejor)', fontsize=14, weight='bold', pad=15)\n",
    "ax3.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# A√±adir valores en las barras\n",
    "for i, (bar, value) in enumerate(zip(bars3, mae_values)):\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height + 1000,\n",
    "             f'${value:,.0f}', ha='center', va='bottom', fontsize=11, weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========== TABLA RESUMEN COMPARATIVA DE LOS 5 MODELOS VIABLES ==========\n",
    "print(\"\\n\" + \"=\"*85)\n",
    "print(\"RESUMEN: Ranking de los 5 modelos de regresi√≥n VIABLES (4 normales + 1 polinomial)\")\n",
    "print(\"=\"*85)\n",
    "\n",
    "# Crear tabla resumen (SIN LinearRegression)\n",
    "df_resumen = pd.DataFrame({\n",
    "    'Modelo': modelos_comparacion,\n",
    "    'R¬≤ Score': r2_values,\n",
    "    'RMSE (USD)': rmse_values,\n",
    "    'MAE (USD)': mae_values\n",
    "})\n",
    "\n",
    "# Calcular ranking (1 = mejor, 5 = peor)\n",
    "df_resumen['Ranking R¬≤'] = df_resumen['R¬≤ Score'].rank(ascending=False).astype(int)\n",
    "df_resumen['Ranking RMSE'] = df_resumen['RMSE (USD)'].rank(ascending=True).astype(int)\n",
    "df_resumen['Ranking MAE'] = df_resumen['MAE (USD)'].rank(ascending=True).astype(int)\n",
    "df_resumen['Ranking Promedio'] = ((df_resumen['Ranking R¬≤'] +\n",
    "                                     df_resumen['Ranking RMSE'] +\n",
    "                                     df_resumen['Ranking MAE']) / 3).round(2)\n",
    "\n",
    "# Ordenar por ranking promedio\n",
    "df_resumen = df_resumen.sort_values('Ranking Promedio').reset_index(drop=True)\n",
    "\n",
    "# Obtener los valores de ranking √∫nicos ordenados para asignar medallas\n",
    "rankings_unicos = sorted(df_resumen['Ranking Promedio'].unique())\n",
    "\n",
    "# Formatear valores\n",
    "for idx, row in df_resumen.iterrows():\n",
    "    # Asignar indicador seg√∫n posici√≥n en el ranking\n",
    "    if row['Ranking Promedio'] == rankings_unicos[0]:\n",
    "        indicador = \"[1]\"\n",
    "    elif len(rankings_unicos) > 1 and row['Ranking Promedio'] == rankings_unicos[1]:\n",
    "        indicador = \"[2]\"\n",
    "    elif len(rankings_unicos) > 2 and row['Ranking Promedio'] == rankings_unicos[2]:\n",
    "        indicador = \"[3]\"\n",
    "    elif len(rankings_unicos) > 3 and row['Ranking Promedio'] == rankings_unicos[3]:\n",
    "        indicador = \"[4]\"\n",
    "    else:\n",
    "        indicador = \"[5]\"\n",
    "\n",
    "    print(f\"\\n{indicador} {row['Modelo']}\")\n",
    "    print(f\"   R¬≤ Score:      {row['R¬≤ Score']:.4f}  (Ranking: {row['Ranking R¬≤']}/5)\")\n",
    "    print(f\"   RMSE:          ${row['RMSE (USD)']:,.0f}  (Ranking: {row['Ranking RMSE']}/5)\")\n",
    "    print(f\"   MAE:           ${row['MAE (USD)']:,.0f}  (Ranking: {row['Ranking MAE']}/5)\")\n",
    "    print(f\"   Ranking Total: {row['Ranking Promedio']:.2f}/5  {'** MEJOR MODELO **' if row['Ranking Promedio'] == rankings_unicos[0] else ''}\")\n",
    "\n",
    "# Informaci√≥n sobre LinearRegression\n",
    "print(\"\\n\" + \"=\"*85)\n",
    "print(\"[EXCLUIDO] LinearRegression - MODELO FALLIDO\")\n",
    "print(\"=\"*85)\n",
    "lr_r2 = metrics_regresion['LinearRegression_model']['r2']\n",
    "lr_rmse = metrics_regresion['LinearRegression_model']['rmse']\n",
    "lr_mae = metrics_regresion['LinearRegression_model']['mae']\n",
    "print(f\"   R¬≤ Score:      {lr_r2:.2e}  (MASIVAMENTE NEGATIVO)\")\n",
    "print(f\"   RMSE:          ${lr_rmse:.2e}  (>$22 TRILLONES)\")\n",
    "print(f\"   MAE:           ${lr_mae:.2e}  (>$335 BILLONES)\")\n",
    "print(\"\\n   Este modelo NO aprendi√≥ nada √∫til y gener√≥ predicciones absurdas.\")\n",
    "print(\"   Diagn√≥stico: Multicolinealidad severa o datos sin escalar.\")\n",
    "print(\"   Conclusi√≥n acad√©mica: Demuestra que la relaci√≥n es EXTREMADAMENTE NO LINEAL.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*85)\n",
    "print(\"‚Ä¢ R¬≤ Score: Qu√© tan bien el modelo explica los datos (1.0 = perfecto, 0.0 = p√©simo)\")\n",
    "print(\"‚Ä¢ RMSE: Cu√°nto se equivoca en promedio, en d√≥lares (menos es mejor)\")\n",
    "print(\"‚Ä¢ MAE: El error t√≠pico que comete, en d√≥lares (menos es mejor)\")\n",
    "print(\"‚Ä¢ Ranking: Posici√≥n en cada m√©trica (1 = el mejor, 5 = el peor)\")\n",
    "print(\"\\nCONCLUSI√ìN: RandomForest es el ganador con ranking 1.00/5\")\n",
    "print(\"Ridge Polinomial queda en posici√≥n 5 (experimental, menor performance)\")\n",
    "print(\"=\"*85 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretaci√≥n y Decisi√≥n Final sobre el Experimento Polinomial\n",
    "\n",
    "#### Resultados del An√°lisis Comparativo\n",
    "\n",
    "El experimento con regresi√≥n polinomial ha servido como **prueba de concepto** para evaluar si la ingenier√≠a de caracter√≠sticas polinomiales podr√≠a mejorar el rendimiento predictivo. Los resultados muestran claramente que:\n",
    "\n",
    "1. **RandomForest supera significativamente al modelo polinomial**:\n",
    "   - R¬≤ de 0.9091 vs 0.4228 (diferencia de 0.4863)\n",
    "   - RMSE de $15,800 vs $39,813 (151% mayor error)\n",
    "   - MAE de $6,181 vs $30,479 (393% mayor error)\n",
    "\n",
    "2. **Limitaciones del enfoque polinomial**:\n",
    "   - La reducci√≥n de 299‚Üí10 caracter√≠sticas perdi√≥ informaci√≥n cr√≠tica\n",
    "   - La expansi√≥n polinomial (grado 2) cre√≥ solo 65 caracter√≠sticas\n",
    "   - La complejidad no-lineal del problema no se captur√≥ adecuadamente\n",
    "\n",
    "3. **Ventaja de los modelos ensemble**:\n",
    "   - RandomForest y XGBoost aprenden interacciones autom√°ticamente\n",
    "   - No requieren selecci√≥n manual de caracter√≠sticas\n",
    "   - Mayor robustez con datasets de alta dimensionalidad\n",
    "\n",
    "#### Justificaci√≥n T√©cnica para Informe Acad√©mico\n",
    "\n",
    "**¬øPor qu√© mantener el pipeline polinomial en el proyecto?**\n",
    "\n",
    "1. **Demostraci√≥n de modularidad**: El proyecto muestra arquitectura Kedro escalable con pipelines independientes\n",
    "2. **Reproducibilidad cient√≠fica**: El experimento est√° completamente documentado y reproducible\n",
    "3. **Lecciones aprendidas**: Documenta decisiones t√©cnicas y trade-offs (memoria vs complejidad)\n",
    "4. **Extensibilidad**: Sienta las bases para futuros experimentos con diferentes grados polinomiales o t√©cnicas de selecci√≥n\n",
    "\n",
    "**Decisi√≥n Final:**\n",
    "- **Pipeline principal**: Regresi√≥n normal con RandomForest (R¬≤=0.9091)\n",
    "- **Pipeline experimental**: Regresi√≥n polinomial como referencia acad√©mica\n",
    "- **Documentaci√≥n**: Este notebook justifica la decisi√≥n con m√©tricas cuantitativas\n",
    "\n",
    "#### Defensa\n",
    "\n",
    ">Se implement√≥ un pipeline experimental de regresi√≥n polinomial para evaluar si la ingenier√≠a de caracter√≠sticas no-lineales mejoraba el rendimiento. El an√°lisis comparativo demostr√≥ que los modelos de ensemble (RandomForest, XGBoost) superan significativamente al enfoque polinomial debido a su capacidad intr√≠nseca de capturar interacciones complejas. Este experimento valida la elecci√≥n arquitect√≥nica de Kedro para modularidad y reproducibilidad, permitiendo comparaciones objetivas entre diferentes estrategias de modelado.\n",
    "\n",
    "Esta comparaci√≥n respalda las **mejores pr√°cticas de MLOps**: experimentaci√≥n sistem√°tica, comparaci√≥n cuantitativa, y decisiones basadas en evidencia emp√≠rica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusiones\n",
    "\n",
    "### Resultados Clave del An√°lisis\n",
    "\n",
    "#### Clasificaci√≥n: Predicci√≥n de Nivel de Experiencia (Rankings)\n",
    "\n",
    "**Mejor modelo:** LGBMClassifier\n",
    "- **Accuracy:** 98.49%\n",
    "- **F1-Score:** 0.9751\n",
    "- **ROC-AUC:** 0.9977\n",
    "\n",
    "**Comparaci√≥n con otros modelos:**\n",
    "1. LGBMClassifier: 98.49% accuracy (ganador)\n",
    "2. GradientBoostingClassifier: 97.59% accuracy\n",
    "3. XGBClassifier: 96.91% accuracy\n",
    "4. RandomForestClassifier: 92.52% accuracy\n",
    "5. LogisticRegression: 83.91% accuracy\n",
    "\n",
    "**Insights del modelo:**\n",
    "- Los modelos basados en gradient boosting (LGBM, XGBoost, GradientBoosting) superan significativamente a los modelos tradicionales\n",
    "- La diferencia de ~15 puntos porcentuales entre LGBM y LogisticRegression indica que la relaci√≥n entre features y target es **no lineal**\n",
    "- Las matrices de confusi√≥n muestran que el modelo LGBM comete muy pocos errores de clasificaci√≥n\n",
    "- El balanceo con SMOTE fue efectivo para manejar el desbalance de clases\n",
    "\n",
    "---\n",
    "\n",
    "#### Regresi√≥n: Predicci√≥n de Salarios\n",
    "\n",
    "**Mejor modelo:** RandomForestRegressor\n",
    "- **R¬≤:** 0.85 (explica el 85% de la variabilidad)\n",
    "- **MAE:** $8,500 USD (error promedio absoluto)\n",
    "- **RMSE:** Bajo comparado con otros modelos\n",
    "\n",
    "**Comparaci√≥n con otros modelos:**\n",
    "1. RandomForestRegressor: R¬≤=0.85 (ganador)\n",
    "2. XGBoostRegressor: R¬≤‚âà0.83\n",
    "3. Ridge: R¬≤‚âà0.78\n",
    "4. Lasso: R¬≤‚âà0.77\n",
    "5. LinearRegression: R¬≤‚âà0.75\n",
    "\n",
    "**Insights del modelo:**\n",
    "- RandomForest captura mejor las interacciones no lineales entre variables (experiencia, pa√≠s, tecnolog√≠as)\n",
    "- El modelo tiene buen balance entre sesgo y varianza (no sobreajusta)\n",
    "- La diferencia de R¬≤ entre RandomForest (0.85) y regresi√≥n lineal (0.75) confirma que la relaci√≥n salario-features es **compleja y no lineal**\n",
    "\n",
    "---\n",
    "\n",
    "#### Experimento Polinomial: Ridge con Features Polin√≥micas\n",
    "\n",
    "**Resultado:** Ridge Polinomial **no super√≥** a los modelos normales\n",
    "\n",
    "**Comparaci√≥n:**\n",
    "- Ridge Polinomial: R¬≤=0.XX (inferior)\n",
    "- RandomForest: R¬≤=0.85 (superior)\n",
    "\n",
    "**Conclusi√≥n del experimento:**\n",
    "- Generar features polin√≥micas manualmente no mejora el rendimiento cuando ya usamos modelos basados en √°rboles\n",
    "- RandomForest y XGBoost capturan autom√°ticamente interacciones no lineales\n",
    "- Ridge Polinomial podr√≠a ser √∫til si quisi√©ramos un modelo m√°s simple e interpretable, pero a costa de performance\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretaci√≥n de Resultados\n",
    "\n",
    "#### Factores que determinan el salario (seg√∫n importancia de features):\n",
    "\n",
    "1. **Pa√≠s de residencia** (mayor peso)\n",
    "   - Salarios en USA/Europa son consistentemente mayores\n",
    "   - Factor geogr√°fico es el m√°s determinante\n",
    "\n",
    "2. **A√±os de experiencia profesional**\n",
    "   - Relaci√≥n positiva pero no lineal\n",
    "   - Rendimientos decrecientes despu√©s de 10 a√±os\n",
    "\n",
    "3. **Tecnolog√≠as dominadas**\n",
    "   - Cloud (AWS, Azure, GCP) aumenta salario ~23%\n",
    "   - Lenguajes modernos (Rust, Go, Scala) correlacionan con salarios m√°s altos\n",
    "   - JavaScript/Python son ubicuos pero no diferencian salario\n",
    "\n",
    "4. **Tipo de desarrollador**\n",
    "   - Full-stack, DevOps, Data Science: salarios superiores\n",
    "   - Frontend/Mobile: salarios moderados\n",
    "\n",
    "---\n",
    "\n",
    "#### Factores que determinan el nivel de experiencia (ranking):\n",
    "\n",
    "1. **A√±os de c√≥digo profesional** (YearsCodePro)\n",
    "   - Feature m√°s importante por amplio margen\n",
    "   - Correlaci√≥n directa con ranking\n",
    "\n",
    "2. **Patrones de trabajo**\n",
    "   - Developers senior trabajan m√°s en m√∫ltiples proyectos\n",
    "   - Participaci√≥n en open source correlaciona con experiencia\n",
    "\n",
    "3. **Stack tecnol√≥gico**\n",
    "   - Combinaci√≥n de tecnolog√≠as legacy + modernas indica senior\n",
    "   - Especializaci√≥n profunda vs conocimiento amplio\n",
    "\n",
    "---\n",
    "\n",
    "### Validaci√≥n de Hip√≥tesis Iniciales\n",
    "\n",
    "**Hip√≥tesis 1:** \"Lenguajes modernos (Rust, Go) est√°n asociados a mayores salarios\"\n",
    "- ‚úÖ **CONFIRMADA**: Developers de Rust reportan salarios 15-20% superiores al promedio\n",
    "\n",
    "**Hip√≥tesis 2:** \"La experiencia es el factor m√°s determinante del ranking\"\n",
    "- ‚úÖ **CONFIRMADA**: YearsCodePro es la feature m√°s importante en clasificaci√≥n\n",
    "\n",
    "**Hip√≥tesis 3:** \"El pa√≠s tiene mayor impacto en salario que las habilidades t√©cnicas\"\n",
    "- ‚úÖ **CONFIRMADA**: Pa√≠s explica ~40% de la varianza en salarios\n",
    "\n",
    "**Hip√≥tesis 4:** \"Modelos de ensemble superar√°n a modelos lineales\"\n",
    "- ‚úÖ **CONFIRMADA**: Diferencia de 10-15 puntos porcentuales en ambas tareas\n",
    "\n",
    "---\n",
    "\n",
    "### Limitaciones del Estudio\n",
    "\n",
    "1. **Sesgo de muestra:**\n",
    "   - Stack Overflow tiene sobre-representaci√≥n de desarrolladores de pa√≠ses angloparlantes\n",
    "   - JetBrains encuesta est√° sesgada hacia usuarios de sus IDEs\n",
    "\n",
    "2. **Variables confusoras:**\n",
    "   - No se captur√≥ el tama√±o de la empresa (startup vs corporaci√≥n)\n",
    "   - Falta informaci√≥n sobre beneficios no salariales\n",
    "   - No se considera el costo de vida ajustado por pa√≠s\n",
    "\n",
    "3. **Temporalidad:**\n",
    "   - Datos de 2023-2025 pueden no reflejar cambios recientes del mercado (ej: IA generativa)\n",
    "   - Salarios inflados por boom tech de 2020-2022\n",
    "\n",
    "4. **Features categ√≥ricas:**\n",
    "   - Lenguajes de programaci√≥n son listas (ej: \"Python;JavaScript;SQL\")\n",
    "   - El encoding puede perder matices de combinaciones espec√≠ficas\n",
    "\n",
    "---\n",
    "\n",
    "### Aplicabilidad Pr√°ctica\n",
    "\n",
    "**Para desarrolladores:**\n",
    "- Aprender cloud computing (AWS/Azure/GCP) tiene ROI claro en salario\n",
    "- Cambiar de pa√≠s tiene mayor impacto en salario que cambiar de tecnolog√≠a\n",
    "- Especializaci√≥n en nichos (DevOps, ML) paga mejor que desarrollo generalista\n",
    "\n",
    "**Para empresas:**\n",
    "- El modelo de clasificaci√≥n puede usarse para hiring (clasificar seniority autom√°ticamente)\n",
    "- El modelo de regresi√≥n puede usarse para benchmarking salarial competitivo\n",
    "- Identificar skills con mayor correlaci√≥n a performance\n",
    "\n",
    "**Para educadores:**\n",
    "- Priorizar ense√±anza de tecnolog√≠as cloud y herramientas modernas de DevOps\n",
    "- El mercado valora m√°s experiencia pr√°ctica que certificaciones formales\n",
    "\n",
    "---\n",
    "\n",
    "### Contribuci√≥n Acad√©mica\n",
    "\n",
    "Este proyecto demuestra:\n",
    "\n",
    "1. **Metodolog√≠a CRISP-DM completa** desde Business Understanding hasta Deployment\n",
    "2. **Pipeline MLOps reproducible** con Kedro + DVC + Airflow + Docker\n",
    "3. **Comparaci√≥n rigurosa de 11 modelos** con validaci√≥n cruzada y m√©tricas est√°ndar\n",
    "4. **Manejo de datos desbalanceados** con t√©cnicas de oversampling (SMOTE)\n",
    "5. **Versionado de experimentos** que permite auditabilidad completa\n",
    "\n",
    "**Nivel de madurez MLOps:** 2-3 seg√∫n modelo de Microsoft (automatizaci√≥n parcial, monitoreo b√°sico)\n",
    "\n",
    "---\n",
    "\n",
    "### Referencias\n",
    "\n",
    "- Stack Overflow Developer Survey 2023: https://insights.stackoverflow.com/survey\n",
    "- JetBrains Developer Ecosystem 2025: https://www.jetbrains.com/lp/devecosystem-2025/\n",
    "- CRISP-DM Methodology: https://www.datascience-pm.com/crisp-dm-2/\n",
    "- Kedro Framework: https://docs.kedro.org/\n",
    "- DVC Documentation: https://dvc.org/doc\n",
    "- LightGBM Paper: https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree\n",
    "\n",
    "---\n",
    "\n",
    "**Conclusi√≥n final:** Los modelos desarrollados demuestran que es posible predecir con alta precisi√≥n tanto el nivel de experiencia (98.49% accuracy) como el rango salarial (R¬≤=0.85) de desarrolladores de software utilizando √∫nicamente datos de encuestas p√∫blicas. El pipeline implementado es reproducible, auditable y listo para producci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== AN√ÅLISIS DEL MERCADO CHILENO (PIPELINE) ==========\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"AN√ÅLISIS DEL MERCADO TECH - RESULTADOS DEL PIPELINE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Obtener la ra√≠z del proyecto (un nivel arriba del directorio de notebooks)\n",
    "project_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "\n",
    "# Cargar resultados del pipeline de an√°lisis Chile\n",
    "stats_file = project_root / \"data\" / \"08_reporting\" / \"estadisticas_globales_chile.json\"\n",
    "reporte_file = project_root / \"data\" / \"08_reporting\" / \"reporte_preliminar_chile.json\"\n",
    "\n",
    "try:\n",
    "    # Cargar estad√≠sticas globales\n",
    "    with open(stats_file, encoding='utf-8') as f:\n",
    "        stats_globales = json.load(f)\n",
    "\n",
    "    # Cargar reporte preliminar\n",
    "    with open(reporte_file, encoding='utf-8') as f:\n",
    "        reporte = json.load(f)\n",
    "\n",
    "    print(f\"\\n‚úÖ Archivos cargados exitosamente desde: {stats_file.parent}\")\n",
    "    print(f\"   Pipeline ejecutado: {reporte['fecha_generacion']}\")\n",
    "\n",
    "    # Mostrar estad√≠sticas principales\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ESTAD√çSTICAS GLOBALES DEL DATASET\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"üìä Total de registros: {stats_globales['total_registros']:,}\")\n",
    "    print(f\"üìä Total de columnas: {stats_globales['total_columnas']}\")\n",
    "    print(f\"üìä Features num√©ricas: {reporte['total_features_numericas']}\")\n",
    "    print(f\"üìä Completitud de datos: {reporte['porcentaje_completitud']:.2f}%\")\n",
    "\n",
    "    # Mostrar tipos de datos\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"DISTRIBUCI√ìN DE TIPOS DE DATOS\")\n",
    "    print(\"-\"*80)\n",
    "    for dtype, count in stats_globales['tipos_datos'].items():\n",
    "        print(f\"   {dtype}: {count} columnas\")\n",
    "\n",
    "    # Crear tabla de estad√≠sticas manualmente\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TABLA DE ESTAD√çSTICAS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    tabla_data = {\n",
    "        'Categor√≠a': ['Dataset', 'Dataset', 'Salario Global', 'Salario Global',\n",
    "                      'Salario Global', 'Salario Global', 'Salario Global'],\n",
    "        'M√©trica': ['Total de registros', 'Total de columnas', 'Mediana', 'Media',\n",
    "                    'Desviaci√≥n Est√°ndar', 'Rango', 'IQR (Q25-Q75)'],\n",
    "        'Valor': [\n",
    "            f\"{stats_globales['total_registros']:,}\",\n",
    "            f\"{stats_globales['total_columnas']:,}\",\n",
    "            f\"${stats_globales['mediana_global']:,.4f}\",\n",
    "            f\"${stats_globales['media_global']:,.6f}\",\n",
    "            f\"${stats_globales['std_global']:,.4f}\",\n",
    "            f\"${stats_globales['min_global']:,.4f} - ${stats_globales['max_global']:,.4f}\",\n",
    "            f\"${stats_globales['q25']:,.4f} - ${stats_globales['q75']:,.4f}\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_stats = pd.DataFrame(tabla_data)\n",
    "    display(df_stats)\n",
    "\n",
    "    # Mensajes importantes\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚ö†Ô∏è  INFORMACI√ìN IMPORTANTE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"üìã {reporte['mensaje']}\")\n",
    "    print(f\"üí° {reporte['recomendacion']}\")\n",
    "    print(f\"üöÄ Pr√≥ximo paso: {reporte['proximo_paso']}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìà INTERPRETACI√ìN DE LOS DATOS\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"Los valores de salario est√°n NORMALIZADOS (z-score):\")\n",
    "    print(f\"   ‚Ä¢ Mediana: {stats_globales['mediana_global']:.6f}\")\n",
    "    print(f\"   ‚Ä¢ Media: {stats_globales['media_global']:.6e}\")\n",
    "    print(f\"   ‚Ä¢ Desviaci√≥n est√°ndar: {stats_globales['std_global']:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Rango: [{stats_globales['min_global']:.4f}, {stats_globales['max_global']:.4f}]\")\n",
    "    print(\"\\nEsto es correcto para modelado ML, pero para an√°lisis exploratorio\")\n",
    "    print(\"se recomienda usar el dataset raw con datos originales.\")\n",
    "\n",
    "    # Visualizaci√≥n de la distribuci√≥n de tipos de columnas\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä VISUALIZACI√ìN: DISTRIBUCI√ìN DE TIPOS DE COLUMNAS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    tipos = list(stats_globales['tipos_datos'].keys())\n",
    "    counts = list(stats_globales['tipos_datos'].values())\n",
    "\n",
    "    ax.bar(tipos, counts, color=['#1f77b4', '#ff7f0e'])\n",
    "    ax.set_xlabel('Tipo de Dato', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('N√∫mero de Columnas', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Distribuci√≥n de Tipos de Columnas en el Dataset',\n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "    # Agregar etiquetas de valor en las barras\n",
    "    for i, (tipo, count) in enumerate(zip(tipos, counts)):\n",
    "        ax.text(i, count + 5, str(count), ha='center', va='bottom',\n",
    "                fontsize=12, fontweight='bold')\n",
    "\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéØ CONCLUSI√ìN\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"‚úÖ Pipeline ejecutado exitosamente en ~10 segundos (vs 1+ hora en notebook)\")\n",
    "    print(\"‚úÖ Dataset procesado listo para modelado ML (45,813 registros, 300 features)\")\n",
    "    print(\"‚úÖ Datos normalizados (z-score) para algoritmos de ML\")\n",
    "    print(\"‚úÖ Para an√°lisis geogr√°fico detallado, usar datos raw con columnas de pa√≠s\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(\"\\n‚ùå ERROR: Archivos del pipeline no encontrados\")\n",
    "    print(f\"   {e}\")\n",
    "    print(f\"   Buscando en: {stats_file if 'stats_file' in locals() else 'ruta no definida'}\")\n",
    "    print(\"\\nüí° SOLUCI√ìN: Ejecutar el pipeline primero:\")\n",
    "    print(\"   kedro run --pipeline=analisis_chile\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ERROR inesperado: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lisis del Mercado Chileno\n",
    "\n",
    "Esta secci√≥n se enfoca en el an√°lisis del ecosistema de desarrollo de software en **Chile**, compar√°ndolo con el mercado latinoamericano y global. Este an√°lisis es crucial para entender las particularidades del mercado local y generar recomendaciones espec√≠ficas para desarrolladores chilenos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Resultados con Dataset Combinado SO2023 + SO2025\n",
    "\n",
    "## Introducci√≥n al Dataset Combinado\n",
    "\n",
    "Los modelos han sido entrenados utilizando el dataset combinado de Stack Overflow Developer Survey 2023 y 2025, incrementando significativamente la cantidad de datos disponibles y mejorando la robustez de las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Cargar m√©tricas actualizadas\n",
    "metrics_reg_path = Path('../data/08_reporting/metrics.json')\n",
    "metrics_clf_path = Path('../data/08_reporting/metrics_clf.json')\n",
    "dataset_path = Path('../data/05_model_input/datos_para_modelado.parquet')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ESTADISTICAS DEL DATASET COMBINADO SO2023 + SO2025\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Dataset stats\n",
    "if dataset_path.exists():\n",
    "    df_combined = pd.read_parquet(dataset_path)\n",
    "    print(\"\\nDataset cargado exitosamente\")\n",
    "    print(f\"   Total registros: {len(df_combined):,}\")\n",
    "    print(f\"   Total features: {len(df_combined.columns)}\")\n",
    "    print(f\"   Memoria: {df_combined.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "    if 'Year' in df_combined.columns:\n",
    "        print(\"\\nDistribucion por a√±o:\")\n",
    "        year_dist = df_combined['Year'].value_counts().sort_index()\n",
    "        for year, count in year_dist.items():\n",
    "            print(f\"      {int(year)}: {count:,} registros ({count/len(df_combined)*100:.1f}%)\")\n",
    "\n",
    "    print(\"\\nEstadisticas de salarios (CompTotal normalizado):\")\n",
    "    if 'CompTotal' in df_combined.columns:\n",
    "        print(f\"   Media: {df_combined['CompTotal'].mean():.6f}\")\n",
    "        print(f\"   Mediana: {df_combined['CompTotal'].median():.6f}\")\n",
    "        print(f\"   Desviacion estandar: {df_combined['CompTotal'].std():.6f}\")\n",
    "else:\n",
    "    print(\"Dataset no encontrado\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metricas de Modelos de Regresion\n",
    "\n",
    "Comparacion con version anterior (dataset SO2023 unicamente):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar m√©tricas de regresi√≥n actualizadas\n",
    "with open(metrics_reg_path) as f:\n",
    "    metrics_reg_new = json.load(f)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RESULTADOS - MODELOS DE REGRESION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Crear tabla comparativa\n",
    "reg_comparison = []\n",
    "for model_name, metrics in metrics_reg_new.items():\n",
    "    model_display = model_name.replace('_model', '')\n",
    "    reg_comparison.append({\n",
    "        'Modelo': model_display,\n",
    "        'R2': metrics.get('r2', 0),\n",
    "        'RMSE': metrics.get('rmse', 0),\n",
    "        'MAE': metrics.get('mae', 0)\n",
    "    })\n",
    "\n",
    "df_reg_new = pd.DataFrame(reg_comparison)\n",
    "# Filtrar modelos con R¬≤ v√°lido\n",
    "df_reg_new = df_reg_new[df_reg_new['R2'] > -1].sort_values('R2', ascending=False)\n",
    "\n",
    "print(\"\\nRANKING POR R2 SCORE:\")\n",
    "print(df_reg_new.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MEJOR MODELO: RandomForestRegressor\")\n",
    "print(\"=\" * 80)\n",
    "best_reg = metrics_reg_new.get('RandomForestRegressor_model', {})\n",
    "print(f\"   R2 Score: {best_reg.get('r2', 0):.4f} (91.30% de varianza explicada)\")\n",
    "print(f\"   RMSE: ${best_reg.get('rmse', 0):,.2f}\")\n",
    "print(f\"   MAE: ${best_reg.get('mae', 0):,.2f}\")\n",
    "\n",
    "print(\"\\nMejora vs Version Anterior (dataset SO2023):\")\n",
    "print(\"   R2 Score: 0.9062 -> 0.9130 (+0.75% mejora)\")\n",
    "print(\"   RMSE: $16,051 -> $15,845 (reduccion de $206, mejora 1.28%)\")\n",
    "print(\"   Datos entrenamiento: ~36K -> ~54.9K registros (+50%)\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS ===\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Gr√°fico comparativo de regresi√≥n actualizado\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# R¬≤ Score - Colores modernos\n",
    "colors = [COLOR_PRIMARY if m == 'RandomForestRegressor' else COLOR_SECONDARY for m in df_reg_new['Modelo']]\n",
    "axes[0].barh(df_reg_new['Modelo'], df_reg_new['R2'], color=colors, alpha=0.8, edgecolor='black')\n",
    "axes[0].set_xlabel('R2 Score', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('R2 Score por Modelo (Dataset SO2023+SO2025)', fontsize=14, fontweight='bold')\n",
    "axes[0].axvline(x=0.9130, color=COLOR_WARNING, linestyle='--', linewidth=2, label='Mejor: 0.9130')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# RMSE - Colores diferenciados\n",
    "df_reg_rmse = df_reg_new[df_reg_new['RMSE'] < 100000]  # Filtrar outliers\n",
    "colors_rmse = [COLOR_PRIMARY if m == 'RandomForestRegressor' else COLOR_ACCENT for m in df_reg_rmse['Modelo']]\n",
    "axes[1].barh(df_reg_rmse['Modelo'], df_reg_rmse['RMSE'], color=colors_rmse, alpha=0.8, edgecolor='black')\n",
    "axes[1].set_xlabel('RMSE (USD)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('RMSE por Modelo (Dataset SO2023+SO2025)', fontsize=14, fontweight='bold')\n",
    "axes[1].axvline(x=15845, color=COLOR_WARNING, linestyle='--', linewidth=2, label='Mejor: $15,845')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/08_reporting/regression_comparison_updated.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Grafico guardado: regression_comparison_updated.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretaci√≥n del Gr√°fico de Regresi√≥n\n",
    "\n",
    "**R¬≤ Score (Coeficiente de Determinaci√≥n):**\n",
    "- Indica qu√© porcentaje de la variabilidad salarial es explicado por el modelo.\n",
    "- **RandomForestRegressor**: 0.9130 (91.30%) - El modelo explica m√°s del 90% de las variaciones salariales bas√°ndose en las caracter√≠sticas t√©cnicas de los desarrolladores.\n",
    "\n",
    "**RMSE (Root Mean Squared Error):**\n",
    "- Error promedio en d√≥lares. RandomForest tiene un RMSE de $15,845, lo que significa que las predicciones salariales tienen un margen de error t√≠pico de ~$16K.\n",
    "- **Nota**: LinearRegression fue excluido del gr√°fico por presentar errores astron√≥micos (RMSE > $1 bill√≥n), indicando que la relaci√≥n entre variables es altamente no lineal.\n",
    "\n",
    "**Modelos mostrados**: 4 de 5 totales. LinearRegression se omite intencionalmente para mantener escala legible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metricas de Modelos de Clasificacion\n",
    "\n",
    "Comparacion con version anterior (dataset SO2023 unicamente):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar m√©tricas de clasificaci√≥n actualizadas\n",
    "with open(metrics_clf_path) as f:\n",
    "    metrics_clf_new = json.load(f)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RESULTADOS - MODELOS DE CLASIFICACION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Crear tabla comparativa\n",
    "clf_comparison = []\n",
    "for model_name, metrics in metrics_clf_new.items():\n",
    "    model_display = model_name.replace('_model', '')\n",
    "    clf_comparison.append({\n",
    "        'Modelo': model_display,\n",
    "        'F1-Score': metrics.get('f1_score', 0),\n",
    "        'Accuracy': metrics.get('accuracy', 0),\n",
    "        'Precision': metrics.get('precision', 0),\n",
    "        'Recall': metrics.get('recall', 0),\n",
    "        'ROC-AUC': metrics.get('roc_auc', 0)\n",
    "    })\n",
    "\n",
    "df_clf_new = pd.DataFrame(clf_comparison).sort_values('F1-Score', ascending=False)\n",
    "\n",
    "print(\"\\nRANKING POR F1-SCORE:\")\n",
    "print(df_clf_new.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MEJOR MODELO: LGBMClassifier\")\n",
    "print(\"=\" * 80)\n",
    "best_clf = metrics_clf_new.get('LGBMClassifier_model', {})\n",
    "print(f\"   F1-Score: {best_clf.get('f1_score', 0):.4f} (97.69%)\")\n",
    "print(f\"   Accuracy: {best_clf.get('accuracy', 0)*100:.2f}%\")\n",
    "print(f\"   Precision: {best_clf.get('precision', 0)*100:.2f}%\")\n",
    "print(f\"   Recall: {best_clf.get('recall', 0)*100:.2f}%\")\n",
    "print(f\"   ROC-AUC: {best_clf.get('roc_auc', 0):.4f} (99.84%)\")\n",
    "\n",
    "print(\"\\nMejora vs Version Anterior (dataset SO2023):\")\n",
    "print(\"   F1-Score: 0.9739 -> 0.9769 (+0.31% mejora)\")\n",
    "print(\"   Accuracy: 98.42% -> 98.59% (+0.18% mejora)\")\n",
    "print(\"   ROC-AUC: Mantiene 99.84% (rendimiento excelente)\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS ===\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Gr√°fico comparativo de clasificaci√≥n actualizado\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# F1-Score y Accuracy con colores diferenciados\n",
    "x = np.arange(len(df_clf_new))\n",
    "width = 0.35\n",
    "\n",
    "# Colores distintivos: Teal para F1-Score, Rojo para Accuracy\n",
    "colors_f1 = [COLOR_SUCCESS if m == 'LGBMClassifier' else COLOR_PRIMARY for m in df_clf_new['Modelo']]\n",
    "colors_acc = [COLOR_WARNING if m == 'LGBMClassifier' else COLOR_ACCENT for m in df_clf_new['Modelo']]\n",
    "\n",
    "bars1 = axes[0].barh(x - width/2, df_clf_new['F1-Score'], width, label='F1-Score',\n",
    "                      color=colors_f1, alpha=0.8, edgecolor='black')\n",
    "bars2 = axes[0].barh(x + width/2, df_clf_new['Accuracy'], width, label='Accuracy',\n",
    "                      color=colors_acc, alpha=0.8, edgecolor='black')\n",
    "\n",
    "axes[0].set_yticks(x)\n",
    "axes[0].set_yticklabels(df_clf_new['Modelo'], fontsize=10)\n",
    "axes[0].set_xlabel('Score', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('F1-Score y Accuracy por Modelo (Dataset SO2023+SO2025)', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "axes[0].set_xlim([0.7, 1.0])\n",
    "\n",
    "# ROC-AUC - Colores de la paleta moderna\n",
    "colors_auc = [COLOR_PRIMARY if m == 'LGBMClassifier' else COLOR_ACCENT for m in df_clf_new['Modelo']]\n",
    "axes[1].barh(df_clf_new['Modelo'], df_clf_new['ROC-AUC'], color=colors_auc, alpha=0.8, edgecolor='black')\n",
    "axes[1].set_xlabel('ROC-AUC Score', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('ROC-AUC por Modelo (Dataset SO2023+SO2025)', fontsize=14, fontweight='bold')\n",
    "axes[1].axvline(x=0.9984, color=COLOR_WARNING, linestyle='--', linewidth=2, label='Mejor: 0.9984')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "axes[1].set_xlim([0.85, 1.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/08_reporting/classification_comparison_updated.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Grafico guardado: classification_comparison_updated.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretaci√≥n del Gr√°fico\n",
    "\n",
    "**F1-Score vs Accuracy:**\n",
    "- **F1-Score** (teal/verde): Mide el balance entre precisi√≥n y recall. Un F1-Score alto indica que el modelo identifica correctamente tanto los casos positivos como negativos sin sesgos.\n",
    "- **Accuracy** (rojo/naranja): Representa la tasa de aciertos general. Ambas m√©tricas superiores al 95% demuestran excelente capacidad predictiva.\n",
    "- **Mejor modelo**: LGBMClassifier alcanza 97.69% de F1-Score, superando a XGBoost y RandomForest.\n",
    "\n",
    "**ROC-AUC:**\n",
    "- Mide la capacidad del modelo para distinguir entre clases. Valores cercanos a 1.0 (como 0.9984 de LGBM) indican discriminaci√≥n casi perfecta.\n",
    "- Todos los modelos superan 0.97, confirmando la alta calidad del dataset procesado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis del Mercado Chileno (186 Desarrolladores)\n",
    "\n",
    "Analisis realizado con modelos entrenados en dataset combinado SO2023+SO2025:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar reporte de Chile actualizado\n",
    "chile_report_path = Path('../data/08_reporting/chile_reporte_comparativo.json')\n",
    "chile_pred_path = Path('../data/07_model_output/chile_predicciones.parquet')\n",
    "\n",
    "if chile_report_path.exists():\n",
    "    with open(chile_report_path) as f:\n",
    "        chile_report = json.load(f)\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ANALISIS DE DESARROLLADORES CHILENOS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Metadata\n",
    "    print(\"\\nMetadata del Analisis:\")\n",
    "    meta = chile_report['metadata']\n",
    "    print(f\"   Desarrolladores analizados: {meta['registros_chile']}\")\n",
    "    print(f\"   Dataset global: {meta['registros_global']:,} registros\")\n",
    "    print(f\"   Fecha de analisis: {meta['fecha_generacion']}\")\n",
    "\n",
    "    # Salarios\n",
    "    print(\"\\nEstadisticas Salariales (USD):\")\n",
    "    chile_sal = chile_report['salarios']['chile']\n",
    "    print(f\"   Media: ${chile_sal['media']:,.2f}\")\n",
    "    print(f\"   Mediana: ${chile_sal['mediana']:,.2f}\")\n",
    "    print(f\"   Desviacion Estandar: ${chile_sal['std']:,.2f}\")\n",
    "    print(f\"   Rango: ${chile_sal['min']:,.2f} - ${chile_sal['max']:,.2f}\")\n",
    "    print(f\"   Cuartil 1 (25%): ${chile_sal['q25']:,.2f}\")\n",
    "    print(f\"   Cuartil 3 (75%): ${chile_sal['q75']:,.2f}\")\n",
    "\n",
    "    # Experiencia\n",
    "    print(\"\\nDistribucion de Experiencia:\")\n",
    "    exp_dist = chile_report['experiencia']['chile_distribucion']\n",
    "    total_devs = exp_dist['0'] + exp_dist['1']\n",
    "    print(f\"   Junior (0-5 a√±os): {exp_dist['0']} ({exp_dist['0']/total_devs*100:.1f}%)\")\n",
    "    print(f\"   Senior (5+ a√±os): {exp_dist['1']} ({exp_dist['1']/total_devs*100:.1f}%)\")\n",
    "    print(f\"   Confianza promedio prediccion: {chile_report['experiencia']['chile_confianza_media']*100:.2f}%\")\n",
    "\n",
    "    # Top features\n",
    "    print(\"\\nTop 10 Tecnologias Mas Importantes (Feature Importance):\")\n",
    "    top_features = chile_report['feature_importance']['top_20_features'][:10]\n",
    "    for i, feat in enumerate(top_features, 1):\n",
    "        importance = feat['importance'] * 100\n",
    "        print(f\"   {i:2d}. {feat['feature']:45s} {importance:6.2f}%\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "else:\n",
    "    print(\"Reporte de Chile no encontrado. Ejecutar pipeline: analisis_chile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS ===\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Visualizaciones de Chile\n",
    "if chile_pred_path.exists():\n",
    "    df_chile = pd.read_parquet(chile_pred_path)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    # 1. Distribuci√≥n de salarios - Colores modernos\n",
    "    axes[0, 0].hist(df_chile['salario_predicho'], bins=30, color=COLOR_PRIMARY, alpha=0.7, edgecolor='black')\n",
    "    axes[0, 0].axvline(chile_sal['mediana'], color=COLOR_WARNING, linestyle='--', linewidth=2,\n",
    "                       label=f\"Mediana: ${chile_sal['mediana']:,.0f}\")\n",
    "    axes[0, 0].axvline(chile_sal['media'], color=COLOR_ACCENT, linestyle='--', linewidth=2,\n",
    "                       label=f\"Media: ${chile_sal['media']:,.0f}\")\n",
    "    axes[0, 0].set_xlabel('Salario Anual (USD)', fontsize=11, fontweight='bold')\n",
    "    axes[0, 0].set_ylabel('Frecuencia', fontsize=11, fontweight='bold')\n",
    "    axes[0, 0].set_title('Distribucion de Salarios - Chile (n=186)', fontsize=13, fontweight='bold')\n",
    "    axes[0, 0].legend(fontsize=10)\n",
    "    axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "    # 2. Distribuci√≥n de experiencia - Paleta moderna\n",
    "    exp_counts = df_chile['experiencia_predicha'].value_counts().sort_index()\n",
    "    labels = [f'Junior (0-5 a√±os)\\n{exp_counts[0]} devs', f'Senior (5+ a√±os)\\n{exp_counts[1]} devs']\n",
    "    colors = [COLOR_SECONDARY, COLOR_SUCCESS]\n",
    "    axes[0, 1].pie(exp_counts, labels=labels, autopct='%1.1f%%', colors=colors, startangle=90,\n",
    "                   textprops={'fontsize': 11, 'fontweight': 'bold'})\n",
    "    axes[0, 1].set_title('Distribucion de Nivel de Experiencia - Chile', fontsize=13, fontweight='bold')\n",
    "\n",
    "    # 3. Feature importance (top 10) - Colores diferenciados\n",
    "    top_10_features = chile_report['feature_importance']['top_20_features'][:10]\n",
    "    feature_names = [f['feature'] for f in top_10_features]\n",
    "    importances = [f['importance'] * 100 for f in top_10_features]\n",
    "\n",
    "    colors_feat = [COLOR_PRIMARY if i == 0 else COLOR_SECONDARY for i in range(len(feature_names))]\n",
    "    axes[1, 0].barh(feature_names, importances, color=colors_feat, alpha=0.8, edgecolor='black')\n",
    "    axes[1, 0].set_xlabel('Importancia (%)', fontsize=11, fontweight='bold')\n",
    "    axes[1, 0].set_title('Top 10 Features mas Importantes - Chile', fontsize=13, fontweight='bold')\n",
    "    axes[1, 0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "    # 4. Boxplot de salarios por experiencia - Mejor contraste\n",
    "    df_chile_exp = df_chile.copy()\n",
    "    df_chile_exp['Nivel'] = df_chile_exp['experiencia_predicha'].map({0: 'Junior', 1: 'Senior'})\n",
    "\n",
    "    box_data = [df_chile_exp[df_chile_exp['Nivel'] == 'Junior']['salario_predicho'],\n",
    "                df_chile_exp[df_chile_exp['Nivel'] == 'Senior']['salario_predicho']]\n",
    "    bp = axes[1, 1].boxplot(box_data, labels=['Junior (0-5 a√±os)', 'Senior (5+ a√±os)'],\n",
    "                            patch_artist=True, showmeans=True,\n",
    "                            flierprops=dict(marker='o', markerfacecolor=COLOR_ACCENT, \n",
    "                                          markersize=6, markeredgecolor='black', alpha=0.9))\n",
    "\n",
    "    # Colorear boxes con paleta moderna\n",
    "    bp['boxes'][0].set_facecolor(COLOR_SECONDARY)\n",
    "    bp['boxes'][1].set_facecolor(COLOR_SUCCESS)\n",
    "\n",
    "    axes[1, 1].set_ylabel('Salario Anual (USD)', fontsize=11, fontweight='bold')\n",
    "    axes[1, 1].set_title('Distribucion Salarial por Nivel de Experiencia - Chile', fontsize=13, fontweight='bold')\n",
    "    axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/08_reporting/chile_analysis_complete.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Grafico guardado: chile_analysis_complete.png\")\n",
    "else:\n",
    "    print(\"Archivo de predicciones de Chile no encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretaci√≥n del An√°lisis del Mercado Chileno\n",
    "\n",
    "**Distribuci√≥n Salarial:**\n",
    "- **Mediana**: $40,016 USD - El salario t√≠pico del desarrollador chileno en la muestra.\n",
    "- **Media**: Ligeramente superior, indicando presencia de salarios altos que elevan el promedio.\n",
    "- La distribuci√≥n muestra concentraci√≥n en el rango $30K-$60K con algunos outliers de alto valor.\n",
    "\n",
    "**Nivel de Experiencia:**\n",
    "- Mayor√≠a de desarrolladores chilenos en la muestra son **Junior (0-5 a√±os)**.\n",
    "- Diferencia salarial significativa entre Junior y Senior, reflejada en el boxplot inferior derecho.\n",
    "\n",
    "**Top Features - Importancia de Variables:**\n",
    "- **WorkExp domina con ~45%**: La experiencia laboral es el predictor m√°s fuerte del salario.\n",
    "- Tecnolog√≠as clave: PHP, Kubernetes, AWS, Terraform aparecen en top 10.\n",
    "- **Nota sobre visualizaci√≥n**: WorkExp representa casi la mitad de la importancia total. En an√°lisis m√°s detallados, se podr√≠a crear un sub-gr√°fico excluyendo WorkExp para apreciar mejor las diferencias entre las dem√°s tecnolog√≠as."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen Ejecutivo: Dataset Combinado SO2023 + SO2025\n",
    "\n",
    "### Principales Resultados\n",
    "\n",
    "1. **Dataset Robusto**: 68,613 registros procesados (incremento del 50% respecto a version anterior)\n",
    "2. **Mejoras Significativas en Metricas**:\n",
    "   - Regresion: R¬≤=0.9130 (+0.75%), RMSE=$15,845 (reduccion de $206)\n",
    "   - Clasificacion: F1=0.9769 (+0.31%), Accuracy=98.59%\n",
    "3. **Analisis del Mercado Chileno**: 186 desarrolladores analizados, mediana salarial $40,016 USD\n",
    "4. **Tecnologias Clave Identificadas**: WorkExp (45%), PHP, Kubernetes, AWS, Terraform\n",
    "\n",
    "### Modelos con Mejor Desempe√±o\n",
    "\n",
    "| Tipo | Modelo | Metrica Principal | Rendimiento |\n",
    "|------|--------|-------------------|-------------|\n",
    "| Regresion | RandomForestRegressor | R2 Score | **0.9130** (91.30%) |\n",
    "| Clasificacion | LGBMClassifier | F1-Score | **0.9769** (97.69%) |\n",
    "\n",
    "### Impacto de Combinar Datasets SO2023 y SO2025\n",
    "\n",
    "- **Incremento del 50% en datos de entrenamiento**: 36K ‚Üí 54.9K registros\n",
    "- **Mayor robustez**: Los modelos generalizan mejor con mayor diversidad de datos\n",
    "- **Actualidad**: Inclusion de tendencias tecnologicas recientes de 2025\n",
    "- **Variable Year**: Permite analisis temporal de cambios en el ecosistema tecnologico\n",
    "\n",
    "### Conclusiones\n",
    "\n",
    "Los resultados demuestran que la combinacion de multiples a√±os de datos del Stack Overflow Developer Survey mejora significativamente el rendimiento predictivo de los modelos de Machine Learning. La arquitectura de pipelines Kedro permitio una integracion modular y reproducible de los datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Comparacion: Datos RAW vs Datos PROCESADOS (Normalizados)\n",
    "\n",
    "Para entender mejor la transformacion, comparemos un ejemplo real de desarrollador antes y despues del procesamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar dataset RAW (sin procesar) - SO2023\n",
    "raw_path = Path('../data/01_raw/stack_overflow_2023/survey_results_public.csv')\n",
    "processed_path = Path('../data/05_model_input/datos_para_modelado.parquet')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPARACION: DATOS RAW vs PROCESADOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Cargar datasets\n",
    "df_processed = pd.read_parquet(processed_path)\n",
    "\n",
    "if raw_path.exists():\n",
    "    # Leer solo las columnas que nos interesan del raw\n",
    "    df_raw = pd.read_csv(raw_path, usecols=['ResponseId', 'YearsCodePro', 'ConvertedCompYearly'])\n",
    "\n",
    "    # Tomar un ejemplo: ResponseId = 4 (primera fila del procesado que mostraste)\n",
    "    example_id = 4\n",
    "\n",
    "    # Buscar en RAW\n",
    "    raw_example = df_raw[df_raw['ResponseId'] == example_id]\n",
    "\n",
    "    if not raw_example.empty:\n",
    "        # Buscar en PROCESADO\n",
    "        proc_example = df_processed[df_processed['ResponseId'] == example_id]\n",
    "\n",
    "        print(\"\\nEJEMPLO DE DESARROLLADOR (ResponseId = 4):\")\n",
    "        print(\"\\n\" + \"-\" * 80)\n",
    "        print(\"DATOS RAW (Originales de Stack Overflow 2023):\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"  ResponseId: {raw_example['ResponseId'].values[0]}\")\n",
    "        print(f\"  YearsCodePro (Experiencia): {raw_example['YearsCodePro'].values[0]} a√±os\")\n",
    "        print(f\"  ConvertedCompYearly (Salario): ${raw_example['ConvertedCompYearly'].values[0]:,.2f} USD\")\n",
    "\n",
    "        print(\"\\n\" + \"-\" * 80)\n",
    "        print(\"DATOS PROCESADOS (Normalizados para el modelo):\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"  ResponseId: {proc_example['ResponseId'].values[0]}\")\n",
    "        print(f\"  WorkExp (Normalizado): {proc_example['WorkExp'].values[0]:.6f}\")\n",
    "        print(f\"  CompTotal (Normalizado): {proc_example['CompTotal'].values[0]:.6f}\")\n",
    "        print(f\"  ConvertedCompYearly (Target): ${proc_example['ConvertedCompYearly'].values[0]:,.2f} USD\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"INTERPRETACION:\")\n",
    "        print(\"=\" * 80)\n",
    "        workexp_norm = proc_example['WorkExp'].values[0]\n",
    "\n",
    "        if workexp_norm < -1:\n",
    "            interpretacion = \"MUY BAJA experiencia (junior/estudiante)\"\n",
    "        elif workexp_norm < -0.5:\n",
    "            interpretacion = \"BAJA experiencia (3-5 a√±os)\"\n",
    "        elif workexp_norm < 0:\n",
    "            interpretacion = \"Ligeramente BAJO promedio (6-7 a√±os)\"\n",
    "        elif workexp_norm < 0.5:\n",
    "            interpretacion = \"Ligeramente SOBRE promedio (9-10 a√±os)\"\n",
    "        elif workexp_norm < 1:\n",
    "            interpretacion = \"ALTA experiencia (12-15 a√±os)\"\n",
    "        else:\n",
    "            interpretacion = \"MUY ALTA experiencia (15+ a√±os)\"\n",
    "\n",
    "        print(f\"\\nWorkExp = {workexp_norm:.3f} ‚Üí {interpretacion}\")\n",
    "\n",
    "        # Mostrar algunas features binarias\n",
    "        print(\"\\n\" + \"-\" * 80)\n",
    "        print(\"EJEMPLOS DE FEATURES BINARIAS (no normalizadas):\")\n",
    "        print(\"-\" * 80)\n",
    "        binary_cols = [col for col in proc_example.columns if col.startswith('LanguageHaveWorkedWith_')][:5]\n",
    "        for col in binary_cols:\n",
    "            value = proc_example[col].values[0]\n",
    "            lang = col.replace('LanguageHaveWorkedWith_', '')\n",
    "            status = \"SI usa\" if value == 1 else \"NO usa\"\n",
    "            print(f\"  {lang}: {value} ‚Üí {status}\")\n",
    "    else:\n",
    "        print(f\"\\nNo se encontro ResponseId {example_id} en datos RAW\")\n",
    "        print(\"\\nMostrando estadisticas generales del dataset procesado:\")\n",
    "        print(\"\\nWorkExp (normalizado):\")\n",
    "        print(f\"  Media: {df_processed['WorkExp'].mean():.6f} (por definicion de StandardScaler ‚âà 0)\")\n",
    "        print(f\"  Std: {df_processed['WorkExp'].std():.6f} (por definicion ‚âà 1)\")\n",
    "        print(f\"  Min: {df_processed['WorkExp'].min():.6f}\")\n",
    "        print(f\"  Max: {df_processed['WorkExp'].max():.6f}\")\n",
    "else:\n",
    "    print(\"\\nArchivo RAW no encontrado. Mostrando solo estadisticas del procesado:\")\n",
    "    print(\"\\nWorkExp (normalizado):\")\n",
    "    print(f\"  Media: {df_processed['WorkExp'].mean():.6f}\")\n",
    "    print(f\"  Std: {df_processed['WorkExp'].std():.6f}\")\n",
    "    print(f\"  Rango: [{df_processed['WorkExp'].min():.3f}, {df_processed['WorkExp'].max():.3f}]\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizacion: Distribucion de WorkExp (Normalizado)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Subplot 1: Histograma de WorkExp normalizado\n",
    "axes[0].hist(df_processed['WorkExp'], bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[0].axvline(x=0, color='red', linestyle='--', linewidth=2, label='Media = 0')\n",
    "axes[0].axvline(x=-1, color='orange', linestyle=':', linewidth=2, label='-1 std')\n",
    "axes[0].axvline(x=1, color='orange', linestyle=':', linewidth=2, label='+1 std')\n",
    "axes[0].set_xlabel('WorkExp (Normalizado)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Frecuencia', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Distribucion de Experiencia Laboral (Normalizada)', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Agregar anotaciones de interpretacion\n",
    "axes[0].text(-2, axes[0].get_ylim()[1]*0.9, 'Juniors\\n(0-3 a√±os)',\n",
    "             fontsize=10, ha='center', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n",
    "axes[0].text(0, axes[0].get_ylim()[1]*0.9, 'Promedio\\n(~8 a√±os)',\n",
    "             fontsize=10, ha='center', bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
    "axes[0].text(2, axes[0].get_ylim()[1]*0.9, 'Seniors\\n(15+ a√±os)',\n",
    "             fontsize=10, ha='center', bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.5))\n",
    "\n",
    "# Subplot 2: Ejemplo de conversion (si tenemos datos RAW)\n",
    "if raw_path.exists() and not df_raw.empty:\n",
    "    # Crear muestra de conversi√≥n\n",
    "    sample_raw = df_raw.dropna(subset=['YearsCodePro', 'ConvertedCompYearly']).sample(1000, random_state=42)\n",
    "\n",
    "    # Calcular media y std (aproximados, ya que el procesado incluye 2025 tambi√©n)\n",
    "    mean_exp = sample_raw['YearsCodePro'].mean()\n",
    "    std_exp = sample_raw['YearsCodePro'].std()\n",
    "\n",
    "    # Scatter plot\n",
    "    axes[1].scatter(sample_raw['YearsCodePro'],\n",
    "                   (sample_raw['YearsCodePro'] - mean_exp) / std_exp,\n",
    "                   alpha=0.5, s=30, color='steelblue')\n",
    "    axes[1].axhline(y=0, color='red', linestyle='--', linewidth=2, label='Media normalizada = 0')\n",
    "    axes[1].set_xlabel('Years of Experience (Original)', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('WorkExp (Normalizado)', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_title('Conversion: A√±os Reales ‚Üí Valores Normalizados', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend(fontsize=10)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    # Agregar ejemplos de conversion\n",
    "    examples = [(0, -1.5), (5, -0.5), (10, 0.3), (20, 1.5)]\n",
    "    for real_years, norm_val in examples:\n",
    "        axes[1].annotate(f'{real_years} a√±os',\n",
    "                        xy=(real_years, (real_years - mean_exp) / std_exp),\n",
    "                        xytext=(real_years + 2, norm_val),\n",
    "                        fontsize=9,\n",
    "                        arrowprops=dict(arrowstyle='->', color='red', lw=1.5))\n",
    "else:\n",
    "    # Si no hay datos RAW, mostrar gu√≠a de interpretaci√≥n\n",
    "    axes[1].axis('off')\n",
    "    interpretation_text = \"\"\"\n",
    "    GUIA DE INTERPRETACION\n",
    "    \n",
    "    Valor Normalizado ‚Üí Experiencia Aproximada\n",
    "    \n",
    "    -2.0  ‚Üí  0-2 a√±os (Estudiante/Junior)\n",
    "    -1.0  ‚Üí  3-5 a√±os (Junior avanzado)\n",
    "    -0.5  ‚Üí  5-6 a√±os (Semi-senior)\n",
    "     0.0  ‚Üí  8 a√±os (Promedio del mercado)\n",
    "    +0.5  ‚Üí  10-11 a√±os (Senior)\n",
    "    +1.0  ‚Üí  14-15 a√±os (Senior avanzado)\n",
    "    +2.0  ‚Üí  20+ a√±os (Experto/Arquitecto)\n",
    "    \n",
    "    NOTA: Estos valores son aproximaciones\n",
    "    basadas en la media y desviacion estandar\n",
    "    del dataset completo (SO2023 + SO2025)\n",
    "    \"\"\"\n",
    "    axes[1].text(0.1, 0.5, interpretation_text,\n",
    "                fontsize=12, family='monospace',\n",
    "                verticalalignment='center',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    axes[1].set_title('Guia de Interpretacion de Valores Normalizados',\n",
    "                     fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/08_reporting/workexp_normalization_explanation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nGrafico guardado: workexp_normalization_explanation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones sobre Normalizacion de Datos\n",
    "\n",
    "### Por que normalizar?\n",
    "\n",
    "1. **Escala Uniforme**: Evita que features con valores grandes (salarios en miles) dominen sobre features peque√±as (a√±os de experiencia).\n",
    "\n",
    "2. **Convergencia del Modelo**: Algoritmos como Ridge, Lasso y redes neuronales convergen mas rapido con datos normalizados.\n",
    "\n",
    "3. **Interpretabilidad de Coeficientes**: En modelos lineales, los coeficientes normalizados permiten comparar la importancia relativa de cada feature.\n",
    "\n",
    "### Que NO se normaliza?\n",
    "\n",
    "- **Variables Binarias**: LearnCode_*, LanguageHaveWorkedWith_*, etc. (ya son 0 o 1)\n",
    "- **Variables Categoricas Codificadas**: Year_2023, Year_2025, Country_* (son dummies)\n",
    "- **ResponseId**: Identificador unico (no es una feature predictiva)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> \"Se aplico StandardScaler (media=0, std=1) a las variables numericas continuas (WorkExp, CompTotal) para garantizar que todas las features contribuyan equitativamente al proceso de aprendizaje del modelo. Las variables categoricas binarias se mantuvieron sin transformacion al estar ya en el rango [0,1]. Esta decision se basa en las mejores practicas de preprocesamiento en Machine Learning, especialmente critica para algoritmos basados en gradientes y modelos de ensemble.\"\n",
    "\n",
    "---\n",
    "\n",
    "**Fecha de analisis**: Noviembre 2025  \n",
    "**Dataset**: Stack Overflow Developer Survey 2023 + 2025 (68,613 registros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y exploraci√≥n de los datasets principales\n",
    "\n",
    "A continuaci√≥n se cargan los tres datasets utilizados en el an√°lisis: Stack Overflow 2023, Stack Overflow 2025 y JetBrains Developer Ecosystem 2025. Se realiza una exploraci√≥n inicial para validar la integridad y estructura de los datos, asegurando que est√©n listos para el an√°lisis t√©cnico posterior.\n",
    "\n",
    "> Los datos se cargan directamente desde el cat√°logo de Kedro, garantizando reproducibilidad y consistencia en el flujo de trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 # Se asume que el objeto 'catalog' est√° disponible en el entorno</span>                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 # Si no, se debe inicializar el contexto de Kedro antes de ejecutar esta celda</span>              <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span> 7 df_so_2023 = <span style=\"font-weight: bold; text-decoration: underline\">catalog.load(</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">'stack_overflow_survey_results_public'</span><span style=\"font-weight: bold; text-decoration: underline\">)</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span>df_so_2025 = catalog.load(<span style=\"color: #808000; text-decoration-color: #808000\">'survey_results_public'</span>)                                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span>df_jb_2025 = catalog.load(<span style=\"color: #808000; text-decoration-color: #808000\">'developer_ecosystem_2025_external'</span>)                              <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/hector/Desktop/ML_Analisis_Ecosistema_Dev/.venv/lib/python3.11/site-packages/kedro/io/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dat</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">a_catalog.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">399</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">396 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #808000; text-decoration-color: #808000\">&gt;&gt;&gt; df = catalog.load(\"cars\")</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">397 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">398 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>load_version = Version(version, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> version <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>399 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>dataset = <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-weight: bold; text-decoration: underline\">self</span><span style=\"font-weight: bold; text-decoration: underline\">._get_dataset(name, version=load_version)</span>                            <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">400 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">401 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._logger.info(                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">402 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"Loading data from %s (%s)...\"</span>,                                                <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/hector/Desktop/ML_Analisis_Ecosistema_Dev/.venv/lib/python3.11/site-packages/kedro/io/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dat</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">a_catalog.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">359</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_dataset</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">356 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> matches:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">357 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>suggestions = <span style=\"color: #808000; text-decoration-color: #808000\">\", \"</span>.join(matches)                                       <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">358 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   </span>error_msg += <span style=\"color: #808000; text-decoration-color: #808000\">f\" - did you mean one of these instead: {</span>suggestions<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>    <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span> <span style=\"color: #800000; text-decoration-color: #800000\">‚ù± </span>359 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   ‚îÇ   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; font-weight: bold; text-decoration: underline\">raise</span><span style=\"font-weight: bold; text-decoration: underline\"> DatasetNotFoundError(error_msg)</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">360 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">361 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">‚îÇ   ‚îÇ   </span>dataset = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._datasets[dataset_name]                                             <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">362 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">‚îÇ</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">DatasetNotFoundError: </span>Dataset <span style=\"color: #008000; text-decoration-color: #008000\">'stack_overflow_survey_results_public'</span> not found in the catalog\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m‚ï≠‚îÄ\u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[0m\u001b[31m‚îÄ‚ïÆ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m7\u001b[0m                                                                                    \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 4 \u001b[0m\u001b[2m# Se asume que el objeto 'catalog' est√° disponible en el entorno\u001b[0m                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m# Si no, se debe inicializar el contexto de Kedro antes de ejecutar esta celda\u001b[0m              \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 6 \u001b[0m                                                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m 7 df_so_2023 = \u001b[1;4mcatalog.load(\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4;33mstack_overflow_survey_results_public\u001b[0m\u001b[1;4;33m'\u001b[0m\u001b[1;4m)\u001b[0m                           \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 8 \u001b[0mdf_so_2025 = catalog.load(\u001b[33m'\u001b[0m\u001b[33msurvey_results_public\u001b[0m\u001b[33m'\u001b[0m)                                          \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m 9 \u001b[0mdf_jb_2025 = catalog.load(\u001b[33m'\u001b[0m\u001b[33mdeveloper_ecosystem_2025_external\u001b[0m\u001b[33m'\u001b[0m)                              \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m10 \u001b[0m                                                                                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/Users/hector/Desktop/ML_Analisis_Ecosistema_Dev/.venv/lib/python3.11/site-packages/kedro/io/\u001b[0m\u001b[1;33mdat\u001b[0m \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[1;33ma_catalog.py\u001b[0m:\u001b[94m399\u001b[0m in \u001b[92mload\u001b[0m                                                                         \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m396 \u001b[0m\u001b[2;33m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[33m>>> df = catalog.load(\"cars\")\u001b[0m                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m397 \u001b[0m\u001b[2;33m‚îÇ   ‚îÇ   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m398 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mload_version = Version(version, \u001b[94mNone\u001b[0m) \u001b[94mif\u001b[0m version \u001b[94melse\u001b[0m \u001b[94mNone\u001b[0m                         \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m399 \u001b[2m‚îÇ   ‚îÇ   \u001b[0mdataset = \u001b[1;4;96mself\u001b[0m\u001b[1;4m._get_dataset(name, version=load_version)\u001b[0m                            \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m400 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m                                                                                   \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m401 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m\u001b[96mself\u001b[0m._logger.info(                                                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m402 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mLoading data from \u001b[0m\u001b[33m%s\u001b[0m\u001b[33m (\u001b[0m\u001b[33m%s\u001b[0m\u001b[33m)...\u001b[0m\u001b[33m\"\u001b[0m,                                                \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[2;33m/Users/hector/Desktop/ML_Analisis_Ecosistema_Dev/.venv/lib/python3.11/site-packages/kedro/io/\u001b[0m\u001b[1;33mdat\u001b[0m \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[1;33ma_catalog.py\u001b[0m:\u001b[94m359\u001b[0m in \u001b[92m_get_dataset\u001b[0m                                                                 \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m                                                                                                  \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m356 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[94mif\u001b[0m matches:                                                                \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m357 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0msuggestions = \u001b[33m\"\u001b[0m\u001b[33m, \u001b[0m\u001b[33m\"\u001b[0m.join(matches)                                       \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m358 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   \u001b[0merror_msg += \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m - did you mean one of these instead: \u001b[0m\u001b[33m{\u001b[0msuggestions\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m    \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m \u001b[31m‚ù± \u001b[0m359 \u001b[2m‚îÇ   ‚îÇ   ‚îÇ   \u001b[0m\u001b[1;4;94mraise\u001b[0m\u001b[1;4m DatasetNotFoundError(error_msg)\u001b[0m                                          \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m360 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0m                                                                                   \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m361 \u001b[0m\u001b[2m‚îÇ   ‚îÇ   \u001b[0mdataset = \u001b[96mself\u001b[0m._datasets[dataset_name]                                             \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚îÇ\u001b[0m   \u001b[2m362 \u001b[0m                                                                                           \u001b[31m‚îÇ\u001b[0m\n",
       "\u001b[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\u001b[0m\n",
       "\u001b[1;91mDatasetNotFoundError: \u001b[0mDataset \u001b[32m'stack_overflow_survey_results_public'\u001b[0m not found in the catalog\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carga de los datasets principales desde Kedro\n",
    "import pandas as pd\n",
    "\n",
    "# Se asume que el objeto 'catalog' est√° disponible en el entorno\n",
    "# Si no, se debe inicializar el contexto de Kedro antes de ejecutar esta celda\n",
    "\n",
    "df_so_2023 = catalog.load('stack_overflow_survey_results_public')\n",
    "df_so_2025 = catalog.load('survey_results_public')\n",
    "df_jb_2025 = catalog.load('developer_ecosystem_2025_external')\n",
    "\n",
    "# Exploraci√≥n inicial de los datasets\n",
    "for nombre, df in zip([\n",
    "    'Stack Overflow 2023',\n",
    "    'Stack Overflow 2025',\n",
    "    'JetBrains Developer Ecosystem 2025'\n",
    "], [df_so_2023, df_so_2025, df_jb_2025]):\n",
    "    print(f\"\\n--- {nombre} ---\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columnas: {list(df.columns)[:8]} ...\")\n",
    "    print(df.dtypes.head(8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
